{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import twenty_newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'imdb_labelled.txt' does not exist: b'imdb_labelled.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-34bef109c508>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mData\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'imdb_labelled.txt'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\\t'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Text'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Sentiment'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\bibekenv\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    703\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\bibekenv\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 429\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\bibekenv\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\bibekenv\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1120\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1121\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1122\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1123\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1124\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\bibekenv\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'usecols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1852\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1855\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'imdb_labelled.txt' does not exist: b'imdb_labelled.txt'"
     ]
    }
   ],
   "source": [
    "Data = pd.read_csv('imdb_labelled.txt',sep='\\t',names=['Text','Sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-ce436162f1ba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mData\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Data' is not defined"
     ]
    }
   ],
   "source": [
    "Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BoW = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = BoW.fit_transform(np.asarray(Data.Text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10',\n",
       " '12',\n",
       " '13',\n",
       " '15',\n",
       " '15pm',\n",
       " '17',\n",
       " '18th',\n",
       " '1928',\n",
       " '1947',\n",
       " '1948',\n",
       " '1949',\n",
       " '1971',\n",
       " '1973',\n",
       " '1980',\n",
       " '1986',\n",
       " '1995',\n",
       " '1998',\n",
       " '20',\n",
       " '2005',\n",
       " '2006',\n",
       " '20th',\n",
       " '25',\n",
       " '30',\n",
       " '40',\n",
       " '50',\n",
       " '54',\n",
       " '70',\n",
       " '70000',\n",
       " '70s',\n",
       " '80',\n",
       " '80s',\n",
       " '8pm',\n",
       " '90',\n",
       " '95',\n",
       " 'aailiyah',\n",
       " 'abandoned',\n",
       " 'ability',\n",
       " 'about',\n",
       " 'above',\n",
       " 'abroad',\n",
       " 'absolutely',\n",
       " 'abstruse',\n",
       " 'abysmal',\n",
       " 'academy',\n",
       " 'accents',\n",
       " 'accessible',\n",
       " 'acclaimed',\n",
       " 'accolades',\n",
       " 'accurate',\n",
       " 'accurately',\n",
       " 'accused',\n",
       " 'achievement',\n",
       " 'achille',\n",
       " 'ackerman',\n",
       " 'act',\n",
       " 'acted',\n",
       " 'acting',\n",
       " 'action',\n",
       " 'actions',\n",
       " 'actor',\n",
       " 'actors',\n",
       " 'actress',\n",
       " 'actresses',\n",
       " 'actually',\n",
       " 'adams',\n",
       " 'adaptation',\n",
       " 'add',\n",
       " 'added',\n",
       " 'addition',\n",
       " 'admins',\n",
       " 'admiration',\n",
       " 'admitted',\n",
       " 'adorable',\n",
       " 'adrift',\n",
       " 'adventure',\n",
       " 'advise',\n",
       " 'aerial',\n",
       " 'aesthetically',\n",
       " 'affected',\n",
       " 'affleck',\n",
       " 'afraid',\n",
       " 'africa',\n",
       " 'after',\n",
       " 'afternoon',\n",
       " 'again',\n",
       " 'against',\n",
       " 'age',\n",
       " 'aged',\n",
       " 'ages',\n",
       " 'ago',\n",
       " 'agree',\n",
       " 'agreed',\n",
       " 'aimless',\n",
       " 'air',\n",
       " 'aired',\n",
       " 'akasha',\n",
       " 'akin',\n",
       " 'alert',\n",
       " 'alexander',\n",
       " 'alike',\n",
       " 'all',\n",
       " 'allison',\n",
       " 'allow',\n",
       " 'allowing',\n",
       " 'almost',\n",
       " 'along',\n",
       " 'alongside',\n",
       " 'already',\n",
       " 'also',\n",
       " 'although',\n",
       " 'always',\n",
       " 'am',\n",
       " 'amateurish',\n",
       " 'amaze',\n",
       " 'amazed',\n",
       " 'amazing',\n",
       " 'amazingly',\n",
       " 'america',\n",
       " 'american',\n",
       " 'americans',\n",
       " 'among',\n",
       " 'amount',\n",
       " 'amusing',\n",
       " 'an',\n",
       " 'anatomist',\n",
       " 'and',\n",
       " 'angel',\n",
       " 'angela',\n",
       " 'angeles',\n",
       " 'angelina',\n",
       " 'angle',\n",
       " 'angles',\n",
       " 'angry',\n",
       " 'anguish',\n",
       " 'angus',\n",
       " 'animals',\n",
       " 'animated',\n",
       " 'animation',\n",
       " 'anita',\n",
       " 'ann',\n",
       " 'anne',\n",
       " 'anniversary',\n",
       " 'annoying',\n",
       " 'another',\n",
       " 'anthony',\n",
       " 'antithesis',\n",
       " 'any',\n",
       " 'anyone',\n",
       " 'anything',\n",
       " 'anyway',\n",
       " 'apart',\n",
       " 'appalling',\n",
       " 'appealing',\n",
       " 'appearance',\n",
       " 'appears',\n",
       " 'applauded',\n",
       " 'applause',\n",
       " 'appreciate',\n",
       " 'appropriate',\n",
       " 'apt',\n",
       " 'are',\n",
       " 'aren',\n",
       " 'argued',\n",
       " 'armageddon',\n",
       " 'armand',\n",
       " 'around',\n",
       " 'array',\n",
       " 'art',\n",
       " 'articulated',\n",
       " 'artiness',\n",
       " 'artist',\n",
       " 'artistic',\n",
       " 'artless',\n",
       " 'arts',\n",
       " 'as',\n",
       " 'aside',\n",
       " 'ask',\n",
       " 'asleep',\n",
       " 'aspect',\n",
       " 'aspects',\n",
       " 'ass',\n",
       " 'assante',\n",
       " 'assaulted',\n",
       " 'assistant',\n",
       " 'astonishingly',\n",
       " 'astronaut',\n",
       " 'at',\n",
       " 'atmosphere',\n",
       " 'atrocious',\n",
       " 'atrocity',\n",
       " 'attempt',\n",
       " 'attempted',\n",
       " 'attempting',\n",
       " 'attempts',\n",
       " 'attention',\n",
       " 'attractive',\n",
       " 'audience',\n",
       " 'audio',\n",
       " 'aurvåg',\n",
       " 'austen',\n",
       " 'austere',\n",
       " 'author',\n",
       " 'average',\n",
       " 'aversion',\n",
       " 'avoid',\n",
       " 'avoided',\n",
       " 'award',\n",
       " 'awarded',\n",
       " 'awards',\n",
       " 'away',\n",
       " 'awesome',\n",
       " 'awful',\n",
       " 'awkwardly',\n",
       " 'aye',\n",
       " 'baaaaaad',\n",
       " 'babbling',\n",
       " 'babie',\n",
       " 'baby',\n",
       " 'babysitting',\n",
       " 'back',\n",
       " 'backdrop',\n",
       " 'backed',\n",
       " 'bad',\n",
       " 'badly',\n",
       " 'bag',\n",
       " 'bailey',\n",
       " 'bakery',\n",
       " 'balance',\n",
       " 'balanced',\n",
       " 'ball',\n",
       " 'ballet',\n",
       " 'balls',\n",
       " 'band',\n",
       " 'barcelona',\n",
       " 'barely',\n",
       " 'barking',\n",
       " 'barney',\n",
       " 'barren',\n",
       " 'based',\n",
       " 'basic',\n",
       " 'basically',\n",
       " 'bat',\n",
       " 'bates',\n",
       " 'baxendale',\n",
       " 'be',\n",
       " 'bear',\n",
       " 'beautiful',\n",
       " 'beautifully',\n",
       " 'became',\n",
       " 'because',\n",
       " 'bechard',\n",
       " 'become',\n",
       " 'becomes',\n",
       " 'been',\n",
       " 'before',\n",
       " 'began',\n",
       " 'begin',\n",
       " 'beginning',\n",
       " 'behind',\n",
       " 'behold',\n",
       " 'being',\n",
       " 'bela',\n",
       " 'believable',\n",
       " 'believe',\n",
       " 'believed',\n",
       " 'bell',\n",
       " 'bellucci',\n",
       " 'belly',\n",
       " 'belmondo',\n",
       " 'below',\n",
       " 'ben',\n",
       " 'bendingly',\n",
       " 'bennett',\n",
       " 'bergen',\n",
       " 'bertolucci',\n",
       " 'best',\n",
       " 'better',\n",
       " 'betty',\n",
       " 'between',\n",
       " 'beware',\n",
       " 'beyond',\n",
       " 'bible',\n",
       " 'big',\n",
       " 'biggest',\n",
       " 'billy',\n",
       " 'biographical',\n",
       " 'bipolarity',\n",
       " 'bit',\n",
       " 'bitchy',\n",
       " 'black',\n",
       " 'blah',\n",
       " 'blake',\n",
       " 'bland',\n",
       " 'blandly',\n",
       " 'blare',\n",
       " 'blatant',\n",
       " 'blew',\n",
       " 'blood',\n",
       " 'blown',\n",
       " 'blue',\n",
       " 'blush',\n",
       " 'boasts',\n",
       " 'bob',\n",
       " 'body',\n",
       " 'bohemian',\n",
       " 'boiling',\n",
       " 'bold',\n",
       " 'bombardments',\n",
       " 'bond',\n",
       " 'bonding',\n",
       " 'bonus',\n",
       " 'bonuses',\n",
       " 'boobs',\n",
       " 'boogeyman',\n",
       " 'book',\n",
       " 'boost',\n",
       " 'bop',\n",
       " 'bordered',\n",
       " 'borderlines',\n",
       " 'borders',\n",
       " 'bore',\n",
       " 'bored',\n",
       " 'boring',\n",
       " 'borrowed',\n",
       " 'boss',\n",
       " 'both',\n",
       " 'bother',\n",
       " 'bothersome',\n",
       " 'bought',\n",
       " 'box',\n",
       " 'boyfriend',\n",
       " 'boyle',\n",
       " 'brain',\n",
       " 'brainsucking',\n",
       " 'brat',\n",
       " 'breaking',\n",
       " 'breeders',\n",
       " 'brevity',\n",
       " 'brian',\n",
       " 'brief',\n",
       " 'brigand',\n",
       " 'bright',\n",
       " 'brilliance',\n",
       " 'brilliant',\n",
       " 'brilliantly',\n",
       " 'bring',\n",
       " 'brings',\n",
       " 'broad',\n",
       " 'broke',\n",
       " 'brooding',\n",
       " 'brother',\n",
       " 'brutal',\n",
       " 'buddy',\n",
       " 'budget',\n",
       " 'buffalo',\n",
       " 'buffet',\n",
       " 'build',\n",
       " 'builders',\n",
       " 'buildings',\n",
       " 'built',\n",
       " 'bullock',\n",
       " 'bully',\n",
       " 'bunch',\n",
       " 'burton',\n",
       " 'business',\n",
       " 'but',\n",
       " 'buy',\n",
       " 'by',\n",
       " 'cable',\n",
       " 'cailles',\n",
       " 'california',\n",
       " 'call',\n",
       " 'called',\n",
       " 'calls',\n",
       " 'came',\n",
       " 'cameo',\n",
       " 'camera',\n",
       " 'camerawork',\n",
       " 'camp',\n",
       " 'campy',\n",
       " 'can',\n",
       " 'canada',\n",
       " 'cancan',\n",
       " 'candace',\n",
       " 'candle',\n",
       " 'cannot',\n",
       " 'cant',\n",
       " 'captain',\n",
       " 'captured',\n",
       " 'captures',\n",
       " 'car',\n",
       " 'card',\n",
       " 'cardboard',\n",
       " 'cardellini',\n",
       " 'care',\n",
       " 'carol',\n",
       " 'carrell',\n",
       " 'carries',\n",
       " 'carry',\n",
       " 'cars',\n",
       " 'cartoon',\n",
       " 'cartoons',\n",
       " 'case',\n",
       " 'cases',\n",
       " 'cast',\n",
       " 'casted',\n",
       " 'casting',\n",
       " 'cat',\n",
       " 'catchy',\n",
       " 'caught',\n",
       " 'cause',\n",
       " 'ceases',\n",
       " 'celebration',\n",
       " 'celebrity',\n",
       " 'celluloid',\n",
       " 'centers',\n",
       " 'central',\n",
       " 'century',\n",
       " 'certain',\n",
       " 'certainly',\n",
       " 'cg',\n",
       " 'cgi',\n",
       " 'chalkboard',\n",
       " 'challenges',\n",
       " 'chance',\n",
       " 'change',\n",
       " 'changes',\n",
       " 'changing',\n",
       " 'channel',\n",
       " 'character',\n",
       " 'characterisation',\n",
       " 'characters',\n",
       " 'charisma',\n",
       " 'charismatic',\n",
       " 'charles',\n",
       " 'charlie',\n",
       " 'charm',\n",
       " 'charming',\n",
       " 'chase',\n",
       " 'chasing',\n",
       " 'cheap',\n",
       " 'cheaply',\n",
       " 'check',\n",
       " 'checking',\n",
       " 'cheek',\n",
       " 'cheekbones',\n",
       " 'cheerfull',\n",
       " 'cheerless',\n",
       " 'cheesiness',\n",
       " 'cheesy',\n",
       " 'chemistry',\n",
       " 'chick',\n",
       " 'child',\n",
       " 'childhood',\n",
       " 'children',\n",
       " 'childrens',\n",
       " 'chills',\n",
       " 'chilly',\n",
       " 'chimp',\n",
       " 'chodorov',\n",
       " 'choice',\n",
       " 'choices',\n",
       " 'choked',\n",
       " 'chosen',\n",
       " 'chow',\n",
       " 'christmas',\n",
       " 'christopher',\n",
       " 'church',\n",
       " 'cinema',\n",
       " 'cinematic',\n",
       " 'cinematographers',\n",
       " 'cinematography',\n",
       " 'circumstances',\n",
       " 'class',\n",
       " 'classic',\n",
       " 'classical',\n",
       " 'clear',\n",
       " 'clearly',\n",
       " 'clever',\n",
       " 'cliche',\n",
       " 'clichés',\n",
       " 'clients',\n",
       " 'cliff',\n",
       " 'climax',\n",
       " 'close',\n",
       " 'closed',\n",
       " 'clothes',\n",
       " 'club',\n",
       " 'co',\n",
       " 'coach',\n",
       " 'coal',\n",
       " 'coastal',\n",
       " 'coaster',\n",
       " 'coherent',\n",
       " 'cold',\n",
       " 'cole',\n",
       " 'collect',\n",
       " 'collective',\n",
       " 'colored',\n",
       " 'colorful',\n",
       " 'colours',\n",
       " 'columbo',\n",
       " 'come',\n",
       " 'comedic',\n",
       " 'comedy',\n",
       " 'comes',\n",
       " 'comfortable',\n",
       " 'comforting',\n",
       " 'comical',\n",
       " 'coming',\n",
       " 'commands',\n",
       " 'comment',\n",
       " 'commentary',\n",
       " 'commented',\n",
       " 'comments',\n",
       " 'commercial',\n",
       " 'community',\n",
       " 'company',\n",
       " 'compelling',\n",
       " 'competent',\n",
       " 'complete',\n",
       " 'completed',\n",
       " 'completely',\n",
       " 'complex',\n",
       " 'complexity',\n",
       " 'composed',\n",
       " 'composition',\n",
       " 'comprehensible',\n",
       " 'compromise',\n",
       " 'computer',\n",
       " 'concentrate',\n",
       " 'conception',\n",
       " 'conceptually',\n",
       " 'concerning',\n",
       " 'concerns',\n",
       " 'concert',\n",
       " 'conclusion',\n",
       " 'condescends',\n",
       " 'confidence',\n",
       " 'configuration',\n",
       " 'confirm',\n",
       " 'conflict',\n",
       " 'confuses',\n",
       " 'confusing',\n",
       " 'connections',\n",
       " 'connery',\n",
       " 'connor',\n",
       " 'conrad',\n",
       " 'consequences',\n",
       " 'consider',\n",
       " 'considerable',\n",
       " 'considered',\n",
       " 'considering',\n",
       " 'considers',\n",
       " 'consistent',\n",
       " 'consolations',\n",
       " 'constant',\n",
       " 'constantine',\n",
       " 'constructed',\n",
       " 'contained',\n",
       " 'containing',\n",
       " 'contains',\n",
       " 'content',\n",
       " 'continually',\n",
       " 'continuation',\n",
       " 'continue',\n",
       " 'continuity',\n",
       " 'continuously',\n",
       " 'contract',\n",
       " 'contrast',\n",
       " 'contributing',\n",
       " 'contributory',\n",
       " 'contrived',\n",
       " 'control',\n",
       " 'controversy',\n",
       " 'convention',\n",
       " 'convey',\n",
       " 'convince',\n",
       " 'convincing',\n",
       " 'convoluted',\n",
       " 'cool',\n",
       " 'coppola',\n",
       " 'cords',\n",
       " 'core',\n",
       " 'corn',\n",
       " 'corny',\n",
       " 'correct',\n",
       " 'cost',\n",
       " 'costs',\n",
       " 'costumes',\n",
       " 'cotton',\n",
       " 'could',\n",
       " 'couldn',\n",
       " 'couple',\n",
       " 'course',\n",
       " 'court',\n",
       " 'courtroom',\n",
       " 'cover',\n",
       " 'cowardice',\n",
       " 'cox',\n",
       " 'crackles',\n",
       " 'crafted',\n",
       " 'crap',\n",
       " 'crash',\n",
       " 'crashed',\n",
       " 'crayon',\n",
       " 'crayons',\n",
       " 'crazy',\n",
       " 'create',\n",
       " 'created',\n",
       " 'creates',\n",
       " 'creative',\n",
       " 'creativity',\n",
       " 'creature',\n",
       " 'credible',\n",
       " 'credit',\n",
       " 'credits',\n",
       " 'crew',\n",
       " 'crime',\n",
       " 'crisp',\n",
       " 'critic',\n",
       " 'critical',\n",
       " 'crocdodile',\n",
       " 'crocs',\n",
       " 'cross',\n",
       " 'crowd',\n",
       " 'crowe',\n",
       " 'cruel',\n",
       " 'cruise',\n",
       " 'cry',\n",
       " 'cult',\n",
       " 'culture',\n",
       " 'curtain',\n",
       " 'custer',\n",
       " 'cute',\n",
       " 'cutest',\n",
       " 'cutie',\n",
       " 'cutouts',\n",
       " 'cuts',\n",
       " 'cutting',\n",
       " 'dads',\n",
       " 'damian',\n",
       " 'damn',\n",
       " 'dance',\n",
       " 'dancing',\n",
       " 'dangerous',\n",
       " 'dark',\n",
       " 'darren',\n",
       " 'daughter',\n",
       " 'daughters',\n",
       " 'day',\n",
       " 'days',\n",
       " 'de',\n",
       " 'dead',\n",
       " 'deadly',\n",
       " 'deadpan',\n",
       " 'deal',\n",
       " 'dealt',\n",
       " 'death',\n",
       " 'debated',\n",
       " 'debbie',\n",
       " 'debits',\n",
       " 'debut',\n",
       " 'decay',\n",
       " 'decent',\n",
       " 'decidely',\n",
       " 'decipher',\n",
       " 'decisions',\n",
       " 'dedication',\n",
       " 'dee',\n",
       " 'deep',\n",
       " 'deeply',\n",
       " 'defensemen',\n",
       " 'defined',\n",
       " 'definitely',\n",
       " 'delete',\n",
       " 'delight',\n",
       " 'delightful',\n",
       " 'delights',\n",
       " 'deliver',\n",
       " 'delivered',\n",
       " 'delivering',\n",
       " 'delivers',\n",
       " 'dependant',\n",
       " 'depending',\n",
       " 'depends',\n",
       " 'depicted',\n",
       " 'depicts',\n",
       " 'depressing',\n",
       " 'depth',\n",
       " 'derivative',\n",
       " 'describe',\n",
       " 'describes',\n",
       " 'desert',\n",
       " 'deserved',\n",
       " 'deserves',\n",
       " 'deserving',\n",
       " 'design',\n",
       " 'designed',\n",
       " 'designer',\n",
       " 'desperately',\n",
       " 'desperation',\n",
       " 'despised',\n",
       " 'despite',\n",
       " 'destroy',\n",
       " 'detailing',\n",
       " 'details',\n",
       " 'develop',\n",
       " 'development',\n",
       " 'developments',\n",
       " 'di',\n",
       " 'diabetic',\n",
       " 'dialog',\n",
       " 'dialogs',\n",
       " 'dialogue',\n",
       " 'diaper',\n",
       " 'dickens',\n",
       " 'did',\n",
       " 'didn',\n",
       " 'difference',\n",
       " 'different',\n",
       " 'dignity',\n",
       " 'dimensional',\n",
       " 'direct',\n",
       " 'directed',\n",
       " 'directing',\n",
       " 'direction',\n",
       " 'director',\n",
       " 'directorial',\n",
       " 'directors',\n",
       " 'disappointed',\n",
       " 'disappointing',\n",
       " 'disappointment',\n",
       " 'disaster',\n",
       " 'disbelief',\n",
       " 'discomfort',\n",
       " 'discovering',\n",
       " 'discovery',\n",
       " 'disgrace',\n",
       " 'disgusting',\n",
       " 'dislike',\n",
       " 'disliked',\n",
       " 'disney',\n",
       " 'disparate',\n",
       " 'distant',\n",
       " 'distinction',\n",
       " 'distorted',\n",
       " 'distract',\n",
       " 'distressed',\n",
       " 'disturbing',\n",
       " 'diving',\n",
       " 'do',\n",
       " 'doctor',\n",
       " 'documentaries',\n",
       " 'documentary',\n",
       " 'dodge',\n",
       " 'does',\n",
       " 'doesn',\n",
       " 'dogs',\n",
       " 'doing',\n",
       " 'dollars',\n",
       " 'dominated',\n",
       " 'don',\n",
       " 'done',\n",
       " 'donlevy',\n",
       " 'dont',\n",
       " 'doomed',\n",
       " 'dosen',\n",
       " 'doubt',\n",
       " 'down',\n",
       " 'downs',\n",
       " 'dozen',\n",
       " 'dr',\n",
       " 'dracula',\n",
       " 'draft',\n",
       " 'drag',\n",
       " 'drago',\n",
       " 'drama',\n",
       " 'dramatic',\n",
       " 'drawings',\n",
       " 'drawn',\n",
       " 'dream',\n",
       " 'dreams',\n",
       " 'dreary',\n",
       " 'dribble',\n",
       " 'drift',\n",
       " 'drifting',\n",
       " 'drive',\n",
       " 'drooling',\n",
       " 'dropped',\n",
       " 'dry',\n",
       " 'due',\n",
       " 'duet',\n",
       " 'dull',\n",
       " 'dumb',\n",
       " 'dumbest',\n",
       " 'duper',\n",
       " 'during',\n",
       " 'duris',\n",
       " 'dustin',\n",
       " 'dvd',\n",
       " 'dwight',\n",
       " 'dysfunction',\n",
       " 'each',\n",
       " 'earlier',\n",
       " 'early',\n",
       " 'earth',\n",
       " 'easily',\n",
       " 'easy',\n",
       " 'eating',\n",
       " 'ebay',\n",
       " 'ebola',\n",
       " 'eccleston',\n",
       " 'ed',\n",
       " 'edge',\n",
       " 'editing',\n",
       " 'edition',\n",
       " 'educational',\n",
       " 'edward',\n",
       " 'effect',\n",
       " 'effective',\n",
       " 'effects',\n",
       " 'effort',\n",
       " 'efforts',\n",
       " 'egotism',\n",
       " 'eighth',\n",
       " 'eiko',\n",
       " 'either',\n",
       " 'elaborately',\n",
       " 'elderly',\n",
       " 'elegant',\n",
       " 'element',\n",
       " 'elias',\n",
       " 'eloquently',\n",
       " 'else',\n",
       " 'elsewhere',\n",
       " 'embarrassed',\n",
       " 'embarrassing',\n",
       " 'embassy',\n",
       " 'emerge',\n",
       " 'emilio',\n",
       " 'emily',\n",
       " 'emoting',\n",
       " 'emotion',\n",
       " 'emotionally',\n",
       " 'emotions',\n",
       " 'emperor',\n",
       " 'empowerment',\n",
       " 'emptiness',\n",
       " 'empty',\n",
       " 'en',\n",
       " 'enchanting',\n",
       " 'end',\n",
       " 'endearing',\n",
       " 'ended',\n",
       " 'ending',\n",
       " 'endlessly',\n",
       " 'ends',\n",
       " 'energetic',\n",
       " 'energy',\n",
       " 'engaging',\n",
       " 'english',\n",
       " 'enhanced',\n",
       " 'enjoy',\n",
       " 'enjoyable',\n",
       " 'enjoyed',\n",
       " 'enjoyment',\n",
       " 'enough',\n",
       " 'enter',\n",
       " 'enterprise',\n",
       " 'entertained',\n",
       " 'entertaining',\n",
       " 'entire',\n",
       " 'entirely',\n",
       " 'entrance',\n",
       " 'episode',\n",
       " 'episodes',\n",
       " 'equivalent',\n",
       " 'era',\n",
       " 'errol',\n",
       " 'errors',\n",
       " 'escalating',\n",
       " 'escapism',\n",
       " 'especially',\n",
       " 'essence',\n",
       " 'establish',\n",
       " 'established',\n",
       " 'estate',\n",
       " 'estevez',\n",
       " 'etc',\n",
       " 'european',\n",
       " 'evaluate',\n",
       " 'even',\n",
       " 'events',\n",
       " 'ever',\n",
       " 'every',\n",
       " 'everybody',\n",
       " 'everyone',\n",
       " 'everything',\n",
       " 'everywhere',\n",
       " 'evidently',\n",
       " 'evil',\n",
       " 'evinced',\n",
       " 'evokes',\n",
       " 'exactly',\n",
       " 'exaggerating',\n",
       " 'example',\n",
       " 'excellent',\n",
       " 'excellently',\n",
       " 'except',\n",
       " 'exceptional',\n",
       " 'exceptionally',\n",
       " 'excerpts',\n",
       " 'excessively',\n",
       " 'exchange',\n",
       " 'exciting',\n",
       " 'excruciatingly',\n",
       " 'excuse',\n",
       " 'excuses',\n",
       " 'executed',\n",
       " 'exemplars',\n",
       " 'existent',\n",
       " 'existential',\n",
       " 'expansive',\n",
       " 'expect',\n",
       " 'expectations',\n",
       " 'expected',\n",
       " 'expecting',\n",
       " 'experience',\n",
       " 'experiences',\n",
       " 'expert',\n",
       " 'explain',\n",
       " 'explains',\n",
       " 'explanation',\n",
       " 'exploit',\n",
       " 'explorations',\n",
       " 'explosion',\n",
       " 'expression',\n",
       " 'exquisite',\n",
       " 'extant',\n",
       " 'exteriors',\n",
       " 'extraneous',\n",
       " 'extraordinary',\n",
       " 'extremely',\n",
       " 'eye',\n",
       " 'eyes',\n",
       " 'fabulous',\n",
       " 'face',\n",
       " 'faces',\n",
       " 'facial',\n",
       " 'facing',\n",
       " 'fact',\n",
       " 'factory',\n",
       " 'failed',\n",
       " 'fails',\n",
       " 'fair',\n",
       " 'fairly',\n",
       " 'faithful',\n",
       " 'fall',\n",
       " 'falling',\n",
       " 'falls',\n",
       " 'falsely',\n",
       " 'falwell',\n",
       " 'fame',\n",
       " 'famed',\n",
       " 'family',\n",
       " 'famous',\n",
       " 'fan',\n",
       " 'fanciful',\n",
       " 'fans',\n",
       " 'fantastic',\n",
       " 'fantasy',\n",
       " 'far',\n",
       " 'farce',\n",
       " 'fare',\n",
       " 'fascinated',\n",
       " 'fascinating',\n",
       " 'fascination',\n",
       " 'fashioned',\n",
       " 'fast',\n",
       " 'faster',\n",
       " 'fat',\n",
       " 'father',\n",
       " 'faultless',\n",
       " 'fausa',\n",
       " 'faux',\n",
       " 'favorite',\n",
       " 'favourite',\n",
       " 'fear',\n",
       " 'feature',\n",
       " 'features',\n",
       " 'feel',\n",
       " 'feeling',\n",
       " 'feelings',\n",
       " 'feet',\n",
       " 'feisty',\n",
       " 'fellowes',\n",
       " 'felt',\n",
       " 'female',\n",
       " 'females',\n",
       " ...]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BoW.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(748, 3047)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ngrams = CountVectorizer(ngram_range=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "NgramFeatures = Ngrams.fit_transform(np.asarray(Data.Text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10',\n",
       " '10 10',\n",
       " '10 an',\n",
       " '10 an amazing',\n",
       " '10 and',\n",
       " '10 and only',\n",
       " '10 do',\n",
       " '10 do think',\n",
       " '10 feet',\n",
       " '10 feet wide',\n",
       " '10 for',\n",
       " '10 for both',\n",
       " '10 grade',\n",
       " '10 grade note',\n",
       " '10 on',\n",
       " '10 on my',\n",
       " '10 out',\n",
       " '10 out of',\n",
       " '10 plus',\n",
       " '10 plus if',\n",
       " '10 scale',\n",
       " '10 score',\n",
       " '10 score is',\n",
       " '10 simply',\n",
       " '10 simply because',\n",
       " '10 stars',\n",
       " '10 to',\n",
       " '10 to in',\n",
       " '12',\n",
       " '12 years',\n",
       " '12 years ago',\n",
       " '13',\n",
       " '13 film',\n",
       " '13 film and',\n",
       " '13 rating',\n",
       " '13 rating certainly',\n",
       " '15',\n",
       " '15 minutes',\n",
       " '15 minutes of',\n",
       " '15pm',\n",
       " '15pm fast',\n",
       " '15pm fast forwarded',\n",
       " '17',\n",
       " '17 movie',\n",
       " '18th',\n",
       " '18th century',\n",
       " '18th century jutland',\n",
       " '1928',\n",
       " '1947',\n",
       " '1947 is',\n",
       " '1947 is masterpiece',\n",
       " '1948',\n",
       " '1948 is',\n",
       " '1948 is not',\n",
       " '1949',\n",
       " '1949 as',\n",
       " '1949 as hollywood',\n",
       " '1971',\n",
       " '1971 and',\n",
       " '1971 and the',\n",
       " '1973',\n",
       " '1973 when',\n",
       " '1973 when it',\n",
       " '1980',\n",
       " '1980 and',\n",
       " '1980 and the',\n",
       " '1986',\n",
       " '1986 version',\n",
       " '1986 version it',\n",
       " '1995',\n",
       " '1995 monster',\n",
       " '1995 monster movie',\n",
       " '1998',\n",
       " '1998 deep',\n",
       " '1998 deep impact',\n",
       " '20',\n",
       " '20 30',\n",
       " '20 30 40',\n",
       " '20 the',\n",
       " '20 the cover',\n",
       " '20 years',\n",
       " '20 years between',\n",
       " '2005',\n",
       " '2005 and',\n",
       " '2005 and began',\n",
       " '2006',\n",
       " '20th',\n",
       " '20th 2005',\n",
       " '20th 2005 and',\n",
       " '20th century',\n",
       " '20th century fox',\n",
       " '25',\n",
       " '25 years',\n",
       " '25 years earlier',\n",
       " '25 years was',\n",
       " '30',\n",
       " '30 40',\n",
       " '30 40 years',\n",
       " '30 minutes',\n",
       " '30 minutes of',\n",
       " '40',\n",
       " '40 years',\n",
       " '40 years down',\n",
       " '50',\n",
       " '50 to',\n",
       " '50 to see',\n",
       " '50 years',\n",
       " '54',\n",
       " '54 minutes',\n",
       " '54 minutes of',\n",
       " '70',\n",
       " '70000',\n",
       " '70000 times',\n",
       " '70s',\n",
       " '70s was',\n",
       " '70s was grainy',\n",
       " '80',\n",
       " '80 flicks',\n",
       " '80 flicks the',\n",
       " '80 wonderful',\n",
       " '80 wonderful years',\n",
       " '80s',\n",
       " '80s loved',\n",
       " '80s loved it',\n",
       " '8pm',\n",
       " '8pm started',\n",
       " '8pm started to',\n",
       " '90',\n",
       " '90 child',\n",
       " '90 child truly',\n",
       " '90 mainly',\n",
       " '90 mainly because',\n",
       " '90 minutes',\n",
       " '90 minutes back',\n",
       " '90 minutes of',\n",
       " '90 vibe',\n",
       " '90 vibe and',\n",
       " '95',\n",
       " '95 of',\n",
       " '95 of the',\n",
       " 'aailiyah',\n",
       " 'aailiyah was',\n",
       " 'aailiyah was pretty',\n",
       " 'abandoned',\n",
       " 'abandoned factory',\n",
       " 'abandoned factory ready',\n",
       " 'ability',\n",
       " 'ability of',\n",
       " 'ability of dwight',\n",
       " 'ability to',\n",
       " 'ability to meld',\n",
       " 'ability to pull',\n",
       " 'about',\n",
       " 'about 25',\n",
       " 'about 25 years',\n",
       " 'about 30',\n",
       " 'about 30 minutes',\n",
       " 'about 70000',\n",
       " 'about 70000 times',\n",
       " 'about an',\n",
       " 'about an author',\n",
       " 'about any',\n",
       " 'about any of',\n",
       " 'about awful',\n",
       " 'about awful do',\n",
       " 'about cover',\n",
       " 'about cover girl',\n",
       " 'about discovering',\n",
       " 'about discovering guilt',\n",
       " 'about distressed',\n",
       " 'about distressed drifting',\n",
       " 'about emptiness',\n",
       " 'about emptiness it',\n",
       " 'about everybody',\n",
       " 'about everybody parents',\n",
       " 'about everything',\n",
       " 'about everything to',\n",
       " 'about films',\n",
       " 'about films especially',\n",
       " 'about fort',\n",
       " 'about fort steele',\n",
       " 'about great',\n",
       " 'about great and',\n",
       " 'about half',\n",
       " 'about half way',\n",
       " 'about how',\n",
       " 'about how far',\n",
       " 'about how he',\n",
       " 'about human',\n",
       " 'about human traffic',\n",
       " 'about it',\n",
       " 'about it at',\n",
       " 'about it is',\n",
       " 'about it surface',\n",
       " 'about life',\n",
       " 'about loneliness',\n",
       " 'about loneliness and',\n",
       " 'about mishima',\n",
       " 'about mishima that',\n",
       " 'about musician',\n",
       " 'about musician hitchcock',\n",
       " 'about not',\n",
       " 'about not only',\n",
       " 'about nothing',\n",
       " 'about nothing just',\n",
       " 'about nurse',\n",
       " 'about nurse betty',\n",
       " 'about purity',\n",
       " 'about purity the',\n",
       " 'about raging',\n",
       " 'about raging cheekbones',\n",
       " 'about ten',\n",
       " 'about ten minutes',\n",
       " 'about the',\n",
       " 'about the acting',\n",
       " 'about the community',\n",
       " 'about the masculinity',\n",
       " 'about the movie',\n",
       " 'about the real',\n",
       " 'about the works',\n",
       " 'about them',\n",
       " 'about them the',\n",
       " 'about this',\n",
       " 'about this film',\n",
       " 'about this movie',\n",
       " 'about to',\n",
       " 'about to begin',\n",
       " 'about two',\n",
       " 'about two people',\n",
       " 'about where',\n",
       " 'about where he',\n",
       " 'about which',\n",
       " 'about which basically',\n",
       " 'about which one',\n",
       " 'about whiny',\n",
       " 'about whiny spoiled',\n",
       " 'about who',\n",
       " 'about who presents',\n",
       " 'above',\n",
       " 'above all',\n",
       " 'above all the',\n",
       " 'above the',\n",
       " 'above the script',\n",
       " 'abroad',\n",
       " 'abroad and',\n",
       " 'abroad and interacting',\n",
       " 'absolutely',\n",
       " 'absolutely abysmal',\n",
       " 'absolutely appalling',\n",
       " 'absolutely hilarious',\n",
       " 'absolutely hilarious to',\n",
       " 'absolutely is',\n",
       " 'absolutely is ray',\n",
       " 'absolutely loved',\n",
       " 'absolutely loved it',\n",
       " 'absolutely no',\n",
       " 'absolutely no suspense',\n",
       " 'absolutely no warmth',\n",
       " 'absolutely nothing',\n",
       " 'absolutely nothing whatsoever',\n",
       " 'absolutely recommend',\n",
       " 'absolutely recommend this',\n",
       " 'abstruse',\n",
       " 'abstruse culture',\n",
       " 'abstruse culture the',\n",
       " 'abysmal',\n",
       " 'abysmal everything',\n",
       " 'abysmal everything stinks',\n",
       " 'academy',\n",
       " 'academy award',\n",
       " 'accents',\n",
       " 'accents are',\n",
       " 'accents are absolutely',\n",
       " 'accessible',\n",
       " 'accessible films',\n",
       " 'acclaimed',\n",
       " 'acclaimed novella',\n",
       " 'acclaimed novella the',\n",
       " 'accolades',\n",
       " 'accolades especially',\n",
       " 'accolades especially when',\n",
       " 'accurate',\n",
       " 'accurate portrayal',\n",
       " 'accurate portrayal of',\n",
       " 'accurately',\n",
       " 'accurately defined',\n",
       " 'accurately defined as',\n",
       " 'accused',\n",
       " 'accused for',\n",
       " 'accused for the',\n",
       " 'accused of',\n",
       " 'accused of murdering',\n",
       " 'achievement',\n",
       " 'achievement as',\n",
       " 'achievement as so',\n",
       " 'achievement made',\n",
       " 'achievement made more',\n",
       " 'achille',\n",
       " 'achille and',\n",
       " 'achille and philippa',\n",
       " 'ackerman',\n",
       " 'ackerman and',\n",
       " 'ackerman and totally',\n",
       " 'act',\n",
       " 'act in',\n",
       " 'act in such',\n",
       " 'act one',\n",
       " 'act one of',\n",
       " 'acted',\n",
       " 'acted and',\n",
       " 'acted and done',\n",
       " 'acted and not',\n",
       " 'acting',\n",
       " 'acting ability',\n",
       " 'acting ability of',\n",
       " 'acting action',\n",
       " 'acting action or',\n",
       " 'acting alongside',\n",
       " 'acting alongside olivia',\n",
       " 'acting and',\n",
       " 'acting and bad',\n",
       " 'acting and decent',\n",
       " 'acting and effective',\n",
       " 'acting and look',\n",
       " 'acting as',\n",
       " 'acting as you',\n",
       " 'acting at',\n",
       " 'acting at least',\n",
       " 'acting by',\n",
       " 'acting by the',\n",
       " 'acting coach',\n",
       " 'acting coach are',\n",
       " 'acting especially',\n",
       " 'acting especially from',\n",
       " 'acting even',\n",
       " 'acting even that',\n",
       " 'acting from',\n",
       " 'acting from all',\n",
       " 'acting from its',\n",
       " 'acting from the',\n",
       " 'acting helps',\n",
       " 'acting helps the',\n",
       " 'acting is',\n",
       " 'acting is absolutely',\n",
       " 'acting is beyond',\n",
       " 'acting is blah',\n",
       " 'acting is fantastic',\n",
       " 'acting is like',\n",
       " 'acting is superb',\n",
       " 'acting is terrible',\n",
       " 'acting is utterly',\n",
       " 'acting make',\n",
       " 'acting make this',\n",
       " 'acting mess',\n",
       " 'acting mess of',\n",
       " 'acting post',\n",
       " 'acting post production',\n",
       " 'acting sucked',\n",
       " 'acting sucked the',\n",
       " 'acting sucks',\n",
       " 'acting sucks the',\n",
       " 'acting the',\n",
       " 'acting the better',\n",
       " 'acting the story',\n",
       " 'acting to',\n",
       " 'acting to cinematography',\n",
       " 'acting was',\n",
       " 'acting was as',\n",
       " 'acting was bad',\n",
       " 'acting was decidely',\n",
       " 'acting was poor',\n",
       " 'acting was skilled',\n",
       " 'acting was stanwyck',\n",
       " 'acting were',\n",
       " 'acting were weak',\n",
       " 'acting wise',\n",
       " 'acting wise either',\n",
       " 'action',\n",
       " 'action if',\n",
       " 'action if you',\n",
       " 'action more',\n",
       " 'action more suspense',\n",
       " 'action movie',\n",
       " 'action movie from',\n",
       " 'action movies',\n",
       " 'action movies ve',\n",
       " 'action or',\n",
       " 'action or location',\n",
       " 'action scenes',\n",
       " 'action scenes in',\n",
       " 'actions',\n",
       " 'actions for',\n",
       " 'actions for 90',\n",
       " 'actor',\n",
       " 'actor and',\n",
       " 'actor and grew',\n",
       " 'actor as',\n",
       " 'actor as he',\n",
       " 'actor enjoyed',\n",
       " 'actor enjoyed reading',\n",
       " 'actor gives',\n",
       " 'actor gives performance',\n",
       " 'actor on',\n",
       " 'actor on screen',\n",
       " 'actor playing',\n",
       " 'actor playing the',\n",
       " 'actor the',\n",
       " 'actor the scripting',\n",
       " 'actor who',\n",
       " 'actor who played',\n",
       " 'actors',\n",
       " 'actors agreed',\n",
       " 'actors agreed to',\n",
       " 'actors an',\n",
       " 'actors an ugly',\n",
       " 'actors and',\n",
       " 'actors and actresses',\n",
       " 'actors are',\n",
       " 'actors are more',\n",
       " 'actors around',\n",
       " 'actors awkwardly',\n",
       " 'actors awkwardly babbling',\n",
       " 'actors deliver',\n",
       " 'actors deliver their',\n",
       " 'actors give',\n",
       " 'actors give wonderful',\n",
       " 'actors like',\n",
       " 'actors like thomerson',\n",
       " 'actors master',\n",
       " 'actors master director',\n",
       " 'actors now',\n",
       " 'actors now have',\n",
       " 'actors on',\n",
       " 'actors on the',\n",
       " 'actors period',\n",
       " 'actors telly',\n",
       " 'actors telly savalas',\n",
       " 'actors truly',\n",
       " 'actors truly understand',\n",
       " 'actors who',\n",
       " 'actors who haven',\n",
       " 'actors you',\n",
       " 'actors you can',\n",
       " 'actress',\n",
       " 'actress has',\n",
       " 'actress has been',\n",
       " 'actress repeating',\n",
       " 'actress repeating her',\n",
       " 'actresses',\n",
       " 'actresses and',\n",
       " 'actresses and think',\n",
       " 'actresses playing',\n",
       " 'actresses playing anne',\n",
       " 'actresses were',\n",
       " 'actresses were bonus',\n",
       " 'actually',\n",
       " 'actually contributing',\n",
       " 'actually contributing to',\n",
       " 'actually gets',\n",
       " 'actually gets from',\n",
       " 'actually has',\n",
       " 'actually has lot',\n",
       " 'actually is',\n",
       " 'actually pretty',\n",
       " 'actually pretty cool',\n",
       " 'actually the',\n",
       " 'actually the graphics',\n",
       " 'actually turned',\n",
       " 'actually turned out',\n",
       " 'actually very',\n",
       " 'actually very smart',\n",
       " 'actually was',\n",
       " 'actually worth',\n",
       " 'actually worth seeing',\n",
       " 'adams',\n",
       " 'adams unfortunate',\n",
       " 'adams unfortunate life',\n",
       " 'adaptation',\n",
       " 'adaptation of',\n",
       " 'adaptation of james',\n",
       " 'adaptation of the',\n",
       " 'add',\n",
       " 'add betty',\n",
       " 'add betty white',\n",
       " 'added',\n",
       " 'added bonuses',\n",
       " 'addition',\n",
       " 'addition of',\n",
       " 'addition of new',\n",
       " 'addition to',\n",
       " 'addition to having',\n",
       " 'addition to the',\n",
       " 'admins',\n",
       " 'admiration',\n",
       " 'admiration of',\n",
       " 'admiration of swords',\n",
       " 'admitted',\n",
       " 'admitted elsewhere',\n",
       " 'adorable',\n",
       " 'adorable his',\n",
       " 'adorable his little',\n",
       " 'adorable seeing',\n",
       " 'adorable seeing mickey',\n",
       " 'adorable the',\n",
       " 'adorable the junkyard',\n",
       " 'adrift',\n",
       " 'adrift and',\n",
       " 'adrift and stagy',\n",
       " 'adventure',\n",
       " 'adventure at',\n",
       " 'adventure at its',\n",
       " 'advise',\n",
       " 'advise anyone',\n",
       " 'advise anyone to',\n",
       " 'advise you',\n",
       " 'advise you to',\n",
       " 'aerial',\n",
       " 'aerial bombardments',\n",
       " 'aerial bombardments of',\n",
       " 'aerial scenes',\n",
       " 'aerial scenes that',\n",
       " 'aerial scenes were',\n",
       " 'aesthetically',\n",
       " 'aesthetically like',\n",
       " 'aesthetically like sculpture',\n",
       " 'affected',\n",
       " 'affected more',\n",
       " 'affected more so',\n",
       " 'affleck',\n",
       " 'affleck and',\n",
       " 'affleck and sandra',\n",
       " 'afraid',\n",
       " 'afraid of',\n",
       " 'afraid of subtitles',\n",
       " 'afraid to',\n",
       " 'afraid to go',\n",
       " 'africa',\n",
       " 'africa understand',\n",
       " 'africa understand its',\n",
       " 'after',\n",
       " 'after 80',\n",
       " 'after 80 wonderful',\n",
       " 'after about',\n",
       " 'after about 25',\n",
       " 'after all',\n",
       " 'after all that',\n",
       " 'after cotton',\n",
       " 'after cotton club',\n",
       " 'after finally',\n",
       " 'after finally watching',\n",
       " 'after jamie',\n",
       " 'after jamie foxx',\n",
       " 'after ready',\n",
       " 'after ready the',\n",
       " 'after reporter',\n",
       " 'after reporter who',\n",
       " 'after scene',\n",
       " 'after scene passed',\n",
       " 'after seeing',\n",
       " 'after seeing movie',\n",
       " 'after seeing the',\n",
       " 'after the',\n",
       " 'after the vision',\n",
       " 'after watching',\n",
       " 'after watching this',\n",
       " 'afternoon',\n",
       " 'afternoon to',\n",
       " 'afternoon to punish',\n",
       " 'again',\n",
       " 'again after',\n",
       " 'again after about',\n",
       " 'again bad',\n",
       " 'again bad rating',\n",
       " 'again for',\n",
       " 'again for free',\n",
       " 'again lame',\n",
       " 'again lame here',\n",
       " 'again no',\n",
       " 'again no plot',\n",
       " 'again on',\n",
       " 'again on dvd',\n",
       " 'again on to',\n",
       " 'again this',\n",
       " 'again this is',\n",
       " 'again two',\n",
       " 'again two sundays',\n",
       " 'against',\n",
       " 'against any',\n",
       " 'against any movie',\n",
       " 'age',\n",
       " 'age appropriate',\n",
       " 'age john',\n",
       " 'age john wayne',\n",
       " 'aged',\n",
       " 'aged upper',\n",
       " 'aged upper class',\n",
       " 'ages',\n",
       " 'ages although',\n",
       " 'ages although the',\n",
       " 'ago',\n",
       " 'ago march',\n",
       " 'ago march 20th',\n",
       " 'agree',\n",
       " 'agree with',\n",
       " 'agree with jessica',\n",
       " 'agreed',\n",
       " 'agreed to',\n",
       " 'agreed to do',\n",
       " 'aimless',\n",
       " 'aimless movie',\n",
       " 'aimless movie about',\n",
       " 'air',\n",
       " 'air force',\n",
       " 'air force one',\n",
       " 'air it',\n",
       " 'air it enough',\n",
       " 'aired',\n",
       " 'aired this',\n",
       " 'aired this dribble',\n",
       " 'akasha',\n",
       " 'akasha in',\n",
       " 'akasha in places',\n",
       " 'akin',\n",
       " 'akin to',\n",
       " 'akin to torture',\n",
       " 'alert',\n",
       " 'alert as',\n",
       " 'alert as try',\n",
       " 'alexander',\n",
       " 'alexander nevsky',\n",
       " 'alexander nevsky is',\n",
       " 'alexander yardley',\n",
       " 'alexander yardley character',\n",
       " 'alike',\n",
       " 'all',\n",
       " 'all ages',\n",
       " 'all ages although',\n",
       " 'all and',\n",
       " 'all and the',\n",
       " 'all angles',\n",
       " 'all beautiful',\n",
       " 'all beautiful directed',\n",
       " 'all cardboard',\n",
       " 'all cardboard cutouts',\n",
       " 'all costs',\n",
       " 'all costs at',\n",
       " 'all costs don',\n",
       " 'all end',\n",
       " 'all end all',\n",
       " 'all extant',\n",
       " 'all extant films',\n",
       " 'all for',\n",
       " 'all for artistic',\n",
       " 'all funny',\n",
       " 'all funny and',\n",
       " 'all give',\n",
       " 'all give this',\n",
       " 'all great',\n",
       " 'all great disappointment',\n",
       " 'all horror',\n",
       " 'all horror movies',\n",
       " 'all in',\n",
       " 'all in all',\n",
       " 'all involved',\n",
       " 'all involved and',\n",
       " 'all it',\n",
       " 'all it was',\n",
       " 'all its',\n",
       " 'all its an',\n",
       " 'all just',\n",
       " 'all just one',\n",
       " 'all of',\n",
       " 'all of brainsucking',\n",
       " 'all of the',\n",
       " 'all of them',\n",
       " 'all of this',\n",
       " 'all references',\n",
       " 'all references are',\n",
       " 'all right',\n",
       " 'all round',\n",
       " 'all shakespear',\n",
       " 'all shakespear fans',\n",
       " 'all star',\n",
       " 'all star cast',\n",
       " 'all study',\n",
       " 'all study of',\n",
       " 'all suggest',\n",
       " 'all suggest natural',\n",
       " 'all that',\n",
       " 'all that is',\n",
       " 'all that memorable',\n",
       " 'all that we',\n",
       " 'all the',\n",
       " 'all the actors',\n",
       " 'all the animals',\n",
       " 'all the characters',\n",
       " 'all the cheap',\n",
       " 'all the exquisite',\n",
       " 'all the junkyard',\n",
       " 'all the pretty',\n",
       " 'all the problems',\n",
       " 'all the time',\n",
       " 'all the way',\n",
       " 'all there',\n",
       " 'all there are',\n",
       " 'all these',\n",
       " 'all these intangibles',\n",
       " 'all these slackers',\n",
       " 'all things',\n",
       " 'all things considered',\n",
       " 'all this',\n",
       " 'all this movie',\n",
       " 'all time',\n",
       " 'all time kieslowski',\n",
       " 'all to',\n",
       " 'all to recommend',\n",
       " 'all wrong',\n",
       " 'all you',\n",
       " 'all you see',\n",
       " 'allison',\n",
       " 'allison in',\n",
       " 'allison in this',\n",
       " 'allow',\n",
       " 'allowing',\n",
       " 'allowing for',\n",
       " 'allowing for poor',\n",
       " 'almost',\n",
       " 'almost all',\n",
       " 'almost all of',\n",
       " 'almost always',\n",
       " 'almost always in',\n",
       " 'almost everyone',\n",
       " 'almost everyone involved',\n",
       " 'almost no',\n",
       " 'almost no action',\n",
       " 'almost non',\n",
       " 'almost non existent',\n",
       " 'almost right',\n",
       " 'almost right in',\n",
       " 'almost unbearable',\n",
       " 'almost unbearable to',\n",
       " 'almost unrecognizable',\n",
       " 'almost unrecognizable to',\n",
       " 'along',\n",
       " 'along to',\n",
       " 'along to its',\n",
       " 'along very',\n",
       " 'along very well',\n",
       " 'along with',\n",
       " 'along with the',\n",
       " 'alongside',\n",
       " 'alongside olivia',\n",
       " 'alongside olivia de',\n",
       " 'already',\n",
       " 'already and',\n",
       " 'already and probably',\n",
       " 'already have',\n",
       " 'already have it',\n",
       " 'already know',\n",
       " 'already know racism',\n",
       " 'already seen',\n",
       " 'already seen one',\n",
       " 'also',\n",
       " 'also annoying',\n",
       " 'also boasts',\n",
       " 'also boasts one',\n",
       " 'also both',\n",
       " 'also both funny',\n",
       " 'also enough',\n",
       " 'also enough hypocrisy',\n",
       " 'also found',\n",
       " 'also found myself',\n",
       " 'also great',\n",
       " 'also great directing',\n",
       " 'also great to',\n",
       " 'also horrible',\n",
       " 'also horrible cause',\n",
       " 'also in',\n",
       " 'also in the',\n",
       " 'also it',\n",
       " 'also it real',\n",
       " 'also lacked',\n",
       " 'also lacked in',\n",
       " 'also makes',\n",
       " 'also makes her',\n",
       " 'also managed',\n",
       " 'also managed to',\n",
       " 'also marred',\n",
       " 'also marred with',\n",
       " 'also not',\n",
       " 'also not bad',\n",
       " 'also notable',\n",
       " 'also notable is',\n",
       " 'also play',\n",
       " 'also play well',\n",
       " 'also produced',\n",
       " 'also produced and',\n",
       " 'also revealing',\n",
       " 'also the',\n",
       " 'also the music',\n",
       " 'also the right',\n",
       " 'also the story',\n",
       " 'also turns',\n",
       " 'also turns in',\n",
       " 'also very',\n",
       " 'also very good',\n",
       " 'also wrote',\n",
       " 'also wrote directed',\n",
       " 'although',\n",
       " 'although he',\n",
       " 'although he never',\n",
       " 'although the',\n",
       " 'although the circumstances',\n",
       " 'although the younger',\n",
       " 'always',\n",
       " 'always entertaining',\n",
       " 'always entertaining as',\n",
       " 'always good',\n",
       " 'always good as',\n",
       " 'always in',\n",
       " 'always in olde',\n",
       " 'always known',\n",
       " 'always known that',\n",
       " 'am',\n",
       " 'am director',\n",
       " 'am director but',\n",
       " 'am fan',\n",
       " 'am fan of',\n",
       " 'am giving',\n",
       " 'am giving it',\n",
       " 'am here',\n",
       " 'am here to',\n",
       " 'am not',\n",
       " 'am not filmmaker',\n",
       " 'am simplifying',\n",
       " 'am simplifying things',\n",
       " 'am so',\n",
       " 'am so pleased',\n",
       " 'am so thrilled',\n",
       " 'am so tired',\n",
       " 'amateurish',\n",
       " 'amateurish films',\n",
       " 'amateurish films when',\n",
       " 'amaze',\n",
       " 'amaze me',\n",
       " 'amaze me he',\n",
       " 'amazed',\n",
       " 'amazed at',\n",
       " 'amazed at how',\n",
       " 'amazing',\n",
       " 'amazing dee',\n",
       " 'amazing dee snider',\n",
       " 'amazing dialog',\n",
       " 'amazing dialog about',\n",
       " 'amazing film',\n",
       " 'amazing film and',\n",
       " 'amazing film artist',\n",
       " 'amazing finale',\n",
       " 'amazing finale to',\n",
       " 'amazing job',\n",
       " 'amazing performances',\n",
       " 'amazing performances of',\n",
       " 'amazing stylized',\n",
       " 'amazing stylized beautiful',\n",
       " 'amazing the',\n",
       " 'amazing the best',\n",
       " 'amazingly',\n",
       " 'amazingly important',\n",
       " 'amazingly important film',\n",
       " 'america',\n",
       " 'america own',\n",
       " 'america own imperial',\n",
       " 'american',\n",
       " 'american justice',\n",
       " 'american justice system',\n",
       " 'american propaganda',\n",
       " 'americans',\n",
       " 'americans brain',\n",
       " 'americans brain eating',\n",
       " 'americans it',\n",
       " 'americans it is',\n",
       " 'among',\n",
       " 'among males',\n",
       " 'among males and',\n",
       " 'among mickey',\n",
       " 'among mickey best',\n",
       " 'amount',\n",
       " 'amount of',\n",
       " 'amount of deadpan',\n",
       " 'amount of fumbling',\n",
       " 'amount of money',\n",
       " 'amount of puzzle',\n",
       " 'amount of weight',\n",
       " 'amusing',\n",
       " 'an',\n",
       " 'an abandoned',\n",
       " 'an abandoned factory',\n",
       " 'an achievement',\n",
       " 'an achievement as',\n",
       " 'an all',\n",
       " 'an all star',\n",
       " 'an amazing',\n",
       " 'an amazing film',\n",
       " 'an amazing finale',\n",
       " 'an amazing job',\n",
       " 'an amazingly',\n",
       " 'an amazingly important',\n",
       " 'an art',\n",
       " 'an art movie',\n",
       " 'an audience',\n",
       " 'an audience with',\n",
       " 'an author',\n",
       " 'an author living',\n",
       " 'an awesome',\n",
       " 'an awesome movie',\n",
       " 'an embassy',\n",
       " 'an embassy function',\n",
       " 'an empty',\n",
       " 'an empty hollow',\n",
       " 'an ending',\n",
       " 'an ending that',\n",
       " 'an example',\n",
       " 'an example of',\n",
       " 'an excellent',\n",
       " 'an excellent drama',\n",
       " 'an excellent film',\n",
       " 'an excellent job',\n",
       " 'an excellent performance',\n",
       " 'an excellent thriller',\n",
       " 'an excellent verbal',\n",
       " 'an exceptional',\n",
       " 'an exceptional actor',\n",
       " 'an extraordinary',\n",
       " 'an extraordinary film',\n",
       " 'an eye',\n",
       " 'an eye pleasing',\n",
       " 'an hour',\n",
       " 'an hour and',\n",
       " 'an idea',\n",
       " 'an idea that',\n",
       " 'an implausible',\n",
       " 'an implausible unmitigated',\n",
       " 'an incredible',\n",
       " 'an incredible job',\n",
       " 'an incredibly',\n",
       " 'an incredibly weak',\n",
       " 'an indication',\n",
       " 'an indication of',\n",
       " 'an indictment',\n",
       " 'an indictment on',\n",
       " 'an indie',\n",
       " 'an indie flick',\n",
       " 'an insane',\n",
       " 'an insane game',\n",
       " 'an inspiration',\n",
       " 'an inspiration to',\n",
       " 'an instant',\n",
       " 'an instant classic',\n",
       " 'an insulin',\n",
       " 'an insulin dependant',\n",
       " 'an insult',\n",
       " 'an insult to',\n",
       " 'an integral',\n",
       " 'an integral element',\n",
       " 'an intense',\n",
       " 'an intense experience',\n",
       " 'an interesting',\n",
       " 'an interesting premise',\n",
       " 'an interesting way',\n",
       " 'an italian',\n",
       " 'an italian reviewer',\n",
       " 'an obviously',\n",
       " 'an obviously meagre',\n",
       " 'an outlandish',\n",
       " 'an outlandish array',\n",
       " 'an ugly',\n",
       " 'an ugly cartoon',\n",
       " 'an ultra',\n",
       " 'an ultra cheap',\n",
       " 'an unpredictable',\n",
       " 'an unpredictable youthful',\n",
       " 'an unsatisfactory',\n",
       " 'an unsatisfactory experience',\n",
       " 'an uplifting',\n",
       " 'an uplifting ending',\n",
       " 'anatomist',\n",
       " 'anatomist doctor',\n",
       " 'anatomist doctor quinn',\n",
       " 'and',\n",
       " 'and ability',\n",
       " 'and ability to',\n",
       " 'and absolutely',\n",
       " 'and absolutely loved',\n",
       " 'and absolutely recommend',\n",
       " 'and accolades',\n",
       " 'and accolades especially',\n",
       " 'and acting',\n",
       " 'and acting were',\n",
       " 'and actresses',\n",
       " 'and actresses were',\n",
       " ...]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ngrams.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24445"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Ngrams.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1639)\t1\n",
      "  (0, 3037)\t1\n",
      "  (0, 786)\t1\n",
      "  (0, 748)\t1\n",
      "  (0, 37)\t1\n",
      "  (0, 1748)\t1\n",
      "  (0, 92)\t1\n",
      "  (0, 1750)\t1\n",
      "  (0, 2404)\t1\n",
      "  (0, 2871)\t3\n",
      "  (1, 1875)\t1\n",
      "  (1, 2905)\t1\n",
      "  (1, 2969)\t1\n",
      "  (1, 1837)\t1\n",
      "  (1, 1206)\t1\n",
      "  (1, 1777)\t1\n",
      "  (1, 196)\t1\n",
      "  (1, 1862)\t1\n",
      "  (1, 431)\t1\n",
      "  (1, 1035)\t1\n",
      "  (1, 2638)\t2\n",
      "  (1, 1605)\t1\n",
      "  (1, 1733)\t1\n",
      "  (1, 2917)\t1\n",
      "  (1, 2965)\t1\n",
      "  :\t:\n",
      "  (744, 1852)\t1\n",
      "  (744, 2658)\t1\n",
      "  (744, 1358)\t1\n",
      "  (744, 1605)\t1\n",
      "  (744, 2917)\t1\n",
      "  (745, 837)\t1\n",
      "  (745, 3001)\t1\n",
      "  (745, 1428)\t1\n",
      "  (745, 1423)\t1\n",
      "  (745, 1358)\t1\n",
      "  (746, 911)\t1\n",
      "  (746, 222)\t1\n",
      "  (747, 1393)\t1\n",
      "  (747, 1397)\t1\n",
      "  (747, 1316)\t1\n",
      "  (747, 1430)\t1\n",
      "  (747, 1725)\t1\n",
      "  (747, 2921)\t1\n",
      "  (747, 123)\t1\n",
      "  (747, 1854)\t1\n",
      "  (747, 100)\t2\n",
      "  (747, 1358)\t1\n",
      "  (747, 2694)\t1\n",
      "  (747, 125)\t1\n",
      "  (747, 1837)\t1\n"
     ]
    }
   ],
   "source": [
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 5762)\t1\n",
      "  (0, 5487)\t1\n",
      "  (0, 170)\t1\n",
      "  (0, 13015)\t1\n",
      "  (0, 610)\t1\n",
      "  (0, 13287)\t1\n",
      "  (0, 17708)\t1\n",
      "  (0, 22444)\t1\n",
      "  (0, 22460)\t1\n",
      "  (0, 22461)\t1\n",
      "  (0, 24381)\t1\n",
      "  (0, 5761)\t1\n",
      "  (0, 5486)\t1\n",
      "  (0, 169)\t1\n",
      "  (0, 13013)\t1\n",
      "  (0, 609)\t1\n",
      "  (0, 13286)\t1\n",
      "  (0, 17707)\t1\n",
      "  (0, 22443)\t1\n",
      "  (0, 22458)\t2\n",
      "  (0, 12389)\t1\n",
      "  (0, 24376)\t1\n",
      "  (0, 5760)\t1\n",
      "  (0, 5485)\t1\n",
      "  (0, 152)\t1\n",
      "  :\t:\n",
      "  (747, 21426)\t1\n",
      "  (747, 11023)\t1\n",
      "  (747, 667)\t1\n",
      "  (747, 961)\t1\n",
      "  (747, 9957)\t1\n",
      "  (747, 960)\t1\n",
      "  (747, 9952)\t1\n",
      "  (747, 9970)\t1\n",
      "  (747, 9969)\t1\n",
      "  (747, 9372)\t1\n",
      "  (747, 22932)\t1\n",
      "  (747, 662)\t1\n",
      "  (747, 661)\t1\n",
      "  (747, 14204)\t1\n",
      "  (747, 11020)\t1\n",
      "  (747, 12822)\t1\n",
      "  (747, 22931)\t1\n",
      "  (747, 894)\t1\n",
      "  (747, 14664)\t1\n",
      "  (747, 9596)\t1\n",
      "  (747, 634)\t2\n",
      "  (747, 9583)\t1\n",
      "  (747, 21222)\t1\n",
      "  (747, 988)\t1\n",
      "  (747, 13986)\t1\n"
     ]
    }
   ],
   "source": [
    "print(NgramFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFIDF = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFIDFfeatures = TFIDF.fit_transform(np.asarray(Data.Text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(TFIDFfeatures.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFIDFngrams = TfidfVectorizer(ngram_range=(1,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFIDFngamFeatures = TFIDFngrams.fit_transform(np.asarray(Data.Text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(748, 35845)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(TFIDFngamFeatures.todense()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10',\n",
       " '10 10',\n",
       " '10 an',\n",
       " '10 an amazing',\n",
       " '10 an amazing finale',\n",
       " '10 and',\n",
       " '10 and only',\n",
       " '10 and only because',\n",
       " '10 do',\n",
       " '10 do think',\n",
       " '10 do think tom',\n",
       " '10 feet',\n",
       " '10 feet wide',\n",
       " '10 feet wide of',\n",
       " '10 for',\n",
       " '10 for both',\n",
       " '10 for both the',\n",
       " '10 grade',\n",
       " '10 grade note',\n",
       " '10 grade note the',\n",
       " '10 on',\n",
       " '10 on my',\n",
       " '10 on my oy',\n",
       " '10 out',\n",
       " '10 out of',\n",
       " '10 out of 10',\n",
       " '10 plus',\n",
       " '10 plus if',\n",
       " '10 plus if could',\n",
       " '10 scale',\n",
       " '10 score',\n",
       " '10 score is',\n",
       " '10 score is mostly',\n",
       " '10 simply',\n",
       " '10 simply because',\n",
       " '10 simply because there',\n",
       " '10 stars',\n",
       " '10 to',\n",
       " '10 to in',\n",
       " '10 to in years',\n",
       " '12',\n",
       " '12 years',\n",
       " '12 years ago',\n",
       " '13',\n",
       " '13 film',\n",
       " '13 film and',\n",
       " '13 film and make',\n",
       " '13 rating',\n",
       " '13 rating certainly',\n",
       " '13 rating certainly won',\n",
       " '15',\n",
       " '15 minutes',\n",
       " '15 minutes of',\n",
       " '15 minutes of movie',\n",
       " '15pm',\n",
       " '15pm fast',\n",
       " '15pm fast forwarded',\n",
       " '15pm fast forwarded the',\n",
       " '17',\n",
       " '17 movie',\n",
       " '18th',\n",
       " '18th century',\n",
       " '18th century jutland',\n",
       " '18th century jutland and',\n",
       " '1928',\n",
       " '1947',\n",
       " '1947 is',\n",
       " '1947 is masterpiece',\n",
       " '1948',\n",
       " '1948 is',\n",
       " '1948 is not',\n",
       " '1948 is not only',\n",
       " '1949',\n",
       " '1949 as',\n",
       " '1949 as hollywood',\n",
       " '1949 as hollywood generally',\n",
       " '1971',\n",
       " '1971 and',\n",
       " '1971 and the',\n",
       " '1971 and the format',\n",
       " '1973',\n",
       " '1973 when',\n",
       " '1973 when it',\n",
       " '1973 when it was',\n",
       " '1980',\n",
       " '1980 and',\n",
       " '1980 and the',\n",
       " '1980 and the experiences',\n",
       " '1986',\n",
       " '1986 version',\n",
       " '1986 version it',\n",
       " '1986 version it was',\n",
       " '1995',\n",
       " '1995 monster',\n",
       " '1995 monster movie',\n",
       " '1995 monster movie grim',\n",
       " '1998',\n",
       " '1998 deep',\n",
       " '1998 deep impact',\n",
       " '1998 deep impact and',\n",
       " '20',\n",
       " '20 30',\n",
       " '20 30 40',\n",
       " '20 30 40 years',\n",
       " '20 the',\n",
       " '20 the cover',\n",
       " '20 the cover has',\n",
       " '20 years',\n",
       " '20 years between',\n",
       " '20 years between his',\n",
       " '2005',\n",
       " '2005 and',\n",
       " '2005 and began',\n",
       " '2005 and began to',\n",
       " '2006',\n",
       " '20th',\n",
       " '20th 2005',\n",
       " '20th 2005 and',\n",
       " '20th 2005 and began',\n",
       " '20th century',\n",
       " '20th century fox',\n",
       " '20th century fox road',\n",
       " '25',\n",
       " '25 years',\n",
       " '25 years earlier',\n",
       " '25 years earlier really',\n",
       " '25 years was',\n",
       " '25 years was amazed',\n",
       " '30',\n",
       " '30 40',\n",
       " '30 40 years',\n",
       " '30 40 years down',\n",
       " '30 minutes',\n",
       " '30 minutes of',\n",
       " '30 minutes of footage',\n",
       " '40',\n",
       " '40 years',\n",
       " '40 years down',\n",
       " '40 years down the',\n",
       " '50',\n",
       " '50 to',\n",
       " '50 to see',\n",
       " '50 to see this',\n",
       " '50 years',\n",
       " '54',\n",
       " '54 minutes',\n",
       " '54 minutes of',\n",
       " '54 minutes of sheer',\n",
       " '70',\n",
       " '70000',\n",
       " '70000 times',\n",
       " '70s',\n",
       " '70s was',\n",
       " '70s was grainy',\n",
       " '70s was grainy but',\n",
       " '80',\n",
       " '80 flicks',\n",
       " '80 flicks the',\n",
       " '80 flicks the story',\n",
       " '80 wonderful',\n",
       " '80 wonderful years',\n",
       " '80s',\n",
       " '80s loved',\n",
       " '80s loved it',\n",
       " '80s loved it was',\n",
       " '8pm',\n",
       " '8pm started',\n",
       " '8pm started to',\n",
       " '8pm started to watch',\n",
       " '90',\n",
       " '90 child',\n",
       " '90 child truly',\n",
       " '90 child truly enjoyed',\n",
       " '90 mainly',\n",
       " '90 mainly because',\n",
       " '90 mainly because it',\n",
       " '90 minutes',\n",
       " '90 minutes back',\n",
       " '90 minutes of',\n",
       " '90 minutes of utter',\n",
       " '90 vibe',\n",
       " '90 vibe and',\n",
       " '90 vibe and delivered',\n",
       " '95',\n",
       " '95 of',\n",
       " '95 of the',\n",
       " '95 of the garbage',\n",
       " 'aailiyah',\n",
       " 'aailiyah was',\n",
       " 'aailiyah was pretty',\n",
       " 'aailiyah was pretty good',\n",
       " 'abandoned',\n",
       " 'abandoned factory',\n",
       " 'abandoned factory ready',\n",
       " 'abandoned factory ready for',\n",
       " 'ability',\n",
       " 'ability of',\n",
       " 'ability of dwight',\n",
       " 'ability of dwight schultz',\n",
       " 'ability to',\n",
       " 'ability to meld',\n",
       " 'ability to meld two',\n",
       " 'ability to pull',\n",
       " 'ability to pull off',\n",
       " 'about',\n",
       " 'about 25',\n",
       " 'about 25 years',\n",
       " 'about 25 years was',\n",
       " 'about 30',\n",
       " 'about 30 minutes',\n",
       " 'about 30 minutes of',\n",
       " 'about 70000',\n",
       " 'about 70000 times',\n",
       " 'about an',\n",
       " 'about an author',\n",
       " 'about an author living',\n",
       " 'about any',\n",
       " 'about any of',\n",
       " 'about any of this',\n",
       " 'about awful',\n",
       " 'about awful do',\n",
       " 'about awful do not',\n",
       " 'about cover',\n",
       " 'about cover girl',\n",
       " 'about cover girl is',\n",
       " 'about discovering',\n",
       " 'about discovering guilt',\n",
       " 'about discovering guilt or',\n",
       " 'about distressed',\n",
       " 'about distressed drifting',\n",
       " 'about distressed drifting young',\n",
       " 'about emptiness',\n",
       " 'about emptiness it',\n",
       " 'about emptiness it works',\n",
       " 'about everybody',\n",
       " 'about everybody parents',\n",
       " 'about everybody parents kids',\n",
       " 'about everything',\n",
       " 'about everything to',\n",
       " 'about everything to stay',\n",
       " 'about films',\n",
       " 'about films especially',\n",
       " 'about films especially those',\n",
       " 'about fort',\n",
       " 'about fort steele',\n",
       " 'about fort steele just',\n",
       " 'about great',\n",
       " 'about great and',\n",
       " 'about great and unconditional',\n",
       " 'about half',\n",
       " 'about half way',\n",
       " 'about half way through',\n",
       " 'about how',\n",
       " 'about how far',\n",
       " 'about how far race',\n",
       " 'about how he',\n",
       " 'about how he became',\n",
       " 'about human',\n",
       " 'about human traffic',\n",
       " 'about it',\n",
       " 'about it at',\n",
       " 'about it at all',\n",
       " 'about it is',\n",
       " 'about it is just',\n",
       " 'about it surface',\n",
       " 'about it surface is',\n",
       " 'about life',\n",
       " 'about loneliness',\n",
       " 'about loneliness and',\n",
       " 'about loneliness and tony',\n",
       " 'about mishima',\n",
       " 'about mishima that',\n",
       " 'about mishima that is',\n",
       " 'about musician',\n",
       " 'about musician hitchcock',\n",
       " 'about musician hitchcock is',\n",
       " 'about not',\n",
       " 'about not only',\n",
       " 'about not only whether',\n",
       " 'about nothing',\n",
       " 'about nothing just',\n",
       " 'about nothing just pretext',\n",
       " 'about nurse',\n",
       " 'about nurse betty',\n",
       " 'about nurse betty is',\n",
       " 'about purity',\n",
       " 'about purity the',\n",
       " 'about purity the admiration',\n",
       " 'about raging',\n",
       " 'about raging cheekbones',\n",
       " 'about ten',\n",
       " 'about ten minutes',\n",
       " 'about ten minutes into',\n",
       " 'about the',\n",
       " 'about the acting',\n",
       " 'about the acting the',\n",
       " 'about the community',\n",
       " 'about the community it',\n",
       " 'about the masculinity',\n",
       " 'about the masculinity they',\n",
       " 'about the movie',\n",
       " 'about the movie business',\n",
       " 'about the real',\n",
       " 'about the real inside',\n",
       " 'about the works',\n",
       " 'about the works of',\n",
       " 'about them',\n",
       " 'about them the',\n",
       " 'about them the longer',\n",
       " 'about this',\n",
       " 'about this film',\n",
       " 'about this film is',\n",
       " 'about this movie',\n",
       " 'about this movie but',\n",
       " 'about this movie is',\n",
       " 'about to',\n",
       " 'about to begin',\n",
       " 'about to begin but',\n",
       " 'about two',\n",
       " 'about two people',\n",
       " 'about two people chasing',\n",
       " 'about where',\n",
       " 'about where he',\n",
       " 'about where he spend',\n",
       " 'about which',\n",
       " 'about which basically',\n",
       " 'about which basically involves',\n",
       " 'about which one',\n",
       " 'about which one might',\n",
       " 'about whiny',\n",
       " 'about whiny spoiled',\n",
       " 'about whiny spoiled brat',\n",
       " 'about who',\n",
       " 'about who presents',\n",
       " 'about who presents better',\n",
       " 'above',\n",
       " 'above all',\n",
       " 'above all the',\n",
       " 'above all the exquisite',\n",
       " 'above the',\n",
       " 'above the script',\n",
       " 'above the script which',\n",
       " 'abroad',\n",
       " 'abroad and',\n",
       " 'abroad and interacting',\n",
       " 'abroad and interacting with',\n",
       " 'absolutely',\n",
       " 'absolutely abysmal',\n",
       " 'absolutely appalling',\n",
       " 'absolutely hilarious',\n",
       " 'absolutely hilarious to',\n",
       " 'absolutely hilarious to watch',\n",
       " 'absolutely is',\n",
       " 'absolutely is ray',\n",
       " 'absolutely is ray charles',\n",
       " 'absolutely loved',\n",
       " 'absolutely loved it',\n",
       " 'absolutely no',\n",
       " 'absolutely no suspense',\n",
       " 'absolutely no suspense or',\n",
       " 'absolutely no warmth',\n",
       " 'absolutely no warmth or',\n",
       " 'absolutely nothing',\n",
       " 'absolutely nothing whatsoever',\n",
       " 'absolutely recommend',\n",
       " 'absolutely recommend this',\n",
       " 'absolutely recommend this movie',\n",
       " 'abstruse',\n",
       " 'abstruse culture',\n",
       " 'abstruse culture the',\n",
       " 'abstruse culture the flat',\n",
       " 'abysmal',\n",
       " 'abysmal everything',\n",
       " 'abysmal everything stinks',\n",
       " 'abysmal everything stinks trouble',\n",
       " 'academy',\n",
       " 'academy award',\n",
       " 'accents',\n",
       " 'accents are',\n",
       " 'accents are absolutely',\n",
       " 'accents are absolutely abysmal',\n",
       " 'accessible',\n",
       " 'accessible films',\n",
       " 'acclaimed',\n",
       " 'acclaimed novella',\n",
       " 'acclaimed novella the',\n",
       " 'acclaimed novella the dead',\n",
       " 'accolades',\n",
       " 'accolades especially',\n",
       " 'accolades especially when',\n",
       " 'accolades especially when there',\n",
       " 'accurate',\n",
       " 'accurate portrayal',\n",
       " 'accurate portrayal of',\n",
       " 'accurate portrayal of the',\n",
       " 'accurately',\n",
       " 'accurately defined',\n",
       " 'accurately defined as',\n",
       " 'accurately defined as pretentious',\n",
       " 'accused',\n",
       " 'accused for',\n",
       " 'accused for the',\n",
       " 'accused for the murder',\n",
       " 'accused of',\n",
       " 'accused of murdering',\n",
       " 'accused of murdering white',\n",
       " 'achievement',\n",
       " 'achievement as',\n",
       " 'achievement as so',\n",
       " 'achievement as so bad',\n",
       " 'achievement made',\n",
       " 'achievement made more',\n",
       " 'achievement made more timely',\n",
       " 'achille',\n",
       " 'achille and',\n",
       " 'achille and philippa',\n",
       " 'achille and philippa beautifully',\n",
       " 'ackerman',\n",
       " 'ackerman and',\n",
       " 'ackerman and totally',\n",
       " 'ackerman and totally believable',\n",
       " 'act',\n",
       " 'act in',\n",
       " 'act in such',\n",
       " 'act in such film',\n",
       " 'act one',\n",
       " 'act one of',\n",
       " 'act one of the',\n",
       " 'acted',\n",
       " 'acted and',\n",
       " 'acted and done',\n",
       " 'acted and done tv',\n",
       " 'acted and not',\n",
       " 'acted and not played',\n",
       " 'acting',\n",
       " 'acting ability',\n",
       " 'acting ability of',\n",
       " 'acting ability of dwight',\n",
       " 'acting action',\n",
       " 'acting action or',\n",
       " 'acting action or location',\n",
       " 'acting alongside',\n",
       " 'acting alongside olivia',\n",
       " 'acting alongside olivia de',\n",
       " 'acting and',\n",
       " 'acting and bad',\n",
       " 'acting and bad is',\n",
       " 'acting and decent',\n",
       " 'acting and decent budget',\n",
       " 'acting and effective',\n",
       " 'acting and effective music',\n",
       " 'acting and look',\n",
       " 'acting and look of',\n",
       " 'acting as',\n",
       " 'acting as you',\n",
       " 'acting as you expect',\n",
       " 'acting at',\n",
       " 'acting at least',\n",
       " 'acting at least for',\n",
       " 'acting by',\n",
       " 'acting by the',\n",
       " 'acting by the whole',\n",
       " 'acting coach',\n",
       " 'acting coach are',\n",
       " 'acting coach are fascinating',\n",
       " 'acting especially',\n",
       " 'acting especially from',\n",
       " 'acting especially from the',\n",
       " 'acting even',\n",
       " 'acting even that',\n",
       " 'acting even that of',\n",
       " 'acting from',\n",
       " 'acting from all',\n",
       " 'acting from all involved',\n",
       " 'acting from its',\n",
       " 'acting from its mostly',\n",
       " 'acting from the',\n",
       " 'acting from the main',\n",
       " 'acting helps',\n",
       " 'acting helps the',\n",
       " 'acting helps the writing',\n",
       " 'acting is',\n",
       " 'acting is absolutely',\n",
       " 'acting is absolutely appalling',\n",
       " 'acting is beyond',\n",
       " 'acting is beyond abysmal',\n",
       " 'acting is blah',\n",
       " 'acting is fantastic',\n",
       " 'acting is fantastic the',\n",
       " 'acting is like',\n",
       " 'acting is like watching',\n",
       " 'acting is superb',\n",
       " 'acting is superb tom',\n",
       " 'acting is terrible',\n",
       " 'acting is terrible and',\n",
       " 'acting is utterly',\n",
       " 'acting is utterly predictable',\n",
       " 'acting make',\n",
       " 'acting make this',\n",
       " 'acting make this one',\n",
       " 'acting mess',\n",
       " 'acting mess of',\n",
       " 'acting mess of script',\n",
       " 'acting post',\n",
       " 'acting post production',\n",
       " 'acting post production editing',\n",
       " 'acting sucked',\n",
       " 'acting sucked the',\n",
       " 'acting sucked the concert',\n",
       " 'acting sucks',\n",
       " 'acting sucks the',\n",
       " 'acting sucks the music',\n",
       " 'acting the',\n",
       " 'acting the better',\n",
       " 'acting the story',\n",
       " 'acting the story the',\n",
       " 'acting to',\n",
       " 'acting to cinematography',\n",
       " 'acting to cinematography was',\n",
       " 'acting was',\n",
       " 'acting was as',\n",
       " 'acting was as bad',\n",
       " 'acting was bad',\n",
       " 'acting was bad really',\n",
       " 'acting was bad the',\n",
       " 'acting was decidely',\n",
       " 'acting was decidely wooden',\n",
       " 'acting was poor',\n",
       " 'acting was poor and',\n",
       " 'acting was skilled',\n",
       " 'acting was stanwyck',\n",
       " 'acting was stanwyck singing',\n",
       " 'acting were',\n",
       " 'acting were weak',\n",
       " 'acting were weak at',\n",
       " 'acting wise',\n",
       " 'acting wise either',\n",
       " 'acting wise either some',\n",
       " 'action',\n",
       " 'action if',\n",
       " 'action if you',\n",
       " 'action if you check',\n",
       " 'action more',\n",
       " 'action more suspense',\n",
       " 'action more suspense and',\n",
       " 'action movie',\n",
       " 'action movie from',\n",
       " 'action movie from the',\n",
       " 'action movies',\n",
       " 'action movies ve',\n",
       " 'action movies ve ever',\n",
       " 'action or',\n",
       " 'action or location',\n",
       " 'action or location work',\n",
       " 'action scenes',\n",
       " 'action scenes in',\n",
       " 'action scenes in it',\n",
       " 'actions',\n",
       " 'actions for',\n",
       " 'actions for 90',\n",
       " 'actions for 90 minutes',\n",
       " 'actor',\n",
       " 'actor and',\n",
       " 'actor and grew',\n",
       " 'actor and grew up',\n",
       " 'actor as',\n",
       " 'actor as he',\n",
       " 'actor as he was',\n",
       " 'actor enjoyed',\n",
       " 'actor enjoyed reading',\n",
       " 'actor enjoyed reading this',\n",
       " 'actor gives',\n",
       " 'actor gives performance',\n",
       " 'actor gives performance that',\n",
       " 'actor on',\n",
       " 'actor on screen',\n",
       " 'actor playing',\n",
       " 'actor playing the',\n",
       " 'actor playing the villain',\n",
       " 'actor the',\n",
       " 'actor the scripting',\n",
       " 'actor the scripting of',\n",
       " 'actor who',\n",
       " 'actor who played',\n",
       " 'actor who played supporting',\n",
       " 'actors',\n",
       " 'actors agreed',\n",
       " 'actors agreed to',\n",
       " 'actors agreed to do',\n",
       " 'actors an',\n",
       " 'actors an ugly',\n",
       " 'actors an ugly cartoon',\n",
       " 'actors and',\n",
       " 'actors and actresses',\n",
       " 'actors and actresses were',\n",
       " 'actors are',\n",
       " 'actors are more',\n",
       " 'actors are more than',\n",
       " 'actors around',\n",
       " 'actors awkwardly',\n",
       " 'actors awkwardly babbling',\n",
       " 'actors awkwardly babbling overwrought',\n",
       " 'actors deliver',\n",
       " 'actors deliver their',\n",
       " 'actors deliver their sharply',\n",
       " 'actors give',\n",
       " 'actors give wonderful',\n",
       " 'actors give wonderful performance',\n",
       " 'actors like',\n",
       " 'actors like thomerson',\n",
       " 'actors like thomerson and',\n",
       " 'actors master',\n",
       " 'actors master director',\n",
       " 'actors master director significant',\n",
       " 'actors now',\n",
       " 'actors now have',\n",
       " 'actors now have twice',\n",
       " 'actors on',\n",
       " 'actors on the',\n",
       " 'actors on the screen',\n",
       " 'actors period',\n",
       " 'actors telly',\n",
       " 'actors telly savalas',\n",
       " 'actors telly savalas and',\n",
       " 'actors truly',\n",
       " 'actors truly understand',\n",
       " 'actors truly understand and',\n",
       " 'actors who',\n",
       " 'actors who haven',\n",
       " 'actors who haven seen',\n",
       " 'actors you',\n",
       " 'actors you can',\n",
       " 'actors you can even',\n",
       " 'actress',\n",
       " 'actress has',\n",
       " 'actress has been',\n",
       " 'actress has been worse',\n",
       " 'actress repeating',\n",
       " 'actress repeating her',\n",
       " 'actress repeating her robotic',\n",
       " 'actresses',\n",
       " 'actresses and',\n",
       " 'actresses and think',\n",
       " 'actresses and think she',\n",
       " 'actresses playing',\n",
       " 'actresses playing anne',\n",
       " 'actresses playing anne sisters',\n",
       " 'actresses were',\n",
       " 'actresses were bonus',\n",
       " 'actresses were bonus to',\n",
       " 'actually',\n",
       " 'actually contributing',\n",
       " 'actually contributing to',\n",
       " 'actually contributing to the',\n",
       " 'actually gets',\n",
       " 'actually gets from',\n",
       " 'actually gets from watching',\n",
       " 'actually has',\n",
       " 'actually has lot',\n",
       " 'actually has lot of',\n",
       " 'actually is',\n",
       " 'actually pretty',\n",
       " 'actually pretty cool',\n",
       " 'actually the',\n",
       " 'actually the graphics',\n",
       " 'actually the graphics were',\n",
       " 'actually turned',\n",
       " 'actually turned out',\n",
       " 'actually turned out to',\n",
       " 'actually very',\n",
       " 'actually very smart',\n",
       " 'actually very smart movie',\n",
       " 'actually was',\n",
       " 'actually worth',\n",
       " 'actually worth seeing',\n",
       " 'actually worth seeing just',\n",
       " 'adams',\n",
       " 'adams unfortunate',\n",
       " 'adams unfortunate life',\n",
       " 'adams unfortunate life was',\n",
       " 'adaptation',\n",
       " 'adaptation of',\n",
       " 'adaptation of james',\n",
       " 'adaptation of james joyce',\n",
       " 'adaptation of the',\n",
       " 'adaptation of the dr',\n",
       " 'add',\n",
       " 'add betty',\n",
       " 'add betty white',\n",
       " 'add betty white and',\n",
       " 'added',\n",
       " 'added bonuses',\n",
       " 'addition',\n",
       " 'addition of',\n",
       " 'addition of new',\n",
       " 'addition of new scenes',\n",
       " 'addition to',\n",
       " 'addition to having',\n",
       " 'addition to having one',\n",
       " 'addition to the',\n",
       " 'addition to the giallo',\n",
       " 'admins',\n",
       " 'admiration',\n",
       " 'admiration of',\n",
       " 'admiration of swords',\n",
       " 'admiration of swords etc',\n",
       " 'admitted',\n",
       " 'admitted elsewhere',\n",
       " 'adorable',\n",
       " 'adorable his',\n",
       " 'adorable his little',\n",
       " 'adorable his little yelps',\n",
       " 'adorable seeing',\n",
       " 'adorable seeing mickey',\n",
       " 'adorable seeing mickey playing',\n",
       " 'adorable the',\n",
       " 'adorable the junkyard',\n",
       " 'adorable the junkyard scenes',\n",
       " 'adrift',\n",
       " 'adrift and',\n",
       " 'adrift and stagy',\n",
       " 'adrift and stagy and',\n",
       " 'adventure',\n",
       " 'adventure at',\n",
       " 'adventure at its',\n",
       " 'adventure at its best',\n",
       " 'advise',\n",
       " 'advise anyone',\n",
       " 'advise anyone to',\n",
       " 'advise anyone to go',\n",
       " 'advise you',\n",
       " 'advise you to',\n",
       " 'advise you to look',\n",
       " 'aerial',\n",
       " 'aerial bombardments',\n",
       " 'aerial bombardments of',\n",
       " 'aerial bombardments of london',\n",
       " 'aerial scenes',\n",
       " 'aerial scenes that',\n",
       " 'aerial scenes that ought',\n",
       " 'aerial scenes were',\n",
       " 'aerial scenes were well',\n",
       " 'aesthetically',\n",
       " 'aesthetically like',\n",
       " 'aesthetically like sculpture',\n",
       " 'affected',\n",
       " 'affected more',\n",
       " 'affected more so',\n",
       " 'affected more so during',\n",
       " 'affleck',\n",
       " 'affleck and',\n",
       " 'affleck and sandra',\n",
       " 'affleck and sandra bullock',\n",
       " 'afraid',\n",
       " 'afraid of',\n",
       " 'afraid of subtitles',\n",
       " 'afraid of subtitles its',\n",
       " 'afraid to',\n",
       " 'afraid to go',\n",
       " 'afraid to go to',\n",
       " 'africa',\n",
       " 'africa understand',\n",
       " 'africa understand its',\n",
       " 'africa understand its past',\n",
       " 'after',\n",
       " 'after 80',\n",
       " 'after 80 wonderful',\n",
       " 'after 80 wonderful years',\n",
       " 'after about',\n",
       " 'after about 25',\n",
       " 'after about 25 years',\n",
       " 'after all',\n",
       " 'after all that',\n",
       " 'after all that we',\n",
       " 'after cotton',\n",
       " 'after cotton club',\n",
       " 'after cotton club and',\n",
       " 'after finally',\n",
       " 'after finally watching',\n",
       " 'after finally watching this',\n",
       " 'after jamie',\n",
       " 'after jamie foxx',\n",
       " 'after jamie foxx absolutely',\n",
       " 'after ready',\n",
       " 'after ready the',\n",
       " 'after ready the script',\n",
       " 'after reporter',\n",
       " 'after reporter who',\n",
       " 'after reporter who working',\n",
       " 'after scene',\n",
       " 'after scene passed',\n",
       " 'after scene passed with',\n",
       " 'after seeing',\n",
       " 'after seeing movie',\n",
       " 'after seeing movie like',\n",
       " 'after seeing the',\n",
       " 'after seeing the short',\n",
       " 'after the',\n",
       " 'after the vision',\n",
       " 'after the vision of',\n",
       " 'after watching',\n",
       " 'after watching this',\n",
       " 'after watching this film',\n",
       " 'afternoon',\n",
       " 'afternoon to',\n",
       " 'afternoon to punish',\n",
       " 'afternoon to punish the',\n",
       " 'again',\n",
       " 'again after',\n",
       " 'again after about',\n",
       " 'again after about 25',\n",
       " 'again bad',\n",
       " 'again bad rating',\n",
       " 'again bad rating out',\n",
       " 'again for',\n",
       " 'again for free',\n",
       " 'again lame',\n",
       " 'again lame here',\n",
       " 'again lame here where',\n",
       " 'again no',\n",
       " 'again no plot',\n",
       " 'again no plot at',\n",
       " 'again on',\n",
       " 'again on dvd',\n",
       " 'again on dvd and',\n",
       " 'again on to',\n",
       " 'again on to video',\n",
       " 'again this',\n",
       " 'again this is',\n",
       " 'again this is torture',\n",
       " 'again two',\n",
       " 'again two sundays',\n",
       " 'again two sundays ago',\n",
       " 'against',\n",
       " 'against any',\n",
       " 'against any movie',\n",
       " 'against any movie in',\n",
       " 'age',\n",
       " 'age appropriate',\n",
       " 'age john',\n",
       " 'age john wayne',\n",
       " 'age john wayne did',\n",
       " 'aged',\n",
       " 'aged upper',\n",
       " 'aged upper class',\n",
       " 'aged upper class uptight',\n",
       " 'ages',\n",
       " 'ages although',\n",
       " 'ages although the',\n",
       " 'ages although the younger',\n",
       " 'ago',\n",
       " 'ago march',\n",
       " 'ago march 20th',\n",
       " 'ago march 20th 2005',\n",
       " 'agree',\n",
       " 'agree with',\n",
       " 'agree with jessica',\n",
       " 'agree with jessica this',\n",
       " 'agreed',\n",
       " 'agreed to',\n",
       " 'agreed to do',\n",
       " 'agreed to do this',\n",
       " 'aimless',\n",
       " 'aimless movie',\n",
       " 'aimless movie about',\n",
       " 'aimless movie about distressed',\n",
       " 'air',\n",
       " 'air force',\n",
       " 'air force one',\n",
       " 'air force one who',\n",
       " 'air it',\n",
       " 'air it enough',\n",
       " 'air it enough so',\n",
       " 'aired',\n",
       " 'aired this',\n",
       " 'aired this dribble',\n",
       " 'aired this dribble watched',\n",
       " 'akasha',\n",
       " 'akasha in',\n",
       " 'akasha in places',\n",
       " 'akasha in places compelling',\n",
       " 'akin',\n",
       " 'akin to',\n",
       " 'akin to torture',\n",
       " 'alert',\n",
       " 'alert as',\n",
       " 'alert as try',\n",
       " 'alert as try to',\n",
       " 'alexander',\n",
       " 'alexander nevsky',\n",
       " 'alexander nevsky is',\n",
       " 'alexander nevsky is great',\n",
       " 'alexander yardley',\n",
       " 'alexander yardley character',\n",
       " 'alike',\n",
       " 'all',\n",
       " 'all ages',\n",
       " 'all ages although',\n",
       " 'all ages although the',\n",
       " 'all and',\n",
       " 'all and the',\n",
       " 'all and the acting',\n",
       " 'all angles',\n",
       " 'all beautiful',\n",
       " 'all beautiful directed',\n",
       " 'all beautiful directed film',\n",
       " 'all cardboard',\n",
       " 'all cardboard cutouts',\n",
       " 'all cardboard cutouts and',\n",
       " 'all costs',\n",
       " 'all costs at',\n",
       " 'all costs at any',\n",
       " 'all costs don',\n",
       " 'all costs don know',\n",
       " 'all end',\n",
       " 'all end all',\n",
       " 'all end all of',\n",
       " 'all extant',\n",
       " 'all extant films',\n",
       " 'all extant films of',\n",
       " 'all for',\n",
       " 'all for artistic',\n",
       " 'all for artistic freedom',\n",
       " 'all funny',\n",
       " 'all funny and',\n",
       " 'all funny and had',\n",
       " 'all give',\n",
       " 'all give this',\n",
       " 'all give this one',\n",
       " 'all great',\n",
       " 'all great disappointment',\n",
       " 'all horror',\n",
       " 'all horror movies',\n",
       " 'all horror movies and',\n",
       " 'all in',\n",
       " 'all in all',\n",
       " 'all in all beautiful',\n",
       " 'all in all give',\n",
       " 'all in all great',\n",
       " 'all in all its',\n",
       " 'all involved',\n",
       " 'all involved and',\n",
       " 'all involved and that',\n",
       " 'all it',\n",
       " 'all it was',\n",
       " 'all it was very',\n",
       " 'all its',\n",
       " 'all its an',\n",
       " 'all its an insult',\n",
       " 'all just',\n",
       " 'all just one',\n",
       " 'all just one big',\n",
       " 'all of',\n",
       " 'all of brainsucking',\n",
       " 'all of brainsucking movies',\n",
       " 'all of the',\n",
       " 'all of the main',\n",
       " 'all of the songs',\n",
       " 'all of them',\n",
       " 'all of them true',\n",
       " 'all of this',\n",
       " 'all of this with',\n",
       " 'all references',\n",
       " 'all references are',\n",
       " 'all references are industry',\n",
       " 'all right',\n",
       " 'all round',\n",
       " 'all shakespear',\n",
       " 'all shakespear fans',\n",
       " 'all star',\n",
       " 'all star cast',\n",
       " 'all star cast and',\n",
       " 'all study',\n",
       " 'all study of',\n",
       " 'all study of the',\n",
       " 'all suggest',\n",
       " 'all suggest natural',\n",
       " 'all suggest natural eye',\n",
       " 'all that',\n",
       " 'all that is',\n",
       " 'all that is good',\n",
       " 'all that memorable',\n",
       " 'all that memorable and',\n",
       " 'all that we',\n",
       " 'all that we get',\n",
       " 'all the',\n",
       " 'all the actors',\n",
       " 'all the actors deliver',\n",
       " 'all the actors give',\n",
       " 'all the animals',\n",
       " 'all the animals and',\n",
       " 'all the characters',\n",
       " 'all the characters have',\n",
       " 'all the characters in',\n",
       " 'all the characters of',\n",
       " 'all the cheap',\n",
       " 'all the cheap drama',\n",
       " 'all the exquisite',\n",
       " 'all the exquisite visual',\n",
       " 'all the junkyard',\n",
       " ...]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TFIDFngrams.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.asarray(TFIDFngamFeatures.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(748, 35845)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.random.beta(0.1,0.5,(X.shape[0],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y = make_regression(n_features=10000,n_samples=4000,n_informative=70,noise=2)\n",
    "Y = np.expand_dims(Y,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SGDRegressor(loss = 'squared_loss',\n",
    "                     penalty='elasticnet',\n",
    "                     max_iter=1000,\n",
    "                     tol=1e-4,\n",
    "                     learning_rate='constant',\n",
    "                     eta0=1e-4,\n",
    "                     early_stopping=False,\n",
    "                     n_iter_no_change=100,\n",
    "                     average=False,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scalerX = MinMaxScaler()\n",
    "scalerY = MinMaxScaler()\n",
    "scalerX.fit(X)\n",
    "scalerY.fit(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "-- Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 0.02, NNZs: 8774, Bias: 0.000201, T: 2666, Avg. loss: 0.011678\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.03, NNZs: 8245, Bias: 0.000204, T: 5332, Avg. loss: 0.011017\n",
      "Total training time: 0.35 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.04, NNZs: 8076, Bias: 0.000191, T: 7998, Avg. loss: 0.010392\n",
      "Total training time: 0.54 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.05, NNZs: 7999, Bias: 0.000179, T: 10664, Avg. loss: 0.010001\n",
      "Total training time: 0.74 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.06, NNZs: 7928, Bias: 0.000190, T: 13330, Avg. loss: 0.009631\n",
      "Total training time: 0.95 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.07, NNZs: 7836, Bias: 0.000158, T: 15996, Avg. loss: 0.009191\n",
      "Total training time: 1.15 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.08, NNZs: 7814, Bias: 0.000161, T: 18662, Avg. loss: 0.008751\n",
      "Total training time: 1.35 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.09, NNZs: 7800, Bias: 0.000143, T: 21328, Avg. loss: 0.008577\n",
      "Total training time: 1.57 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.10, NNZs: 7772, Bias: 0.000163, T: 23994, Avg. loss: 0.008168\n",
      "Total training time: 1.78 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.11, NNZs: 7734, Bias: 0.000109, T: 26660, Avg. loss: 0.007910\n",
      "Total training time: 1.99 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.12, NNZs: 7726, Bias: 0.000120, T: 29326, Avg. loss: 0.007632\n",
      "Total training time: 2.19 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.12, NNZs: 7682, Bias: 0.000143, T: 31992, Avg. loss: 0.007297\n",
      "Total training time: 2.39 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.13, NNZs: 7657, Bias: 0.000121, T: 34658, Avg. loss: 0.007181\n",
      "Total training time: 2.60 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 0.14, NNZs: 7641, Bias: 0.000104, T: 37324, Avg. loss: 0.006912\n",
      "Total training time: 2.81 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 0.15, NNZs: 7626, Bias: 0.000136, T: 39990, Avg. loss: 0.006600\n",
      "Total training time: 3.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 0.15, NNZs: 7613, Bias: 0.000093, T: 42656, Avg. loss: 0.006413\n",
      "Total training time: 3.21 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 0.16, NNZs: 7589, Bias: 0.000095, T: 45322, Avg. loss: 0.006257\n",
      "Total training time: 3.42 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 0.17, NNZs: 7556, Bias: 0.000122, T: 47988, Avg. loss: 0.005959\n",
      "Total training time: 3.63 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.18, NNZs: 7538, Bias: 0.000080, T: 50654, Avg. loss: 0.005781\n",
      "Total training time: 3.83 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 0.18, NNZs: 7504, Bias: 0.000085, T: 53320, Avg. loss: 0.005650\n",
      "Total training time: 4.03 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 0.19, NNZs: 7481, Bias: 0.000052, T: 55986, Avg. loss: 0.005451\n",
      "Total training time: 4.23 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.19, NNZs: 7470, Bias: 0.000072, T: 58652, Avg. loss: 0.005319\n",
      "Total training time: 4.43 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 0.20, NNZs: 7443, Bias: 0.000042, T: 61318, Avg. loss: 0.005113\n",
      "Total training time: 4.64 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 0.21, NNZs: 7423, Bias: 0.000042, T: 63984, Avg. loss: 0.004977\n",
      "Total training time: 4.83 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 0.21, NNZs: 7412, Bias: 0.000056, T: 66650, Avg. loss: 0.004778\n",
      "Total training time: 5.03 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 0.22, NNZs: 7385, Bias: 0.000041, T: 69316, Avg. loss: 0.004697\n",
      "Total training time: 5.22 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 0.22, NNZs: 7374, Bias: 0.000018, T: 71982, Avg. loss: 0.004537\n",
      "Total training time: 5.41 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 0.23, NNZs: 7358, Bias: 0.000061, T: 74648, Avg. loss: 0.004388\n",
      "Total training time: 5.61 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 0.24, NNZs: 7330, Bias: 0.000020, T: 77314, Avg. loss: 0.004272\n",
      "Total training time: 5.80 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 0.24, NNZs: 7316, Bias: 0.000013, T: 79980, Avg. loss: 0.004154\n",
      "Total training time: 5.99 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 0.25, NNZs: 7280, Bias: 0.000008, T: 82646, Avg. loss: 0.004060\n",
      "Total training time: 6.20 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 0.25, NNZs: 7265, Bias: 0.000022, T: 85312, Avg. loss: 0.003909\n",
      "Total training time: 6.39 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.26, NNZs: 7238, Bias: 0.000032, T: 87978, Avg. loss: 0.003818\n",
      "Total training time: 6.59 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.26, NNZs: 7213, Bias: 0.000008, T: 90644, Avg. loss: 0.003699\n",
      "Total training time: 6.79 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 0.27, NNZs: 7193, Bias: -0.000009, T: 93310, Avg. loss: 0.003625\n",
      "Total training time: 6.98 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 0.27, NNZs: 7167, Bias: -0.000025, T: 95976, Avg. loss: 0.003483\n",
      "Total training time: 7.18 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 0.28, NNZs: 7160, Bias: -0.000024, T: 98642, Avg. loss: 0.003454\n",
      "Total training time: 7.38 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 0.28, NNZs: 7142, Bias: -0.000046, T: 101308, Avg. loss: 0.003340\n",
      "Total training time: 7.58 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 0.29, NNZs: 7129, Bias: -0.000043, T: 103974, Avg. loss: 0.003285\n",
      "Total training time: 7.78 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 0.29, NNZs: 7103, Bias: -0.000041, T: 106640, Avg. loss: 0.003180\n",
      "Total training time: 7.98 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 0.29, NNZs: 7087, Bias: -0.000037, T: 109306, Avg. loss: 0.003129\n",
      "Total training time: 8.18 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 0.30, NNZs: 7068, Bias: -0.000061, T: 111972, Avg. loss: 0.003062\n",
      "Total training time: 8.38 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 0.30, NNZs: 7055, Bias: -0.000074, T: 114638, Avg. loss: 0.002957\n",
      "Total training time: 8.58 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 0.31, NNZs: 7023, Bias: -0.000082, T: 117304, Avg. loss: 0.002879\n",
      "Total training time: 8.78 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 0.31, NNZs: 7007, Bias: -0.000069, T: 119970, Avg. loss: 0.002843\n",
      "Total training time: 8.97 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 0.32, NNZs: 6984, Bias: -0.000079, T: 122636, Avg. loss: 0.002758\n",
      "Total training time: 9.17 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 0.32, NNZs: 6953, Bias: -0.000089, T: 125302, Avg. loss: 0.002704\n",
      "Total training time: 9.38 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 0.32, NNZs: 6940, Bias: -0.000088, T: 127968, Avg. loss: 0.002618\n",
      "Total training time: 9.57 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 0.33, NNZs: 6927, Bias: -0.000097, T: 130634, Avg. loss: 0.002566\n",
      "Total training time: 9.77 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 0.33, NNZs: 6908, Bias: -0.000095, T: 133300, Avg. loss: 0.002502\n",
      "Total training time: 9.96 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 0.34, NNZs: 6895, Bias: -0.000111, T: 135966, Avg. loss: 0.002498\n",
      "Total training time: 10.15 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 0.34, NNZs: 6877, Bias: -0.000116, T: 138632, Avg. loss: 0.002431\n",
      "Total training time: 10.35 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 0.34, NNZs: 6856, Bias: -0.000092, T: 141298, Avg. loss: 0.002364\n",
      "Total training time: 10.55 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 0.35, NNZs: 6843, Bias: -0.000138, T: 143964, Avg. loss: 0.002349\n",
      "Total training time: 10.74 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 0.35, NNZs: 6823, Bias: -0.000134, T: 146630, Avg. loss: 0.002271\n",
      "Total training time: 10.95 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 0.35, NNZs: 6798, Bias: -0.000108, T: 149296, Avg. loss: 0.002238\n",
      "Total training time: 11.15 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 0.36, NNZs: 6784, Bias: -0.000129, T: 151962, Avg. loss: 0.002165\n",
      "Total training time: 11.35 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 0.36, NNZs: 6764, Bias: -0.000143, T: 154628, Avg. loss: 0.002170\n",
      "Total training time: 11.53 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 0.36, NNZs: 6751, Bias: -0.000139, T: 157294, Avg. loss: 0.002127\n",
      "Total training time: 11.73 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 0.37, NNZs: 6737, Bias: -0.000168, T: 159960, Avg. loss: 0.002051\n",
      "Total training time: 11.93 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 0.37, NNZs: 6725, Bias: -0.000163, T: 162626, Avg. loss: 0.002020\n",
      "Total training time: 12.12 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 0.37, NNZs: 6711, Bias: -0.000145, T: 165292, Avg. loss: 0.001991\n",
      "Total training time: 12.32 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 0.38, NNZs: 6697, Bias: -0.000146, T: 167958, Avg. loss: 0.001971\n",
      "Total training time: 12.52 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 0.38, NNZs: 6676, Bias: -0.000179, T: 170624, Avg. loss: 0.001914\n",
      "Total training time: 12.71 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 0.38, NNZs: 6664, Bias: -0.000164, T: 173290, Avg. loss: 0.001881\n",
      "Total training time: 12.91 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 0.39, NNZs: 6638, Bias: -0.000194, T: 175956, Avg. loss: 0.001854\n",
      "Total training time: 13.10 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 0.39, NNZs: 6623, Bias: -0.000189, T: 178622, Avg. loss: 0.001834\n",
      "Total training time: 13.30 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 0.39, NNZs: 6603, Bias: -0.000212, T: 181288, Avg. loss: 0.001786\n",
      "Total training time: 13.49 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 0.39, NNZs: 6590, Bias: -0.000210, T: 183954, Avg. loss: 0.001759\n",
      "Total training time: 13.69 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 0.40, NNZs: 6564, Bias: -0.000198, T: 186620, Avg. loss: 0.001720\n",
      "Total training time: 13.88 seconds.\n",
      "-- Epoch 71\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 0.40, NNZs: 6550, Bias: -0.000219, T: 189286, Avg. loss: 0.001700\n",
      "Total training time: 14.08 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 0.40, NNZs: 6530, Bias: -0.000221, T: 191952, Avg. loss: 0.001674\n",
      "Total training time: 14.27 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 0.41, NNZs: 6505, Bias: -0.000226, T: 194618, Avg. loss: 0.001649\n",
      "Total training time: 14.47 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 0.41, NNZs: 6500, Bias: -0.000232, T: 197284, Avg. loss: 0.001622\n",
      "Total training time: 14.65 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 0.41, NNZs: 6484, Bias: -0.000228, T: 199950, Avg. loss: 0.001576\n",
      "Total training time: 14.84 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 0.41, NNZs: 6460, Bias: -0.000252, T: 202616, Avg. loss: 0.001578\n",
      "Total training time: 15.02 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 0.42, NNZs: 6444, Bias: -0.000243, T: 205282, Avg. loss: 0.001565\n",
      "Total training time: 15.22 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 0.42, NNZs: 6438, Bias: -0.000264, T: 207948, Avg. loss: 0.001531\n",
      "Total training time: 15.42 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 0.42, NNZs: 6426, Bias: -0.000261, T: 210614, Avg. loss: 0.001499\n",
      "Total training time: 15.60 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 0.42, NNZs: 6410, Bias: -0.000264, T: 213280, Avg. loss: 0.001469\n",
      "Total training time: 15.79 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 0.43, NNZs: 6402, Bias: -0.000273, T: 215946, Avg. loss: 0.001462\n",
      "Total training time: 15.98 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 0.43, NNZs: 6388, Bias: -0.000273, T: 218612, Avg. loss: 0.001431\n",
      "Total training time: 16.18 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 0.43, NNZs: 6376, Bias: -0.000272, T: 221278, Avg. loss: 0.001428\n",
      "Total training time: 16.38 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 0.43, NNZs: 6352, Bias: -0.000300, T: 223944, Avg. loss: 0.001413\n",
      "Total training time: 16.57 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 0.44, NNZs: 6339, Bias: -0.000303, T: 226610, Avg. loss: 0.001373\n",
      "Total training time: 16.77 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 0.44, NNZs: 6317, Bias: -0.000295, T: 229276, Avg. loss: 0.001355\n",
      "Total training time: 16.95 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 0.44, NNZs: 6300, Bias: -0.000294, T: 231942, Avg. loss: 0.001343\n",
      "Total training time: 17.13 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 0.44, NNZs: 6286, Bias: -0.000317, T: 234608, Avg. loss: 0.001326\n",
      "Total training time: 17.32 seconds.\n",
      "-- Epoch 89\n",
      "Norm: 0.45, NNZs: 6272, Bias: -0.000310, T: 237274, Avg. loss: 0.001313\n",
      "Total training time: 17.51 seconds.\n",
      "-- Epoch 90\n",
      "Norm: 0.45, NNZs: 6248, Bias: -0.000320, T: 239940, Avg. loss: 0.001296\n",
      "Total training time: 17.70 seconds.\n",
      "-- Epoch 91\n",
      "Norm: 0.45, NNZs: 6233, Bias: -0.000315, T: 242606, Avg. loss: 0.001267\n",
      "Total training time: 17.88 seconds.\n",
      "-- Epoch 92\n",
      "Norm: 0.45, NNZs: 6223, Bias: -0.000320, T: 245272, Avg. loss: 0.001268\n",
      "Total training time: 18.07 seconds.\n",
      "-- Epoch 93\n",
      "Norm: 0.45, NNZs: 6206, Bias: -0.000342, T: 247938, Avg. loss: 0.001246\n",
      "Total training time: 18.26 seconds.\n",
      "-- Epoch 94\n",
      "Norm: 0.46, NNZs: 6198, Bias: -0.000341, T: 250604, Avg. loss: 0.001235\n",
      "Total training time: 18.44 seconds.\n",
      "-- Epoch 95\n",
      "Norm: 0.46, NNZs: 6180, Bias: -0.000356, T: 253270, Avg. loss: 0.001218\n",
      "Total training time: 18.64 seconds.\n",
      "-- Epoch 96\n",
      "Norm: 0.46, NNZs: 6166, Bias: -0.000352, T: 255936, Avg. loss: 0.001213\n",
      "Total training time: 18.82 seconds.\n",
      "-- Epoch 97\n",
      "Norm: 0.46, NNZs: 6140, Bias: -0.000353, T: 258602, Avg. loss: 0.001196\n",
      "Total training time: 19.00 seconds.\n",
      "-- Epoch 98\n",
      "Norm: 0.46, NNZs: 6128, Bias: -0.000358, T: 261268, Avg. loss: 0.001179\n",
      "Total training time: 19.19 seconds.\n",
      "-- Epoch 99\n",
      "Norm: 0.47, NNZs: 6114, Bias: -0.000363, T: 263934, Avg. loss: 0.001170\n",
      "Total training time: 19.37 seconds.\n",
      "-- Epoch 100\n",
      "Norm: 0.47, NNZs: 6096, Bias: -0.000371, T: 266600, Avg. loss: 0.001158\n",
      "Total training time: 19.56 seconds.\n",
      "-- Epoch 101\n",
      "Norm: 0.47, NNZs: 6075, Bias: -0.000378, T: 269266, Avg. loss: 0.001144\n",
      "Total training time: 19.74 seconds.\n",
      "-- Epoch 102\n",
      "Norm: 0.47, NNZs: 6059, Bias: -0.000378, T: 271932, Avg. loss: 0.001125\n",
      "Total training time: 19.93 seconds.\n",
      "-- Epoch 103\n",
      "Norm: 0.48, NNZs: 6046, Bias: -0.000393, T: 274598, Avg. loss: 0.001108\n",
      "Total training time: 20.11 seconds.\n",
      "-- Epoch 104\n",
      "Norm: 0.48, NNZs: 6034, Bias: -0.000381, T: 277264, Avg. loss: 0.001087\n",
      "Total training time: 20.30 seconds.\n",
      "-- Epoch 105\n",
      "Norm: 0.48, NNZs: 6020, Bias: -0.000401, T: 279930, Avg. loss: 0.001088\n",
      "Total training time: 20.48 seconds.\n",
      "-- Epoch 106\n",
      "Norm: 0.48, NNZs: 6007, Bias: -0.000405, T: 282596, Avg. loss: 0.001071\n",
      "Total training time: 20.66 seconds.\n",
      "-- Epoch 107\n",
      "Norm: 0.48, NNZs: 5994, Bias: -0.000395, T: 285262, Avg. loss: 0.001080\n",
      "Total training time: 20.85 seconds.\n",
      "-- Epoch 108\n",
      "Norm: 0.49, NNZs: 5982, Bias: -0.000425, T: 287928, Avg. loss: 0.001053\n",
      "Total training time: 21.03 seconds.\n",
      "-- Epoch 109\n",
      "Norm: 0.49, NNZs: 5963, Bias: -0.000412, T: 290594, Avg. loss: 0.001055\n",
      "Total training time: 21.21 seconds.\n",
      "-- Epoch 110\n",
      "Norm: 0.49, NNZs: 5951, Bias: -0.000426, T: 293260, Avg. loss: 0.001038\n",
      "Total training time: 21.39 seconds.\n",
      "-- Epoch 111\n",
      "Norm: 0.49, NNZs: 5939, Bias: -0.000441, T: 295926, Avg. loss: 0.001005\n",
      "Total training time: 21.57 seconds.\n",
      "-- Epoch 112\n",
      "Norm: 0.49, NNZs: 5935, Bias: -0.000426, T: 298592, Avg. loss: 0.001017\n",
      "Total training time: 21.76 seconds.\n",
      "-- Epoch 113\n",
      "Norm: 0.49, NNZs: 5915, Bias: -0.000440, T: 301258, Avg. loss: 0.001008\n",
      "Total training time: 21.93 seconds.\n",
      "-- Epoch 114\n",
      "Norm: 0.50, NNZs: 5898, Bias: -0.000442, T: 303924, Avg. loss: 0.000998\n",
      "Total training time: 22.12 seconds.\n",
      "-- Epoch 115\n",
      "Norm: 0.50, NNZs: 5885, Bias: -0.000471, T: 306590, Avg. loss: 0.000990\n",
      "Total training time: 22.30 seconds.\n",
      "-- Epoch 116\n",
      "Norm: 0.50, NNZs: 5867, Bias: -0.000463, T: 309256, Avg. loss: 0.000973\n",
      "Total training time: 22.48 seconds.\n",
      "-- Epoch 117\n",
      "Norm: 0.50, NNZs: 5853, Bias: -0.000468, T: 311922, Avg. loss: 0.000970\n",
      "Total training time: 22.67 seconds.\n",
      "-- Epoch 118\n",
      "Norm: 0.50, NNZs: 5838, Bias: -0.000472, T: 314588, Avg. loss: 0.000960\n",
      "Total training time: 22.86 seconds.\n",
      "-- Epoch 119\n",
      "Norm: 0.51, NNZs: 5818, Bias: -0.000463, T: 317254, Avg. loss: 0.000943\n",
      "Total training time: 23.05 seconds.\n",
      "-- Epoch 120\n",
      "Norm: 0.51, NNZs: 5809, Bias: -0.000491, T: 319920, Avg. loss: 0.000936\n",
      "Total training time: 23.24 seconds.\n",
      "-- Epoch 121\n",
      "Norm: 0.51, NNZs: 5795, Bias: -0.000485, T: 322586, Avg. loss: 0.000934\n",
      "Total training time: 23.43 seconds.\n",
      "-- Epoch 122\n",
      "Norm: 0.51, NNZs: 5782, Bias: -0.000490, T: 325252, Avg. loss: 0.000915\n",
      "Total training time: 23.62 seconds.\n",
      "-- Epoch 123\n",
      "Norm: 0.51, NNZs: 5770, Bias: -0.000497, T: 327918, Avg. loss: 0.000919\n",
      "Total training time: 23.81 seconds.\n",
      "-- Epoch 124\n",
      "Norm: 0.51, NNZs: 5759, Bias: -0.000505, T: 330584, Avg. loss: 0.000905\n",
      "Total training time: 23.99 seconds.\n",
      "-- Epoch 125\n",
      "Norm: 0.52, NNZs: 5737, Bias: -0.000507, T: 333250, Avg. loss: 0.000907\n",
      "Total training time: 24.18 seconds.\n",
      "-- Epoch 126\n",
      "Norm: 0.52, NNZs: 5725, Bias: -0.000510, T: 335916, Avg. loss: 0.000893\n",
      "Total training time: 24.37 seconds.\n",
      "-- Epoch 127\n",
      "Norm: 0.52, NNZs: 5710, Bias: -0.000512, T: 338582, Avg. loss: 0.000880\n",
      "Total training time: 24.56 seconds.\n",
      "-- Epoch 128\n",
      "Norm: 0.52, NNZs: 5699, Bias: -0.000521, T: 341248, Avg. loss: 0.000879\n",
      "Total training time: 24.74 seconds.\n",
      "-- Epoch 129\n",
      "Norm: 0.52, NNZs: 5685, Bias: -0.000528, T: 343914, Avg. loss: 0.000867\n",
      "Total training time: 24.93 seconds.\n",
      "-- Epoch 130\n",
      "Norm: 0.52, NNZs: 5670, Bias: -0.000522, T: 346580, Avg. loss: 0.000864\n",
      "Total training time: 25.12 seconds.\n",
      "-- Epoch 131\n",
      "Norm: 0.53, NNZs: 5659, Bias: -0.000532, T: 349246, Avg. loss: 0.000858\n",
      "Total training time: 25.31 seconds.\n",
      "-- Epoch 132\n",
      "Norm: 0.53, NNZs: 5647, Bias: -0.000540, T: 351912, Avg. loss: 0.000847\n",
      "Total training time: 25.49 seconds.\n",
      "-- Epoch 133\n",
      "Norm: 0.53, NNZs: 5632, Bias: -0.000551, T: 354578, Avg. loss: 0.000849\n",
      "Total training time: 25.68 seconds.\n",
      "-- Epoch 134\n",
      "Norm: 0.53, NNZs: 5619, Bias: -0.000551, T: 357244, Avg. loss: 0.000844\n",
      "Total training time: 25.86 seconds.\n",
      "-- Epoch 135\n",
      "Norm: 0.53, NNZs: 5603, Bias: -0.000560, T: 359910, Avg. loss: 0.000824\n",
      "Total training time: 26.04 seconds.\n",
      "-- Epoch 136\n",
      "Norm: 0.53, NNZs: 5581, Bias: -0.000570, T: 362576, Avg. loss: 0.000827\n",
      "Total training time: 26.22 seconds.\n",
      "-- Epoch 137\n",
      "Norm: 0.54, NNZs: 5566, Bias: -0.000575, T: 365242, Avg. loss: 0.000823\n",
      "Total training time: 26.40 seconds.\n",
      "-- Epoch 138\n",
      "Norm: 0.54, NNZs: 5553, Bias: -0.000576, T: 367908, Avg. loss: 0.000816\n",
      "Total training time: 26.59 seconds.\n",
      "-- Epoch 139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 0.54, NNZs: 5541, Bias: -0.000583, T: 370574, Avg. loss: 0.000821\n",
      "Total training time: 26.77 seconds.\n",
      "-- Epoch 140\n",
      "Norm: 0.54, NNZs: 5527, Bias: -0.000589, T: 373240, Avg. loss: 0.000802\n",
      "Total training time: 26.94 seconds.\n",
      "-- Epoch 141\n",
      "Norm: 0.54, NNZs: 5511, Bias: -0.000612, T: 375906, Avg. loss: 0.000798\n",
      "Total training time: 27.12 seconds.\n",
      "-- Epoch 142\n",
      "Norm: 0.54, NNZs: 5493, Bias: -0.000589, T: 378572, Avg. loss: 0.000793\n",
      "Total training time: 27.31 seconds.\n",
      "-- Epoch 143\n",
      "Norm: 0.54, NNZs: 5482, Bias: -0.000600, T: 381238, Avg. loss: 0.000792\n",
      "Total training time: 27.49 seconds.\n",
      "Convergence after 143 epochs took 27.49 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.02, NNZs: 8523, Bias: 0.000166, T: 2667, Avg. loss: 0.010912\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.03, NNZs: 8100, Bias: 0.000179, T: 5334, Avg. loss: 0.010200\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.04, NNZs: 7987, Bias: 0.000194, T: 8001, Avg. loss: 0.009848\n",
      "Total training time: 0.56 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.05, NNZs: 7912, Bias: 0.000209, T: 10668, Avg. loss: 0.009481\n",
      "Total training time: 0.76 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.06, NNZs: 7852, Bias: 0.000201, T: 13335, Avg. loss: 0.009144\n",
      "Total training time: 0.97 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.07, NNZs: 7798, Bias: 0.000161, T: 16002, Avg. loss: 0.008724\n",
      "Total training time: 1.17 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.08, NNZs: 7768, Bias: 0.000177, T: 18669, Avg. loss: 0.008396\n",
      "Total training time: 1.37 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.09, NNZs: 7726, Bias: 0.000143, T: 21336, Avg. loss: 0.008141\n",
      "Total training time: 1.58 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.10, NNZs: 7725, Bias: 0.000164, T: 24003, Avg. loss: 0.007722\n",
      "Total training time: 1.79 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.10, NNZs: 7677, Bias: 0.000147, T: 26670, Avg. loss: 0.007549\n",
      "Total training time: 1.99 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.11, NNZs: 7666, Bias: 0.000176, T: 29337, Avg. loss: 0.007245\n",
      "Total training time: 2.20 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.12, NNZs: 7626, Bias: 0.000146, T: 32004, Avg. loss: 0.007067\n",
      "Total training time: 2.39 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.13, NNZs: 7618, Bias: 0.000174, T: 34671, Avg. loss: 0.006728\n",
      "Total training time: 2.60 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 0.14, NNZs: 7572, Bias: 0.000186, T: 37338, Avg. loss: 0.006583\n",
      "Total training time: 2.80 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 0.14, NNZs: 7540, Bias: 0.000151, T: 40005, Avg. loss: 0.006328\n",
      "Total training time: 3.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 0.15, NNZs: 7522, Bias: 0.000145, T: 42672, Avg. loss: 0.006144\n",
      "Total training time: 3.22 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 0.16, NNZs: 7498, Bias: 0.000115, T: 45339, Avg. loss: 0.005874\n",
      "Total training time: 3.42 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 0.16, NNZs: 7474, Bias: 0.000098, T: 48006, Avg. loss: 0.005683\n",
      "Total training time: 3.62 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.17, NNZs: 7443, Bias: 0.000130, T: 50673, Avg. loss: 0.005505\n",
      "Total training time: 3.82 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 0.18, NNZs: 7423, Bias: 0.000113, T: 53340, Avg. loss: 0.005298\n",
      "Total training time: 4.03 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 0.18, NNZs: 7410, Bias: 0.000127, T: 56007, Avg. loss: 0.005184\n",
      "Total training time: 4.23 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.19, NNZs: 7391, Bias: 0.000077, T: 58674, Avg. loss: 0.005013\n",
      "Total training time: 4.43 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 0.20, NNZs: 7383, Bias: 0.000100, T: 61341, Avg. loss: 0.004837\n",
      "Total training time: 4.63 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 0.20, NNZs: 7364, Bias: 0.000098, T: 64008, Avg. loss: 0.004769\n",
      "Total training time: 4.83 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 0.21, NNZs: 7333, Bias: 0.000069, T: 66675, Avg. loss: 0.004614\n",
      "Total training time: 5.03 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 0.21, NNZs: 7331, Bias: 0.000086, T: 69342, Avg. loss: 0.004463\n",
      "Total training time: 5.24 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 0.22, NNZs: 7300, Bias: 0.000111, T: 72009, Avg. loss: 0.004316\n",
      "Total training time: 5.44 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 0.22, NNZs: 7285, Bias: 0.000085, T: 74676, Avg. loss: 0.004196\n",
      "Total training time: 5.64 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 0.23, NNZs: 7267, Bias: 0.000092, T: 77343, Avg. loss: 0.004058\n",
      "Total training time: 5.83 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 0.24, NNZs: 7237, Bias: 0.000061, T: 80010, Avg. loss: 0.003903\n",
      "Total training time: 6.03 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 0.24, NNZs: 7209, Bias: 0.000056, T: 82677, Avg. loss: 0.003854\n",
      "Total training time: 6.23 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 0.25, NNZs: 7194, Bias: 0.000058, T: 85344, Avg. loss: 0.003743\n",
      "Total training time: 6.43 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.25, NNZs: 7178, Bias: 0.000037, T: 88011, Avg. loss: 0.003650\n",
      "Total training time: 6.63 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.26, NNZs: 7175, Bias: 0.000076, T: 90678, Avg. loss: 0.003561\n",
      "Total training time: 6.83 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 0.26, NNZs: 7145, Bias: 0.000047, T: 93345, Avg. loss: 0.003455\n",
      "Total training time: 7.02 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 0.26, NNZs: 7118, Bias: 0.000030, T: 96012, Avg. loss: 0.003357\n",
      "Total training time: 7.21 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 0.27, NNZs: 7097, Bias: 0.000032, T: 98679, Avg. loss: 0.003314\n",
      "Total training time: 7.40 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 0.27, NNZs: 7082, Bias: 0.000014, T: 101346, Avg. loss: 0.003189\n",
      "Total training time: 7.60 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 0.28, NNZs: 7066, Bias: 0.000043, T: 104013, Avg. loss: 0.003138\n",
      "Total training time: 7.78 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 0.28, NNZs: 7054, Bias: 0.000018, T: 106680, Avg. loss: 0.003051\n",
      "Total training time: 7.97 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 0.29, NNZs: 7028, Bias: 0.000017, T: 109347, Avg. loss: 0.002961\n",
      "Total training time: 8.17 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 0.29, NNZs: 7016, Bias: 0.000005, T: 112014, Avg. loss: 0.002923\n",
      "Total training time: 8.36 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 0.30, NNZs: 7003, Bias: 0.000030, T: 114681, Avg. loss: 0.002835\n",
      "Total training time: 8.55 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 0.30, NNZs: 6985, Bias: -0.000019, T: 117348, Avg. loss: 0.002754\n",
      "Total training time: 8.74 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 0.30, NNZs: 6966, Bias: 0.000012, T: 120015, Avg. loss: 0.002701\n",
      "Total training time: 8.95 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 0.31, NNZs: 6959, Bias: 0.000019, T: 122682, Avg. loss: 0.002666\n",
      "Total training time: 9.14 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 0.31, NNZs: 6935, Bias: -0.000018, T: 125349, Avg. loss: 0.002589\n",
      "Total training time: 9.33 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 0.32, NNZs: 6917, Bias: -0.000012, T: 128016, Avg. loss: 0.002534\n",
      "Total training time: 9.52 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 0.32, NNZs: 6893, Bias: -0.000030, T: 130683, Avg. loss: 0.002466\n",
      "Total training time: 9.70 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 0.32, NNZs: 6875, Bias: -0.000030, T: 133350, Avg. loss: 0.002414\n",
      "Total training time: 9.90 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 0.33, NNZs: 6847, Bias: -0.000019, T: 136017, Avg. loss: 0.002395\n",
      "Total training time: 10.09 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 0.33, NNZs: 6830, Bias: -0.000035, T: 138684, Avg. loss: 0.002305\n",
      "Total training time: 10.28 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 0.33, NNZs: 6815, Bias: -0.000031, T: 141351, Avg. loss: 0.002274\n",
      "Total training time: 10.47 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 0.34, NNZs: 6798, Bias: -0.000025, T: 144018, Avg. loss: 0.002207\n",
      "Total training time: 10.67 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 0.34, NNZs: 6779, Bias: -0.000045, T: 146685, Avg. loss: 0.002192\n",
      "Total training time: 10.86 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 0.34, NNZs: 6763, Bias: -0.000030, T: 149352, Avg. loss: 0.002164\n",
      "Total training time: 11.06 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 0.35, NNZs: 6738, Bias: -0.000052, T: 152019, Avg. loss: 0.002110\n",
      "Total training time: 11.25 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 0.35, NNZs: 6718, Bias: -0.000041, T: 154686, Avg. loss: 0.002046\n",
      "Total training time: 11.44 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 0.35, NNZs: 6708, Bias: -0.000053, T: 157353, Avg. loss: 0.002035\n",
      "Total training time: 11.63 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 0.36, NNZs: 6678, Bias: -0.000064, T: 160020, Avg. loss: 0.001996\n",
      "Total training time: 11.82 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 0.36, NNZs: 6665, Bias: -0.000062, T: 162687, Avg. loss: 0.001957\n",
      "Total training time: 12.01 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 0.36, NNZs: 6654, Bias: -0.000076, T: 165354, Avg. loss: 0.001917\n",
      "Total training time: 12.20 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 0.37, NNZs: 6635, Bias: -0.000072, T: 168021, Avg. loss: 0.001889\n",
      "Total training time: 12.39 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 0.37, NNZs: 6621, Bias: -0.000081, T: 170688, Avg. loss: 0.001852\n",
      "Total training time: 12.59 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 0.37, NNZs: 6604, Bias: -0.000078, T: 173355, Avg. loss: 0.001815\n",
      "Total training time: 12.78 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 0.38, NNZs: 6591, Bias: -0.000110, T: 176022, Avg. loss: 0.001792\n",
      "Total training time: 12.98 seconds.\n",
      "-- Epoch 67\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 0.38, NNZs: 6577, Bias: -0.000106, T: 178689, Avg. loss: 0.001762\n",
      "Total training time: 13.17 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 0.38, NNZs: 6565, Bias: -0.000117, T: 181356, Avg. loss: 0.001716\n",
      "Total training time: 13.37 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 0.38, NNZs: 6557, Bias: -0.000095, T: 184023, Avg. loss: 0.001704\n",
      "Total training time: 13.55 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 0.39, NNZs: 6535, Bias: -0.000100, T: 186690, Avg. loss: 0.001659\n",
      "Total training time: 13.74 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 0.39, NNZs: 6517, Bias: -0.000136, T: 189357, Avg. loss: 0.001628\n",
      "Total training time: 13.93 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 0.39, NNZs: 6505, Bias: -0.000125, T: 192024, Avg. loss: 0.001623\n",
      "Total training time: 14.12 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 0.39, NNZs: 6494, Bias: -0.000146, T: 194691, Avg. loss: 0.001593\n",
      "Total training time: 14.31 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 0.40, NNZs: 6463, Bias: -0.000135, T: 197358, Avg. loss: 0.001533\n",
      "Total training time: 14.49 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 0.40, NNZs: 6449, Bias: -0.000129, T: 200025, Avg. loss: 0.001551\n",
      "Total training time: 14.68 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 0.40, NNZs: 6432, Bias: -0.000138, T: 202692, Avg. loss: 0.001523\n",
      "Total training time: 14.87 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 0.41, NNZs: 6410, Bias: -0.000149, T: 205359, Avg. loss: 0.001489\n",
      "Total training time: 15.05 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 0.41, NNZs: 6401, Bias: -0.000145, T: 208026, Avg. loss: 0.001457\n",
      "Total training time: 15.25 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 0.41, NNZs: 6385, Bias: -0.000151, T: 210693, Avg. loss: 0.001469\n",
      "Total training time: 15.43 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 0.41, NNZs: 6369, Bias: -0.000154, T: 213360, Avg. loss: 0.001425\n",
      "Total training time: 15.62 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 0.42, NNZs: 6356, Bias: -0.000168, T: 216027, Avg. loss: 0.001407\n",
      "Total training time: 15.80 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 0.42, NNZs: 6335, Bias: -0.000150, T: 218694, Avg. loss: 0.001411\n",
      "Total training time: 15.99 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 0.42, NNZs: 6325, Bias: -0.000173, T: 221361, Avg. loss: 0.001374\n",
      "Total training time: 16.18 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 0.42, NNZs: 6307, Bias: -0.000175, T: 224028, Avg. loss: 0.001371\n",
      "Total training time: 16.37 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 0.42, NNZs: 6284, Bias: -0.000174, T: 226695, Avg. loss: 0.001343\n",
      "Total training time: 16.57 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 0.43, NNZs: 6270, Bias: -0.000174, T: 229362, Avg. loss: 0.001314\n",
      "Total training time: 16.76 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 0.43, NNZs: 6252, Bias: -0.000182, T: 232029, Avg. loss: 0.001300\n",
      "Total training time: 16.95 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 0.43, NNZs: 6235, Bias: -0.000176, T: 234696, Avg. loss: 0.001295\n",
      "Total training time: 17.15 seconds.\n",
      "-- Epoch 89\n",
      "Norm: 0.43, NNZs: 6212, Bias: -0.000208, T: 237363, Avg. loss: 0.001269\n",
      "Total training time: 17.34 seconds.\n",
      "-- Epoch 90\n",
      "Norm: 0.44, NNZs: 6195, Bias: -0.000213, T: 240030, Avg. loss: 0.001250\n",
      "Total training time: 17.53 seconds.\n",
      "-- Epoch 91\n",
      "Norm: 0.44, NNZs: 6184, Bias: -0.000217, T: 242697, Avg. loss: 0.001246\n",
      "Total training time: 17.72 seconds.\n",
      "-- Epoch 92\n",
      "Norm: 0.44, NNZs: 6167, Bias: -0.000216, T: 245364, Avg. loss: 0.001233\n",
      "Total training time: 17.91 seconds.\n",
      "-- Epoch 93\n",
      "Norm: 0.44, NNZs: 6155, Bias: -0.000223, T: 248031, Avg. loss: 0.001210\n",
      "Total training time: 18.11 seconds.\n",
      "-- Epoch 94\n",
      "Norm: 0.44, NNZs: 6136, Bias: -0.000224, T: 250698, Avg. loss: 0.001186\n",
      "Total training time: 18.29 seconds.\n",
      "-- Epoch 95\n",
      "Norm: 0.45, NNZs: 6126, Bias: -0.000228, T: 253365, Avg. loss: 0.001185\n",
      "Total training time: 18.47 seconds.\n",
      "-- Epoch 96\n",
      "Norm: 0.45, NNZs: 6111, Bias: -0.000225, T: 256032, Avg. loss: 0.001172\n",
      "Total training time: 18.65 seconds.\n",
      "-- Epoch 97\n",
      "Norm: 0.45, NNZs: 6089, Bias: -0.000228, T: 258699, Avg. loss: 0.001162\n",
      "Total training time: 18.85 seconds.\n",
      "-- Epoch 98\n",
      "Norm: 0.45, NNZs: 6078, Bias: -0.000249, T: 261366, Avg. loss: 0.001138\n",
      "Total training time: 19.03 seconds.\n",
      "-- Epoch 99\n",
      "Norm: 0.46, NNZs: 6068, Bias: -0.000229, T: 264033, Avg. loss: 0.001128\n",
      "Total training time: 19.21 seconds.\n",
      "-- Epoch 100\n",
      "Norm: 0.46, NNZs: 6046, Bias: -0.000251, T: 266700, Avg. loss: 0.001132\n",
      "Total training time: 19.39 seconds.\n",
      "-- Epoch 101\n",
      "Norm: 0.46, NNZs: 6035, Bias: -0.000240, T: 269367, Avg. loss: 0.001095\n",
      "Total training time: 19.58 seconds.\n",
      "-- Epoch 102\n",
      "Norm: 0.46, NNZs: 6028, Bias: -0.000242, T: 272034, Avg. loss: 0.001089\n",
      "Total training time: 19.76 seconds.\n",
      "-- Epoch 103\n",
      "Norm: 0.46, NNZs: 6019, Bias: -0.000254, T: 274701, Avg. loss: 0.001071\n",
      "Total training time: 19.95 seconds.\n",
      "-- Epoch 104\n",
      "Norm: 0.47, NNZs: 6005, Bias: -0.000273, T: 277368, Avg. loss: 0.001061\n",
      "Total training time: 20.13 seconds.\n",
      "-- Epoch 105\n",
      "Norm: 0.47, NNZs: 5990, Bias: -0.000263, T: 280035, Avg. loss: 0.001069\n",
      "Total training time: 20.32 seconds.\n",
      "-- Epoch 106\n",
      "Norm: 0.47, NNZs: 5973, Bias: -0.000274, T: 282702, Avg. loss: 0.001049\n",
      "Total training time: 20.51 seconds.\n",
      "-- Epoch 107\n",
      "Norm: 0.47, NNZs: 5965, Bias: -0.000267, T: 285369, Avg. loss: 0.001038\n",
      "Total training time: 20.70 seconds.\n",
      "-- Epoch 108\n",
      "Norm: 0.47, NNZs: 5949, Bias: -0.000282, T: 288036, Avg. loss: 0.001028\n",
      "Total training time: 20.88 seconds.\n",
      "-- Epoch 109\n",
      "Norm: 0.47, NNZs: 5929, Bias: -0.000296, T: 290703, Avg. loss: 0.001018\n",
      "Total training time: 21.06 seconds.\n",
      "-- Epoch 110\n",
      "Norm: 0.48, NNZs: 5926, Bias: -0.000277, T: 293370, Avg. loss: 0.001007\n",
      "Total training time: 21.25 seconds.\n",
      "-- Epoch 111\n",
      "Norm: 0.48, NNZs: 5906, Bias: -0.000298, T: 296037, Avg. loss: 0.000995\n",
      "Total training time: 21.44 seconds.\n",
      "-- Epoch 112\n",
      "Norm: 0.48, NNZs: 5895, Bias: -0.000315, T: 298704, Avg. loss: 0.000990\n",
      "Total training time: 21.63 seconds.\n",
      "-- Epoch 113\n",
      "Norm: 0.48, NNZs: 5876, Bias: -0.000309, T: 301371, Avg. loss: 0.000985\n",
      "Total training time: 21.83 seconds.\n",
      "-- Epoch 114\n",
      "Norm: 0.48, NNZs: 5856, Bias: -0.000316, T: 304038, Avg. loss: 0.000971\n",
      "Total training time: 22.02 seconds.\n",
      "-- Epoch 115\n",
      "Norm: 0.49, NNZs: 5840, Bias: -0.000311, T: 306705, Avg. loss: 0.000960\n",
      "Total training time: 22.21 seconds.\n",
      "-- Epoch 116\n",
      "Norm: 0.49, NNZs: 5824, Bias: -0.000317, T: 309372, Avg. loss: 0.000961\n",
      "Total training time: 22.40 seconds.\n",
      "-- Epoch 117\n",
      "Norm: 0.49, NNZs: 5802, Bias: -0.000313, T: 312039, Avg. loss: 0.000943\n",
      "Total training time: 22.59 seconds.\n",
      "-- Epoch 118\n",
      "Norm: 0.49, NNZs: 5787, Bias: -0.000315, T: 314706, Avg. loss: 0.000934\n",
      "Total training time: 22.76 seconds.\n",
      "-- Epoch 119\n",
      "Norm: 0.49, NNZs: 5769, Bias: -0.000318, T: 317373, Avg. loss: 0.000923\n",
      "Total training time: 22.94 seconds.\n",
      "-- Epoch 120\n",
      "Norm: 0.49, NNZs: 5758, Bias: -0.000340, T: 320040, Avg. loss: 0.000909\n",
      "Total training time: 23.13 seconds.\n",
      "-- Epoch 121\n",
      "Norm: 0.50, NNZs: 5747, Bias: -0.000336, T: 322707, Avg. loss: 0.000910\n",
      "Total training time: 23.31 seconds.\n",
      "-- Epoch 122\n",
      "Norm: 0.50, NNZs: 5729, Bias: -0.000338, T: 325374, Avg. loss: 0.000903\n",
      "Total training time: 23.49 seconds.\n",
      "-- Epoch 123\n",
      "Norm: 0.50, NNZs: 5718, Bias: -0.000337, T: 328041, Avg. loss: 0.000889\n",
      "Total training time: 23.67 seconds.\n",
      "-- Epoch 124\n",
      "Norm: 0.50, NNZs: 5709, Bias: -0.000357, T: 330708, Avg. loss: 0.000885\n",
      "Total training time: 23.86 seconds.\n",
      "-- Epoch 125\n",
      "Norm: 0.50, NNZs: 5699, Bias: -0.000346, T: 333375, Avg. loss: 0.000880\n",
      "Total training time: 24.05 seconds.\n",
      "-- Epoch 126\n",
      "Norm: 0.50, NNZs: 5686, Bias: -0.000355, T: 336042, Avg. loss: 0.000875\n",
      "Total training time: 24.23 seconds.\n",
      "-- Epoch 127\n",
      "Norm: 0.51, NNZs: 5666, Bias: -0.000353, T: 338709, Avg. loss: 0.000868\n",
      "Total training time: 24.42 seconds.\n",
      "-- Epoch 128\n",
      "Norm: 0.51, NNZs: 5653, Bias: -0.000354, T: 341376, Avg. loss: 0.000854\n",
      "Total training time: 24.61 seconds.\n",
      "-- Epoch 129\n",
      "Norm: 0.51, NNZs: 5641, Bias: -0.000362, T: 344043, Avg. loss: 0.000842\n",
      "Total training time: 24.79 seconds.\n",
      "-- Epoch 130\n",
      "Norm: 0.51, NNZs: 5627, Bias: -0.000387, T: 346710, Avg. loss: 0.000844\n",
      "Total training time: 24.98 seconds.\n",
      "-- Epoch 131\n",
      "Norm: 0.51, NNZs: 5616, Bias: -0.000365, T: 349377, Avg. loss: 0.000846\n",
      "Total training time: 25.17 seconds.\n",
      "-- Epoch 132\n",
      "Norm: 0.51, NNZs: 5610, Bias: -0.000388, T: 352044, Avg. loss: 0.000832\n",
      "Total training time: 25.36 seconds.\n",
      "-- Epoch 133\n",
      "Norm: 0.52, NNZs: 5594, Bias: -0.000394, T: 354711, Avg. loss: 0.000832\n",
      "Total training time: 25.54 seconds.\n",
      "-- Epoch 134\n",
      "Norm: 0.52, NNZs: 5586, Bias: -0.000386, T: 357378, Avg. loss: 0.000825\n",
      "Total training time: 25.73 seconds.\n",
      "-- Epoch 135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 0.52, NNZs: 5568, Bias: -0.000392, T: 360045, Avg. loss: 0.000811\n",
      "Total training time: 25.92 seconds.\n",
      "-- Epoch 136\n",
      "Norm: 0.52, NNZs: 5560, Bias: -0.000405, T: 362712, Avg. loss: 0.000800\n",
      "Total training time: 26.11 seconds.\n",
      "-- Epoch 137\n",
      "Norm: 0.52, NNZs: 5544, Bias: -0.000418, T: 365379, Avg. loss: 0.000802\n",
      "Total training time: 26.29 seconds.\n",
      "-- Epoch 138\n",
      "Norm: 0.52, NNZs: 5525, Bias: -0.000420, T: 368046, Avg. loss: 0.000800\n",
      "Total training time: 26.48 seconds.\n",
      "Convergence after 138 epochs took 26.48 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.02, NNZs: 8715, Bias: 0.000192, T: 2667, Avg. loss: 0.011498\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.03, NNZs: 8195, Bias: 0.000202, T: 5334, Avg. loss: 0.010798\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.04, NNZs: 8021, Bias: 0.000194, T: 8001, Avg. loss: 0.010460\n",
      "Total training time: 0.57 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.05, NNZs: 7965, Bias: 0.000219, T: 10668, Avg. loss: 0.009866\n",
      "Total training time: 0.78 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.06, NNZs: 7880, Bias: 0.000165, T: 13335, Avg. loss: 0.009557\n",
      "Total training time: 0.98 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.07, NNZs: 7859, Bias: 0.000163, T: 16002, Avg. loss: 0.009130\n",
      "Total training time: 1.18 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.08, NNZs: 7790, Bias: 0.000177, T: 18669, Avg. loss: 0.008901\n",
      "Total training time: 1.37 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.09, NNZs: 7780, Bias: 0.000173, T: 21336, Avg. loss: 0.008589\n",
      "Total training time: 1.57 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.10, NNZs: 7776, Bias: 0.000132, T: 24003, Avg. loss: 0.008237\n",
      "Total training time: 1.77 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.11, NNZs: 7747, Bias: 0.000136, T: 26670, Avg. loss: 0.007906\n",
      "Total training time: 1.97 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.12, NNZs: 7728, Bias: 0.000148, T: 29337, Avg. loss: 0.007646\n",
      "Total training time: 2.16 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.12, NNZs: 7702, Bias: 0.000127, T: 32004, Avg. loss: 0.007362\n",
      "Total training time: 2.36 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.13, NNZs: 7703, Bias: 0.000144, T: 34671, Avg. loss: 0.007088\n",
      "Total training time: 2.57 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 0.14, NNZs: 7656, Bias: 0.000100, T: 37338, Avg. loss: 0.006823\n",
      "Total training time: 2.76 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 0.15, NNZs: 7642, Bias: 0.000125, T: 40005, Avg. loss: 0.006571\n",
      "Total training time: 2.96 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 0.15, NNZs: 7615, Bias: 0.000136, T: 42672, Avg. loss: 0.006349\n",
      "Total training time: 3.17 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 0.16, NNZs: 7602, Bias: 0.000104, T: 45339, Avg. loss: 0.006236\n",
      "Total training time: 3.37 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 0.17, NNZs: 7593, Bias: 0.000120, T: 48006, Avg. loss: 0.005983\n",
      "Total training time: 3.56 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.17, NNZs: 7562, Bias: 0.000120, T: 50673, Avg. loss: 0.005814\n",
      "Total training time: 3.76 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 0.18, NNZs: 7537, Bias: 0.000096, T: 53340, Avg. loss: 0.005552\n",
      "Total training time: 3.95 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 0.19, NNZs: 7532, Bias: 0.000066, T: 56007, Avg. loss: 0.005486\n",
      "Total training time: 4.15 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.19, NNZs: 7495, Bias: 0.000060, T: 58674, Avg. loss: 0.005236\n",
      "Total training time: 4.33 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 0.20, NNZs: 7492, Bias: 0.000068, T: 61341, Avg. loss: 0.005074\n",
      "Total training time: 4.54 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 0.21, NNZs: 7455, Bias: 0.000070, T: 64008, Avg. loss: 0.004907\n",
      "Total training time: 4.73 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 0.21, NNZs: 7447, Bias: 0.000063, T: 66675, Avg. loss: 0.004818\n",
      "Total training time: 4.92 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 0.22, NNZs: 7428, Bias: 0.000046, T: 69342, Avg. loss: 0.004690\n",
      "Total training time: 5.12 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 0.22, NNZs: 7399, Bias: 0.000029, T: 72009, Avg. loss: 0.004535\n",
      "Total training time: 5.31 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 0.23, NNZs: 7388, Bias: 0.000003, T: 74676, Avg. loss: 0.004344\n",
      "Total training time: 5.50 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 0.24, NNZs: 7355, Bias: 0.000022, T: 77343, Avg. loss: 0.004263\n",
      "Total training time: 5.70 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 0.24, NNZs: 7341, Bias: 0.000037, T: 80010, Avg. loss: 0.004163\n",
      "Total training time: 5.89 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 0.25, NNZs: 7308, Bias: 0.000022, T: 82677, Avg. loss: 0.004024\n",
      "Total training time: 6.09 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 0.25, NNZs: 7298, Bias: 0.000009, T: 85344, Avg. loss: 0.003879\n",
      "Total training time: 6.29 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.26, NNZs: 7271, Bias: 0.000005, T: 88011, Avg. loss: 0.003797\n",
      "Total training time: 6.50 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.26, NNZs: 7243, Bias: 0.000010, T: 90678, Avg. loss: 0.003695\n",
      "Total training time: 6.70 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 0.27, NNZs: 7225, Bias: 0.000022, T: 93345, Avg. loss: 0.003608\n",
      "Total training time: 6.90 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 0.27, NNZs: 7203, Bias: 0.000001, T: 96012, Avg. loss: 0.003508\n",
      "Total training time: 7.11 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 0.28, NNZs: 7187, Bias: -0.000009, T: 98679, Avg. loss: 0.003440\n",
      "Total training time: 7.30 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 0.28, NNZs: 7151, Bias: -0.000042, T: 101346, Avg. loss: 0.003299\n",
      "Total training time: 7.50 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 0.29, NNZs: 7134, Bias: -0.000010, T: 104013, Avg. loss: 0.003244\n",
      "Total training time: 7.69 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 0.29, NNZs: 7108, Bias: -0.000031, T: 106680, Avg. loss: 0.003161\n",
      "Total training time: 7.89 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 0.29, NNZs: 7087, Bias: -0.000039, T: 109347, Avg. loss: 0.003104\n",
      "Total training time: 8.09 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 0.30, NNZs: 7076, Bias: -0.000040, T: 112014, Avg. loss: 0.003031\n",
      "Total training time: 8.29 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 0.30, NNZs: 7058, Bias: -0.000045, T: 114681, Avg. loss: 0.002960\n",
      "Total training time: 8.49 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 0.31, NNZs: 7032, Bias: -0.000060, T: 117348, Avg. loss: 0.002923\n",
      "Total training time: 8.68 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 0.31, NNZs: 7020, Bias: -0.000046, T: 120015, Avg. loss: 0.002808\n",
      "Total training time: 8.87 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 0.32, NNZs: 6999, Bias: -0.000087, T: 122682, Avg. loss: 0.002752\n",
      "Total training time: 9.07 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 0.32, NNZs: 6983, Bias: -0.000072, T: 125349, Avg. loss: 0.002698\n",
      "Total training time: 9.27 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 0.32, NNZs: 6962, Bias: -0.000074, T: 128016, Avg. loss: 0.002631\n",
      "Total training time: 9.46 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 0.33, NNZs: 6939, Bias: -0.000086, T: 130683, Avg. loss: 0.002560\n",
      "Total training time: 9.65 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 0.33, NNZs: 6922, Bias: -0.000077, T: 133350, Avg. loss: 0.002530\n",
      "Total training time: 9.84 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 0.33, NNZs: 6899, Bias: -0.000075, T: 136017, Avg. loss: 0.002481\n",
      "Total training time: 10.03 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 0.34, NNZs: 6877, Bias: -0.000106, T: 138684, Avg. loss: 0.002404\n",
      "Total training time: 10.22 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 0.34, NNZs: 6851, Bias: -0.000096, T: 141351, Avg. loss: 0.002349\n",
      "Total training time: 10.42 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 0.35, NNZs: 6820, Bias: -0.000092, T: 144018, Avg. loss: 0.002312\n",
      "Total training time: 10.61 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 0.35, NNZs: 6801, Bias: -0.000107, T: 146685, Avg. loss: 0.002285\n",
      "Total training time: 10.81 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 0.35, NNZs: 6782, Bias: -0.000109, T: 149352, Avg. loss: 0.002200\n",
      "Total training time: 11.01 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 0.36, NNZs: 6773, Bias: -0.000117, T: 152019, Avg. loss: 0.002157\n",
      "Total training time: 11.21 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 0.36, NNZs: 6756, Bias: -0.000130, T: 154686, Avg. loss: 0.002123\n",
      "Total training time: 11.40 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 0.36, NNZs: 6736, Bias: -0.000115, T: 157353, Avg. loss: 0.002070\n",
      "Total training time: 11.60 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 0.37, NNZs: 6722, Bias: -0.000148, T: 160020, Avg. loss: 0.002046\n",
      "Total training time: 11.80 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 0.37, NNZs: 6704, Bias: -0.000152, T: 162687, Avg. loss: 0.002022\n",
      "Total training time: 11.99 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 0.37, NNZs: 6685, Bias: -0.000173, T: 165354, Avg. loss: 0.001969\n",
      "Total training time: 12.18 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 0.38, NNZs: 6659, Bias: -0.000152, T: 168021, Avg. loss: 0.001937\n",
      "Total training time: 12.37 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 0.38, NNZs: 6635, Bias: -0.000169, T: 170688, Avg. loss: 0.001912\n",
      "Total training time: 12.56 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 0.38, NNZs: 6617, Bias: -0.000165, T: 173355, Avg. loss: 0.001859\n",
      "Total training time: 12.76 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 0.38, NNZs: 6603, Bias: -0.000173, T: 176022, Avg. loss: 0.001828\n",
      "Total training time: 12.95 seconds.\n",
      "-- Epoch 67\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 0.39, NNZs: 6586, Bias: -0.000175, T: 178689, Avg. loss: 0.001789\n",
      "Total training time: 13.14 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 0.39, NNZs: 6557, Bias: -0.000177, T: 181356, Avg. loss: 0.001776\n",
      "Total training time: 13.32 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 0.39, NNZs: 6542, Bias: -0.000176, T: 184023, Avg. loss: 0.001724\n",
      "Total training time: 13.52 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 0.40, NNZs: 6523, Bias: -0.000201, T: 186690, Avg. loss: 0.001715\n",
      "Total training time: 13.71 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 0.40, NNZs: 6501, Bias: -0.000199, T: 189357, Avg. loss: 0.001668\n",
      "Total training time: 13.91 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 0.40, NNZs: 6494, Bias: -0.000213, T: 192024, Avg. loss: 0.001647\n",
      "Total training time: 14.11 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 0.40, NNZs: 6471, Bias: -0.000209, T: 194691, Avg. loss: 0.001615\n",
      "Total training time: 14.31 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 0.41, NNZs: 6449, Bias: -0.000224, T: 197358, Avg. loss: 0.001594\n",
      "Total training time: 14.50 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 0.41, NNZs: 6430, Bias: -0.000215, T: 200025, Avg. loss: 0.001591\n",
      "Total training time: 14.70 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 0.41, NNZs: 6412, Bias: -0.000227, T: 202692, Avg. loss: 0.001543\n",
      "Total training time: 14.89 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 0.42, NNZs: 6399, Bias: -0.000225, T: 205359, Avg. loss: 0.001530\n",
      "Total training time: 15.09 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 0.42, NNZs: 6382, Bias: -0.000225, T: 208026, Avg. loss: 0.001519\n",
      "Total training time: 15.28 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 0.42, NNZs: 6367, Bias: -0.000237, T: 210693, Avg. loss: 0.001489\n",
      "Total training time: 15.48 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 0.42, NNZs: 6355, Bias: -0.000234, T: 213360, Avg. loss: 0.001466\n",
      "Total training time: 15.67 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 0.43, NNZs: 6338, Bias: -0.000248, T: 216027, Avg. loss: 0.001454\n",
      "Total training time: 15.86 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 0.43, NNZs: 6321, Bias: -0.000259, T: 218694, Avg. loss: 0.001434\n",
      "Total training time: 16.05 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 0.43, NNZs: 6310, Bias: -0.000254, T: 221361, Avg. loss: 0.001415\n",
      "Total training time: 16.24 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 0.43, NNZs: 6295, Bias: -0.000275, T: 224028, Avg. loss: 0.001402\n",
      "Total training time: 16.43 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 0.44, NNZs: 6277, Bias: -0.000268, T: 226695, Avg. loss: 0.001366\n",
      "Total training time: 16.62 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 0.44, NNZs: 6259, Bias: -0.000262, T: 229362, Avg. loss: 0.001342\n",
      "Total training time: 16.82 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 0.44, NNZs: 6234, Bias: -0.000288, T: 232029, Avg. loss: 0.001335\n",
      "Total training time: 17.01 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 0.44, NNZs: 6225, Bias: -0.000291, T: 234696, Avg. loss: 0.001303\n",
      "Total training time: 17.20 seconds.\n",
      "-- Epoch 89\n",
      "Norm: 0.44, NNZs: 6208, Bias: -0.000274, T: 237363, Avg. loss: 0.001289\n",
      "Total training time: 17.39 seconds.\n",
      "-- Epoch 90\n",
      "Norm: 0.45, NNZs: 6198, Bias: -0.000294, T: 240030, Avg. loss: 0.001278\n",
      "Total training time: 17.57 seconds.\n",
      "-- Epoch 91\n",
      "Norm: 0.45, NNZs: 6189, Bias: -0.000294, T: 242697, Avg. loss: 0.001278\n",
      "Total training time: 17.76 seconds.\n",
      "-- Epoch 92\n",
      "Norm: 0.45, NNZs: 6174, Bias: -0.000309, T: 245364, Avg. loss: 0.001248\n",
      "Total training time: 17.95 seconds.\n",
      "-- Epoch 93\n",
      "Norm: 0.45, NNZs: 6161, Bias: -0.000314, T: 248031, Avg. loss: 0.001230\n",
      "Total training time: 18.14 seconds.\n",
      "-- Epoch 94\n",
      "Norm: 0.46, NNZs: 6146, Bias: -0.000314, T: 250698, Avg. loss: 0.001226\n",
      "Total training time: 18.32 seconds.\n",
      "-- Epoch 95\n",
      "Norm: 0.46, NNZs: 6135, Bias: -0.000316, T: 253365, Avg. loss: 0.001196\n",
      "Total training time: 18.51 seconds.\n",
      "-- Epoch 96\n",
      "Norm: 0.46, NNZs: 6120, Bias: -0.000319, T: 256032, Avg. loss: 0.001190\n",
      "Total training time: 18.69 seconds.\n",
      "-- Epoch 97\n",
      "Norm: 0.46, NNZs: 6099, Bias: -0.000327, T: 258699, Avg. loss: 0.001184\n",
      "Total training time: 18.87 seconds.\n",
      "-- Epoch 98\n",
      "Norm: 0.46, NNZs: 6086, Bias: -0.000332, T: 261366, Avg. loss: 0.001158\n",
      "Total training time: 19.05 seconds.\n",
      "-- Epoch 99\n",
      "Norm: 0.47, NNZs: 6063, Bias: -0.000349, T: 264033, Avg. loss: 0.001148\n",
      "Total training time: 19.24 seconds.\n",
      "-- Epoch 100\n",
      "Norm: 0.47, NNZs: 6052, Bias: -0.000347, T: 266700, Avg. loss: 0.001142\n",
      "Total training time: 19.42 seconds.\n",
      "-- Epoch 101\n",
      "Norm: 0.47, NNZs: 6040, Bias: -0.000353, T: 269367, Avg. loss: 0.001131\n",
      "Total training time: 19.60 seconds.\n",
      "-- Epoch 102\n",
      "Norm: 0.47, NNZs: 6023, Bias: -0.000354, T: 272034, Avg. loss: 0.001110\n",
      "Total training time: 19.78 seconds.\n",
      "-- Epoch 103\n",
      "Norm: 0.47, NNZs: 6012, Bias: -0.000349, T: 274701, Avg. loss: 0.001099\n",
      "Total training time: 19.96 seconds.\n",
      "-- Epoch 104\n",
      "Norm: 0.48, NNZs: 5991, Bias: -0.000361, T: 277368, Avg. loss: 0.001086\n",
      "Total training time: 20.14 seconds.\n",
      "-- Epoch 105\n",
      "Norm: 0.48, NNZs: 5978, Bias: -0.000371, T: 280035, Avg. loss: 0.001081\n",
      "Total training time: 20.32 seconds.\n",
      "-- Epoch 106\n",
      "Norm: 0.48, NNZs: 5959, Bias: -0.000376, T: 282702, Avg. loss: 0.001058\n",
      "Total training time: 20.52 seconds.\n",
      "-- Epoch 107\n",
      "Norm: 0.48, NNZs: 5941, Bias: -0.000382, T: 285369, Avg. loss: 0.001046\n",
      "Total training time: 20.71 seconds.\n",
      "-- Epoch 108\n",
      "Norm: 0.48, NNZs: 5929, Bias: -0.000389, T: 288036, Avg. loss: 0.001044\n",
      "Total training time: 20.90 seconds.\n",
      "-- Epoch 109\n",
      "Norm: 0.49, NNZs: 5915, Bias: -0.000396, T: 290703, Avg. loss: 0.001041\n",
      "Total training time: 21.08 seconds.\n",
      "-- Epoch 110\n",
      "Norm: 0.49, NNZs: 5895, Bias: -0.000389, T: 293370, Avg. loss: 0.001031\n",
      "Total training time: 21.26 seconds.\n",
      "-- Epoch 111\n",
      "Norm: 0.49, NNZs: 5879, Bias: -0.000400, T: 296037, Avg. loss: 0.001013\n",
      "Total training time: 21.44 seconds.\n",
      "-- Epoch 112\n",
      "Norm: 0.49, NNZs: 5871, Bias: -0.000402, T: 298704, Avg. loss: 0.001010\n",
      "Total training time: 21.62 seconds.\n",
      "-- Epoch 113\n",
      "Norm: 0.49, NNZs: 5859, Bias: -0.000424, T: 301371, Avg. loss: 0.000979\n",
      "Total training time: 21.80 seconds.\n",
      "-- Epoch 114\n",
      "Norm: 0.50, NNZs: 5849, Bias: -0.000407, T: 304038, Avg. loss: 0.000981\n",
      "Total training time: 21.99 seconds.\n",
      "-- Epoch 115\n",
      "Norm: 0.50, NNZs: 5831, Bias: -0.000426, T: 306705, Avg. loss: 0.000973\n",
      "Total training time: 22.18 seconds.\n",
      "-- Epoch 116\n",
      "Norm: 0.50, NNZs: 5817, Bias: -0.000422, T: 309372, Avg. loss: 0.000964\n",
      "Total training time: 22.37 seconds.\n",
      "-- Epoch 117\n",
      "Norm: 0.50, NNZs: 5800, Bias: -0.000428, T: 312039, Avg. loss: 0.000949\n",
      "Total training time: 22.56 seconds.\n",
      "-- Epoch 118\n",
      "Norm: 0.50, NNZs: 5792, Bias: -0.000445, T: 314706, Avg. loss: 0.000945\n",
      "Total training time: 22.75 seconds.\n",
      "-- Epoch 119\n",
      "Norm: 0.50, NNZs: 5778, Bias: -0.000445, T: 317373, Avg. loss: 0.000944\n",
      "Total training time: 22.94 seconds.\n",
      "-- Epoch 120\n",
      "Norm: 0.51, NNZs: 5763, Bias: -0.000451, T: 320040, Avg. loss: 0.000928\n",
      "Total training time: 23.13 seconds.\n",
      "-- Epoch 121\n",
      "Norm: 0.51, NNZs: 5752, Bias: -0.000447, T: 322707, Avg. loss: 0.000919\n",
      "Total training time: 23.31 seconds.\n",
      "-- Epoch 122\n",
      "Norm: 0.51, NNZs: 5742, Bias: -0.000457, T: 325374, Avg. loss: 0.000913\n",
      "Total training time: 23.49 seconds.\n",
      "-- Epoch 123\n",
      "Norm: 0.51, NNZs: 5720, Bias: -0.000465, T: 328041, Avg. loss: 0.000893\n",
      "Total training time: 23.67 seconds.\n",
      "-- Epoch 124\n",
      "Norm: 0.51, NNZs: 5707, Bias: -0.000465, T: 330708, Avg. loss: 0.000900\n",
      "Total training time: 23.86 seconds.\n",
      "-- Epoch 125\n",
      "Norm: 0.52, NNZs: 5683, Bias: -0.000484, T: 333375, Avg. loss: 0.000898\n",
      "Total training time: 24.05 seconds.\n",
      "-- Epoch 126\n",
      "Norm: 0.52, NNZs: 5666, Bias: -0.000476, T: 336042, Avg. loss: 0.000875\n",
      "Total training time: 24.24 seconds.\n",
      "-- Epoch 127\n",
      "Norm: 0.52, NNZs: 5650, Bias: -0.000491, T: 338709, Avg. loss: 0.000874\n",
      "Total training time: 24.42 seconds.\n",
      "-- Epoch 128\n",
      "Norm: 0.52, NNZs: 5636, Bias: -0.000492, T: 341376, Avg. loss: 0.000875\n",
      "Total training time: 24.59 seconds.\n",
      "-- Epoch 129\n",
      "Norm: 0.52, NNZs: 5617, Bias: -0.000492, T: 344043, Avg. loss: 0.000848\n",
      "Total training time: 24.77 seconds.\n",
      "-- Epoch 130\n",
      "Norm: 0.52, NNZs: 5602, Bias: -0.000485, T: 346710, Avg. loss: 0.000852\n",
      "Total training time: 24.96 seconds.\n",
      "-- Epoch 131\n",
      "Norm: 0.52, NNZs: 5584, Bias: -0.000510, T: 349377, Avg. loss: 0.000842\n",
      "Total training time: 25.14 seconds.\n",
      "-- Epoch 132\n",
      "Norm: 0.53, NNZs: 5576, Bias: -0.000513, T: 352044, Avg. loss: 0.000839\n",
      "Total training time: 25.32 seconds.\n",
      "-- Epoch 133\n",
      "Norm: 0.53, NNZs: 5561, Bias: -0.000516, T: 354711, Avg. loss: 0.000832\n",
      "Total training time: 25.49 seconds.\n",
      "-- Epoch 134\n",
      "Norm: 0.53, NNZs: 5547, Bias: -0.000510, T: 357378, Avg. loss: 0.000832\n",
      "Total training time: 25.66 seconds.\n",
      "-- Epoch 135\n",
      "Norm: 0.53, NNZs: 5531, Bias: -0.000525, T: 360045, Avg. loss: 0.000822\n",
      "Total training time: 25.84 seconds.\n",
      "-- Epoch 136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 0.53, NNZs: 5526, Bias: -0.000516, T: 362712, Avg. loss: 0.000821\n",
      "Total training time: 26.02 seconds.\n",
      "-- Epoch 137\n",
      "Norm: 0.53, NNZs: 5512, Bias: -0.000531, T: 365379, Avg. loss: 0.000807\n",
      "Total training time: 26.20 seconds.\n",
      "-- Epoch 138\n",
      "Norm: 0.54, NNZs: 5492, Bias: -0.000535, T: 368046, Avg. loss: 0.000800\n",
      "Total training time: 26.37 seconds.\n",
      "-- Epoch 139\n",
      "Norm: 0.54, NNZs: 5477, Bias: -0.000550, T: 370713, Avg. loss: 0.000798\n",
      "Total training time: 26.55 seconds.\n",
      "-- Epoch 140\n",
      "Norm: 0.54, NNZs: 5462, Bias: -0.000554, T: 373380, Avg. loss: 0.000795\n",
      "Total training time: 26.73 seconds.\n",
      "-- Epoch 141\n",
      "Norm: 0.54, NNZs: 5445, Bias: -0.000556, T: 376047, Avg. loss: 0.000790\n",
      "Total training time: 26.91 seconds.\n",
      "-- Epoch 142\n",
      "Norm: 0.54, NNZs: 5434, Bias: -0.000564, T: 378714, Avg. loss: 0.000783\n",
      "Total training time: 27.09 seconds.\n",
      "-- Epoch 143\n",
      "Norm: 0.54, NNZs: 5421, Bias: -0.000580, T: 381381, Avg. loss: 0.000770\n",
      "Total training time: 27.28 seconds.\n",
      "-- Epoch 144\n",
      "Norm: 0.55, NNZs: 5404, Bias: -0.000569, T: 384048, Avg. loss: 0.000777\n",
      "Total training time: 27.46 seconds.\n",
      "-- Epoch 145\n",
      "Norm: 0.55, NNZs: 5394, Bias: -0.000580, T: 386715, Avg. loss: 0.000764\n",
      "Total training time: 27.65 seconds.\n",
      "Convergence after 145 epochs took 27.65 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.02, NNZs: 7688, Bias: 0.000272, T: 2666, Avg. loss: 0.011423\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.04, NNZs: 6111, Bias: 0.000286, T: 5332, Avg. loss: 0.010711\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.05, NNZs: 5651, Bias: 0.000311, T: 7998, Avg. loss: 0.010346\n",
      "Total training time: 0.54 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.06, NNZs: 5441, Bias: 0.000321, T: 10664, Avg. loss: 0.009967\n",
      "Total training time: 0.73 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.07, NNZs: 5264, Bias: 0.000284, T: 13330, Avg. loss: 0.009700\n",
      "Total training time: 0.91 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.08, NNZs: 5167, Bias: 0.000273, T: 15996, Avg. loss: 0.009385\n",
      "Total training time: 1.09 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.09, NNZs: 5102, Bias: 0.000284, T: 18662, Avg. loss: 0.009131\n",
      "Total training time: 1.28 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.10, NNZs: 5034, Bias: 0.000288, T: 21328, Avg. loss: 0.008897\n",
      "Total training time: 1.46 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.11, NNZs: 4974, Bias: 0.000278, T: 23994, Avg. loss: 0.008651\n",
      "Total training time: 1.65 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.11, NNZs: 4911, Bias: 0.000277, T: 26660, Avg. loss: 0.008396\n",
      "Total training time: 1.83 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.12, NNZs: 4848, Bias: 0.000272, T: 29326, Avg. loss: 0.008213\n",
      "Total training time: 2.02 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.13, NNZs: 4802, Bias: 0.000247, T: 31992, Avg. loss: 0.007910\n",
      "Total training time: 2.20 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.14, NNZs: 4762, Bias: 0.000166, T: 34658, Avg. loss: 0.007728\n",
      "Total training time: 2.38 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 0.14, NNZs: 4756, Bias: 0.000237, T: 37324, Avg. loss: 0.007622\n",
      "Total training time: 2.55 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 0.15, NNZs: 4722, Bias: 0.000215, T: 39990, Avg. loss: 0.007422\n",
      "Total training time: 2.73 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 0.16, NNZs: 4683, Bias: 0.000218, T: 42656, Avg. loss: 0.007259\n",
      "Total training time: 2.91 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 0.16, NNZs: 4650, Bias: 0.000179, T: 45322, Avg. loss: 0.007067\n",
      "Total training time: 3.08 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 0.17, NNZs: 4618, Bias: 0.000177, T: 47988, Avg. loss: 0.006878\n",
      "Total training time: 3.26 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.18, NNZs: 4570, Bias: 0.000118, T: 50654, Avg. loss: 0.006777\n",
      "Total training time: 3.44 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 0.18, NNZs: 4549, Bias: 0.000121, T: 53320, Avg. loss: 0.006661\n",
      "Total training time: 3.62 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 0.19, NNZs: 4530, Bias: 0.000103, T: 55986, Avg. loss: 0.006516\n",
      "Total training time: 3.80 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.20, NNZs: 4504, Bias: 0.000109, T: 58652, Avg. loss: 0.006311\n",
      "Total training time: 3.97 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 0.20, NNZs: 4477, Bias: 0.000137, T: 61318, Avg. loss: 0.006179\n",
      "Total training time: 4.14 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 0.21, NNZs: 4448, Bias: 0.000120, T: 63984, Avg. loss: 0.006094\n",
      "Total training time: 4.30 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 0.22, NNZs: 4409, Bias: 0.000108, T: 66650, Avg. loss: 0.005976\n",
      "Total training time: 4.48 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 0.22, NNZs: 4388, Bias: 0.000085, T: 69316, Avg. loss: 0.005800\n",
      "Total training time: 4.66 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 0.23, NNZs: 4365, Bias: 0.000106, T: 71982, Avg. loss: 0.005695\n",
      "Total training time: 4.83 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 0.23, NNZs: 4342, Bias: 0.000099, T: 74648, Avg. loss: 0.005630\n",
      "Total training time: 5.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 0.24, NNZs: 4311, Bias: 0.000075, T: 77314, Avg. loss: 0.005472\n",
      "Total training time: 5.16 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 0.24, NNZs: 4280, Bias: 0.000059, T: 79980, Avg. loss: 0.005400\n",
      "Total training time: 5.33 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 0.25, NNZs: 4257, Bias: 0.000024, T: 82646, Avg. loss: 0.005276\n",
      "Total training time: 5.51 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 0.25, NNZs: 4235, Bias: 0.000034, T: 85312, Avg. loss: 0.005182\n",
      "Total training time: 5.68 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.26, NNZs: 4214, Bias: 0.000010, T: 87978, Avg. loss: 0.005067\n",
      "Total training time: 5.86 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.26, NNZs: 4181, Bias: -0.000015, T: 90644, Avg. loss: 0.004990\n",
      "Total training time: 6.03 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 0.27, NNZs: 4159, Bias: -0.000026, T: 93310, Avg. loss: 0.004936\n",
      "Total training time: 6.19 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 0.27, NNZs: 4128, Bias: -0.000041, T: 95976, Avg. loss: 0.004807\n",
      "Total training time: 6.36 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 0.28, NNZs: 4108, Bias: -0.000056, T: 98642, Avg. loss: 0.004732\n",
      "Total training time: 6.53 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 0.28, NNZs: 4082, Bias: -0.000037, T: 101308, Avg. loss: 0.004660\n",
      "Total training time: 6.70 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 0.29, NNZs: 4049, Bias: -0.000041, T: 103974, Avg. loss: 0.004596\n",
      "Total training time: 6.87 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 0.29, NNZs: 4037, Bias: -0.000030, T: 106640, Avg. loss: 0.004471\n",
      "Total training time: 7.03 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 0.30, NNZs: 4007, Bias: -0.000036, T: 109306, Avg. loss: 0.004389\n",
      "Total training time: 7.20 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 0.30, NNZs: 3982, Bias: -0.000115, T: 111972, Avg. loss: 0.004320\n",
      "Total training time: 7.37 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 0.31, NNZs: 3972, Bias: -0.000056, T: 114638, Avg. loss: 0.004315\n",
      "Total training time: 7.53 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 0.31, NNZs: 3937, Bias: -0.000090, T: 117304, Avg. loss: 0.004211\n",
      "Total training time: 7.70 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 0.32, NNZs: 3905, Bias: -0.000114, T: 119970, Avg. loss: 0.004132\n",
      "Total training time: 7.86 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 0.32, NNZs: 3891, Bias: -0.000140, T: 122636, Avg. loss: 0.004071\n",
      "Total training time: 8.02 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 0.32, NNZs: 3874, Bias: -0.000123, T: 125302, Avg. loss: 0.004043\n",
      "Total training time: 8.18 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 0.33, NNZs: 3846, Bias: -0.000158, T: 127968, Avg. loss: 0.003975\n",
      "Total training time: 8.35 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 0.33, NNZs: 3833, Bias: -0.000199, T: 130634, Avg. loss: 0.003915\n",
      "Total training time: 8.52 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 0.34, NNZs: 3816, Bias: -0.000134, T: 133300, Avg. loss: 0.003875\n",
      "Total training time: 8.68 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 0.34, NNZs: 3788, Bias: -0.000198, T: 135966, Avg. loss: 0.003818\n",
      "Total training time: 8.84 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 0.34, NNZs: 3765, Bias: -0.000215, T: 138632, Avg. loss: 0.003731\n",
      "Total training time: 9.01 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 0.35, NNZs: 3746, Bias: -0.000189, T: 141298, Avg. loss: 0.003692\n",
      "Total training time: 9.18 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 0.35, NNZs: 3723, Bias: -0.000213, T: 143964, Avg. loss: 0.003627\n",
      "Total training time: 9.35 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 0.36, NNZs: 3704, Bias: -0.000243, T: 146630, Avg. loss: 0.003610\n",
      "Total training time: 9.51 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 0.36, NNZs: 3680, Bias: -0.000254, T: 149296, Avg. loss: 0.003571\n",
      "Total training time: 9.67 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 0.36, NNZs: 3667, Bias: -0.000276, T: 151962, Avg. loss: 0.003529\n",
      "Total training time: 9.83 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 0.37, NNZs: 3649, Bias: -0.000292, T: 154628, Avg. loss: 0.003476\n",
      "Total training time: 10.00 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 0.37, NNZs: 3631, Bias: -0.000303, T: 157294, Avg. loss: 0.003426\n",
      "Total training time: 10.15 seconds.\n",
      "-- Epoch 60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 0.38, NNZs: 3615, Bias: -0.000272, T: 159960, Avg. loss: 0.003383\n",
      "Total training time: 10.32 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 0.38, NNZs: 3603, Bias: -0.000328, T: 162626, Avg. loss: 0.003345\n",
      "Total training time: 10.49 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 0.38, NNZs: 3584, Bias: -0.000294, T: 165292, Avg. loss: 0.003295\n",
      "Total training time: 10.65 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 0.39, NNZs: 3565, Bias: -0.000328, T: 167958, Avg. loss: 0.003267\n",
      "Total training time: 10.81 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 0.39, NNZs: 3552, Bias: -0.000333, T: 170624, Avg. loss: 0.003223\n",
      "Total training time: 10.97 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 0.39, NNZs: 3531, Bias: -0.000356, T: 173290, Avg. loss: 0.003195\n",
      "Total training time: 11.13 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 0.40, NNZs: 3511, Bias: -0.000372, T: 175956, Avg. loss: 0.003141\n",
      "Total training time: 11.30 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 0.40, NNZs: 3488, Bias: -0.000394, T: 178622, Avg. loss: 0.003084\n",
      "Total training time: 11.45 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 0.40, NNZs: 3473, Bias: -0.000400, T: 181288, Avg. loss: 0.003068\n",
      "Total training time: 11.62 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 0.41, NNZs: 3454, Bias: -0.000402, T: 183954, Avg. loss: 0.003064\n",
      "Total training time: 11.78 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 0.41, NNZs: 3438, Bias: -0.000440, T: 186620, Avg. loss: 0.003022\n",
      "Total training time: 11.95 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 0.41, NNZs: 3414, Bias: -0.000437, T: 189286, Avg. loss: 0.002970\n",
      "Total training time: 12.11 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 0.42, NNZs: 3396, Bias: -0.000459, T: 191952, Avg. loss: 0.002953\n",
      "Total training time: 12.27 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 0.42, NNZs: 3372, Bias: -0.000425, T: 194618, Avg. loss: 0.002908\n",
      "Total training time: 12.44 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 0.42, NNZs: 3346, Bias: -0.000477, T: 197284, Avg. loss: 0.002892\n",
      "Total training time: 12.60 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 0.43, NNZs: 3328, Bias: -0.000508, T: 199950, Avg. loss: 0.002876\n",
      "Total training time: 12.76 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 0.43, NNZs: 3307, Bias: -0.000505, T: 202616, Avg. loss: 0.002827\n",
      "Total training time: 12.92 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 0.43, NNZs: 3292, Bias: -0.000539, T: 205282, Avg. loss: 0.002808\n",
      "Total training time: 13.08 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 0.44, NNZs: 3276, Bias: -0.000560, T: 207948, Avg. loss: 0.002782\n",
      "Total training time: 13.24 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 0.44, NNZs: 3261, Bias: -0.000579, T: 210614, Avg. loss: 0.002767\n",
      "Total training time: 13.40 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 0.44, NNZs: 3243, Bias: -0.000570, T: 213280, Avg. loss: 0.002716\n",
      "Total training time: 13.56 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 0.45, NNZs: 3227, Bias: -0.000580, T: 215946, Avg. loss: 0.002699\n",
      "Total training time: 13.73 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 0.45, NNZs: 3210, Bias: -0.000589, T: 218612, Avg. loss: 0.002654\n",
      "Total training time: 13.89 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 0.45, NNZs: 3203, Bias: -0.000627, T: 221278, Avg. loss: 0.002660\n",
      "Total training time: 14.05 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 0.45, NNZs: 3185, Bias: -0.000636, T: 223944, Avg. loss: 0.002644\n",
      "Total training time: 14.21 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 0.46, NNZs: 3168, Bias: -0.000654, T: 226610, Avg. loss: 0.002612\n",
      "Total training time: 14.37 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 0.46, NNZs: 3162, Bias: -0.000677, T: 229276, Avg. loss: 0.002588\n",
      "Total training time: 14.53 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 0.46, NNZs: 3146, Bias: -0.000658, T: 231942, Avg. loss: 0.002547\n",
      "Total training time: 14.68 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 0.47, NNZs: 3124, Bias: -0.000689, T: 234608, Avg. loss: 0.002554\n",
      "Total training time: 14.84 seconds.\n",
      "-- Epoch 89\n",
      "Norm: 0.47, NNZs: 3104, Bias: -0.000672, T: 237274, Avg. loss: 0.002522\n",
      "Total training time: 15.00 seconds.\n",
      "-- Epoch 90\n",
      "Norm: 0.47, NNZs: 3095, Bias: -0.000725, T: 239940, Avg. loss: 0.002482\n",
      "Total training time: 15.16 seconds.\n",
      "-- Epoch 91\n",
      "Norm: 0.47, NNZs: 3085, Bias: -0.000743, T: 242606, Avg. loss: 0.002481\n",
      "Total training time: 15.32 seconds.\n",
      "-- Epoch 92\n",
      "Norm: 0.48, NNZs: 3074, Bias: -0.000766, T: 245272, Avg. loss: 0.002450\n",
      "Total training time: 15.48 seconds.\n",
      "-- Epoch 93\n",
      "Norm: 0.48, NNZs: 3053, Bias: -0.000803, T: 247938, Avg. loss: 0.002441\n",
      "Total training time: 15.64 seconds.\n",
      "-- Epoch 94\n",
      "Norm: 0.48, NNZs: 3033, Bias: -0.000800, T: 250604, Avg. loss: 0.002411\n",
      "Total training time: 15.80 seconds.\n",
      "-- Epoch 95\n",
      "Norm: 0.49, NNZs: 3017, Bias: -0.000771, T: 253270, Avg. loss: 0.002392\n",
      "Total training time: 15.96 seconds.\n",
      "-- Epoch 96\n",
      "Norm: 0.49, NNZs: 2998, Bias: -0.000805, T: 255936, Avg. loss: 0.002373\n",
      "Total training time: 16.12 seconds.\n",
      "-- Epoch 97\n",
      "Norm: 0.49, NNZs: 2984, Bias: -0.000789, T: 258602, Avg. loss: 0.002347\n",
      "Total training time: 16.27 seconds.\n",
      "-- Epoch 98\n",
      "Norm: 0.49, NNZs: 2969, Bias: -0.000862, T: 261268, Avg. loss: 0.002340\n",
      "Total training time: 16.43 seconds.\n",
      "-- Epoch 99\n",
      "Norm: 0.50, NNZs: 2959, Bias: -0.000862, T: 263934, Avg. loss: 0.002309\n",
      "Total training time: 16.59 seconds.\n",
      "-- Epoch 100\n",
      "Norm: 0.50, NNZs: 2949, Bias: -0.000875, T: 266600, Avg. loss: 0.002311\n",
      "Total training time: 16.75 seconds.\n",
      "-- Epoch 101\n",
      "Norm: 0.50, NNZs: 2941, Bias: -0.000918, T: 269266, Avg. loss: 0.002293\n",
      "Total training time: 16.91 seconds.\n",
      "-- Epoch 102\n",
      "Norm: 0.50, NNZs: 2925, Bias: -0.000911, T: 271932, Avg. loss: 0.002272\n",
      "Total training time: 17.07 seconds.\n",
      "-- Epoch 103\n",
      "Norm: 0.51, NNZs: 2908, Bias: -0.000926, T: 274598, Avg. loss: 0.002267\n",
      "Total training time: 17.23 seconds.\n",
      "-- Epoch 104\n",
      "Norm: 0.51, NNZs: 2893, Bias: -0.000921, T: 277264, Avg. loss: 0.002244\n",
      "Total training time: 17.39 seconds.\n",
      "-- Epoch 105\n",
      "Norm: 0.51, NNZs: 2879, Bias: -0.000975, T: 279930, Avg. loss: 0.002227\n",
      "Total training time: 17.54 seconds.\n",
      "-- Epoch 106\n",
      "Norm: 0.51, NNZs: 2866, Bias: -0.000945, T: 282596, Avg. loss: 0.002202\n",
      "Total training time: 17.71 seconds.\n",
      "-- Epoch 107\n",
      "Norm: 0.52, NNZs: 2849, Bias: -0.001033, T: 285262, Avg. loss: 0.002192\n",
      "Total training time: 17.86 seconds.\n",
      "-- Epoch 108\n",
      "Norm: 0.52, NNZs: 2834, Bias: -0.000984, T: 287928, Avg. loss: 0.002181\n",
      "Total training time: 18.02 seconds.\n",
      "-- Epoch 109\n",
      "Norm: 0.52, NNZs: 2824, Bias: -0.001002, T: 290594, Avg. loss: 0.002161\n",
      "Total training time: 18.18 seconds.\n",
      "-- Epoch 110\n",
      "Norm: 0.52, NNZs: 2810, Bias: -0.001017, T: 293260, Avg. loss: 0.002149\n",
      "Total training time: 18.34 seconds.\n",
      "-- Epoch 111\n",
      "Norm: 0.53, NNZs: 2791, Bias: -0.001060, T: 295926, Avg. loss: 0.002132\n",
      "Total training time: 18.50 seconds.\n",
      "-- Epoch 112\n",
      "Norm: 0.53, NNZs: 2780, Bias: -0.001099, T: 298592, Avg. loss: 0.002114\n",
      "Total training time: 18.66 seconds.\n",
      "-- Epoch 113\n",
      "Norm: 0.53, NNZs: 2764, Bias: -0.001083, T: 301258, Avg. loss: 0.002113\n",
      "Total training time: 18.81 seconds.\n",
      "-- Epoch 114\n",
      "Norm: 0.53, NNZs: 2752, Bias: -0.001122, T: 303924, Avg. loss: 0.002089\n",
      "Total training time: 18.97 seconds.\n",
      "-- Epoch 115\n",
      "Norm: 0.54, NNZs: 2738, Bias: -0.001148, T: 306590, Avg. loss: 0.002080\n",
      "Total training time: 19.13 seconds.\n",
      "-- Epoch 116\n",
      "Norm: 0.54, NNZs: 2729, Bias: -0.001168, T: 309256, Avg. loss: 0.002080\n",
      "Total training time: 19.29 seconds.\n",
      "-- Epoch 117\n",
      "Norm: 0.54, NNZs: 2714, Bias: -0.001172, T: 311922, Avg. loss: 0.002056\n",
      "Total training time: 19.45 seconds.\n",
      "-- Epoch 118\n",
      "Norm: 0.54, NNZs: 2693, Bias: -0.001203, T: 314588, Avg. loss: 0.002036\n",
      "Total training time: 19.61 seconds.\n",
      "-- Epoch 119\n",
      "Norm: 0.54, NNZs: 2684, Bias: -0.001220, T: 317254, Avg. loss: 0.002027\n",
      "Total training time: 19.77 seconds.\n",
      "-- Epoch 120\n",
      "Norm: 0.55, NNZs: 2670, Bias: -0.001210, T: 319920, Avg. loss: 0.002020\n",
      "Total training time: 19.93 seconds.\n",
      "-- Epoch 121\n",
      "Norm: 0.55, NNZs: 2656, Bias: -0.001234, T: 322586, Avg. loss: 0.001992\n",
      "Total training time: 20.08 seconds.\n",
      "-- Epoch 122\n",
      "Norm: 0.55, NNZs: 2648, Bias: -0.001256, T: 325252, Avg. loss: 0.001990\n",
      "Total training time: 20.25 seconds.\n",
      "-- Epoch 123\n",
      "Norm: 0.55, NNZs: 2640, Bias: -0.001274, T: 327918, Avg. loss: 0.001999\n",
      "Total training time: 20.40 seconds.\n",
      "-- Epoch 124\n",
      "Norm: 0.56, NNZs: 2630, Bias: -0.001303, T: 330584, Avg. loss: 0.001966\n",
      "Total training time: 20.56 seconds.\n",
      "-- Epoch 125\n",
      "Norm: 0.56, NNZs: 2617, Bias: -0.001306, T: 333250, Avg. loss: 0.001962\n",
      "Total training time: 20.71 seconds.\n",
      "-- Epoch 126\n",
      "Norm: 0.56, NNZs: 2616, Bias: -0.001353, T: 335916, Avg. loss: 0.001936\n",
      "Total training time: 20.86 seconds.\n",
      "-- Epoch 127\n",
      "Norm: 0.56, NNZs: 2603, Bias: -0.001360, T: 338582, Avg. loss: 0.001940\n",
      "Total training time: 21.03 seconds.\n",
      "-- Epoch 128\n",
      "Norm: 0.57, NNZs: 2594, Bias: -0.001350, T: 341248, Avg. loss: 0.001930\n",
      "Total training time: 21.19 seconds.\n",
      "-- Epoch 129\n",
      "Norm: 0.57, NNZs: 2585, Bias: -0.001413, T: 343914, Avg. loss: 0.001923\n",
      "Total training time: 21.34 seconds.\n",
      "-- Epoch 130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 0.57, NNZs: 2576, Bias: -0.001392, T: 346580, Avg. loss: 0.001908\n",
      "Total training time: 21.50 seconds.\n",
      "-- Epoch 131\n",
      "Norm: 0.57, NNZs: 2565, Bias: -0.001442, T: 349246, Avg. loss: 0.001891\n",
      "Total training time: 21.66 seconds.\n",
      "-- Epoch 132\n",
      "Norm: 0.57, NNZs: 2554, Bias: -0.001433, T: 351912, Avg. loss: 0.001885\n",
      "Total training time: 21.82 seconds.\n",
      "-- Epoch 133\n",
      "Norm: 0.58, NNZs: 2545, Bias: -0.001448, T: 354578, Avg. loss: 0.001851\n",
      "Total training time: 21.97 seconds.\n",
      "-- Epoch 134\n",
      "Norm: 0.58, NNZs: 2535, Bias: -0.001485, T: 357244, Avg. loss: 0.001853\n",
      "Total training time: 22.13 seconds.\n",
      "-- Epoch 135\n",
      "Norm: 0.58, NNZs: 2524, Bias: -0.001528, T: 359910, Avg. loss: 0.001837\n",
      "Total training time: 22.28 seconds.\n",
      "-- Epoch 136\n",
      "Norm: 0.58, NNZs: 2515, Bias: -0.001507, T: 362576, Avg. loss: 0.001855\n",
      "Total training time: 22.44 seconds.\n",
      "-- Epoch 137\n",
      "Norm: 0.58, NNZs: 2508, Bias: -0.001515, T: 365242, Avg. loss: 0.001829\n",
      "Total training time: 22.60 seconds.\n",
      "-- Epoch 138\n",
      "Norm: 0.59, NNZs: 2502, Bias: -0.001518, T: 367908, Avg. loss: 0.001823\n",
      "Total training time: 22.76 seconds.\n",
      "-- Epoch 139\n",
      "Norm: 0.59, NNZs: 2496, Bias: -0.001564, T: 370574, Avg. loss: 0.001815\n",
      "Total training time: 22.91 seconds.\n",
      "-- Epoch 140\n",
      "Norm: 0.59, NNZs: 2490, Bias: -0.001581, T: 373240, Avg. loss: 0.001808\n",
      "Total training time: 23.07 seconds.\n",
      "-- Epoch 141\n",
      "Norm: 0.59, NNZs: 2473, Bias: -0.001595, T: 375906, Avg. loss: 0.001807\n",
      "Total training time: 23.22 seconds.\n",
      "-- Epoch 142\n",
      "Norm: 0.59, NNZs: 2466, Bias: -0.001612, T: 378572, Avg. loss: 0.001799\n",
      "Total training time: 23.37 seconds.\n",
      "-- Epoch 143\n",
      "Norm: 0.60, NNZs: 2457, Bias: -0.001670, T: 381238, Avg. loss: 0.001791\n",
      "Total training time: 23.53 seconds.\n",
      "-- Epoch 144\n",
      "Norm: 0.60, NNZs: 2445, Bias: -0.001670, T: 383904, Avg. loss: 0.001772\n",
      "Total training time: 23.70 seconds.\n",
      "Convergence after 144 epochs took 23.70 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.02, NNZs: 7961, Bias: 0.000289, T: 2667, Avg. loss: 0.010750\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.03, NNZs: 6193, Bias: 0.000308, T: 5334, Avg. loss: 0.010018\n",
      "Total training time: 0.33 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.05, NNZs: 5461, Bias: 0.000292, T: 8001, Avg. loss: 0.009680\n",
      "Total training time: 0.51 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.06, NNZs: 5322, Bias: 0.000345, T: 10668, Avg. loss: 0.009423\n",
      "Total training time: 0.70 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.07, NNZs: 5025, Bias: 0.000281, T: 13335, Avg. loss: 0.009150\n",
      "Total training time: 0.88 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.08, NNZs: 4944, Bias: 0.000264, T: 16002, Avg. loss: 0.008888\n",
      "Total training time: 1.04 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.09, NNZs: 4945, Bias: 0.000300, T: 18669, Avg. loss: 0.008686\n",
      "Total training time: 1.22 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.09, NNZs: 4812, Bias: 0.000237, T: 21336, Avg. loss: 0.008459\n",
      "Total training time: 1.38 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.10, NNZs: 4818, Bias: 0.000308, T: 24003, Avg. loss: 0.008212\n",
      "Total training time: 1.56 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.11, NNZs: 4768, Bias: 0.000297, T: 26670, Avg. loss: 0.007987\n",
      "Total training time: 1.73 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.12, NNZs: 4714, Bias: 0.000284, T: 29337, Avg. loss: 0.007819\n",
      "Total training time: 1.90 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.13, NNZs: 4674, Bias: 0.000263, T: 32004, Avg. loss: 0.007648\n",
      "Total training time: 2.08 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.13, NNZs: 4656, Bias: 0.000307, T: 34671, Avg. loss: 0.007430\n",
      "Total training time: 2.26 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 0.14, NNZs: 4627, Bias: 0.000251, T: 37338, Avg. loss: 0.007293\n",
      "Total training time: 2.44 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 0.15, NNZs: 4591, Bias: 0.000256, T: 40005, Avg. loss: 0.007043\n",
      "Total training time: 2.61 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 0.15, NNZs: 4547, Bias: 0.000193, T: 42672, Avg. loss: 0.006884\n",
      "Total training time: 2.78 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 0.16, NNZs: 4530, Bias: 0.000207, T: 45339, Avg. loss: 0.006728\n",
      "Total training time: 2.96 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 0.17, NNZs: 4508, Bias: 0.000222, T: 48006, Avg. loss: 0.006554\n",
      "Total training time: 3.13 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.17, NNZs: 4486, Bias: 0.000229, T: 50673, Avg. loss: 0.006510\n",
      "Total training time: 3.31 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 0.18, NNZs: 4451, Bias: 0.000218, T: 53340, Avg. loss: 0.006364\n",
      "Total training time: 3.47 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 0.19, NNZs: 4427, Bias: 0.000203, T: 56007, Avg. loss: 0.006185\n",
      "Total training time: 3.64 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.19, NNZs: 4396, Bias: 0.000171, T: 58674, Avg. loss: 0.006047\n",
      "Total training time: 3.82 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 0.20, NNZs: 4384, Bias: 0.000196, T: 61341, Avg. loss: 0.005946\n",
      "Total training time: 4.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 0.20, NNZs: 4363, Bias: 0.000177, T: 64008, Avg. loss: 0.005817\n",
      "Total training time: 4.17 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 0.21, NNZs: 4332, Bias: 0.000167, T: 66675, Avg. loss: 0.005685\n",
      "Total training time: 4.35 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 0.21, NNZs: 4293, Bias: 0.000145, T: 69342, Avg. loss: 0.005545\n",
      "Total training time: 4.53 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 0.22, NNZs: 4285, Bias: 0.000196, T: 72009, Avg. loss: 0.005458\n",
      "Total training time: 4.70 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 0.23, NNZs: 4255, Bias: 0.000143, T: 74676, Avg. loss: 0.005404\n",
      "Total training time: 4.88 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 0.23, NNZs: 4226, Bias: 0.000089, T: 77343, Avg. loss: 0.005259\n",
      "Total training time: 5.05 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 0.24, NNZs: 4201, Bias: 0.000091, T: 80010, Avg. loss: 0.005199\n",
      "Total training time: 5.23 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 0.24, NNZs: 4164, Bias: 0.000135, T: 82677, Avg. loss: 0.005093\n",
      "Total training time: 5.41 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 0.25, NNZs: 4153, Bias: 0.000103, T: 85344, Avg. loss: 0.005000\n",
      "Total training time: 5.58 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.25, NNZs: 4140, Bias: 0.000099, T: 88011, Avg. loss: 0.004956\n",
      "Total training time: 5.74 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.26, NNZs: 4109, Bias: 0.000123, T: 90678, Avg. loss: 0.004760\n",
      "Total training time: 5.90 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 0.26, NNZs: 4085, Bias: 0.000084, T: 93345, Avg. loss: 0.004721\n",
      "Total training time: 6.07 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 0.27, NNZs: 4061, Bias: 0.000068, T: 96012, Avg. loss: 0.004662\n",
      "Total training time: 6.24 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 0.27, NNZs: 4027, Bias: 0.000072, T: 98679, Avg. loss: 0.004587\n",
      "Total training time: 6.42 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 0.28, NNZs: 4002, Bias: 0.000066, T: 101346, Avg. loss: 0.004516\n",
      "Total training time: 6.58 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 0.28, NNZs: 3990, Bias: 0.000069, T: 104013, Avg. loss: 0.004380\n",
      "Total training time: 6.75 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 0.28, NNZs: 3966, Bias: 0.000034, T: 106680, Avg. loss: 0.004344\n",
      "Total training time: 6.91 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 0.29, NNZs: 3939, Bias: 0.000053, T: 109347, Avg. loss: 0.004303\n",
      "Total training time: 7.07 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 0.29, NNZs: 3916, Bias: 0.000021, T: 112014, Avg. loss: 0.004222\n",
      "Total training time: 7.23 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 0.30, NNZs: 3885, Bias: 0.000041, T: 114681, Avg. loss: 0.004159\n",
      "Total training time: 7.40 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 0.30, NNZs: 3873, Bias: -0.000019, T: 117348, Avg. loss: 0.004052\n",
      "Total training time: 7.57 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 0.31, NNZs: 3848, Bias: 0.000005, T: 120015, Avg. loss: 0.004031\n",
      "Total training time: 7.74 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 0.31, NNZs: 3827, Bias: -0.000037, T: 122682, Avg. loss: 0.003955\n",
      "Total training time: 7.90 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 0.31, NNZs: 3812, Bias: -0.000029, T: 125349, Avg. loss: 0.003921\n",
      "Total training time: 8.07 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 0.32, NNZs: 3785, Bias: -0.000005, T: 128016, Avg. loss: 0.003869\n",
      "Total training time: 8.23 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 0.32, NNZs: 3761, Bias: -0.000025, T: 130683, Avg. loss: 0.003798\n",
      "Total training time: 8.40 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 0.33, NNZs: 3737, Bias: -0.000041, T: 133350, Avg. loss: 0.003743\n",
      "Total training time: 8.57 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 0.33, NNZs: 3716, Bias: -0.000049, T: 136017, Avg. loss: 0.003701\n",
      "Total training time: 8.73 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 0.34, NNZs: 3695, Bias: -0.000048, T: 138684, Avg. loss: 0.003636\n",
      "Total training time: 8.90 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 0.34, NNZs: 3680, Bias: -0.000065, T: 141351, Avg. loss: 0.003590\n",
      "Total training time: 9.07 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 0.34, NNZs: 3656, Bias: -0.000069, T: 144018, Avg. loss: 0.003571\n",
      "Total training time: 9.23 seconds.\n",
      "-- Epoch 55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 0.35, NNZs: 3638, Bias: -0.000075, T: 146685, Avg. loss: 0.003524\n",
      "Total training time: 9.39 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 0.35, NNZs: 3619, Bias: -0.000092, T: 149352, Avg. loss: 0.003439\n",
      "Total training time: 9.55 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 0.35, NNZs: 3601, Bias: -0.000101, T: 152019, Avg. loss: 0.003432\n",
      "Total training time: 9.71 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 0.36, NNZs: 3576, Bias: -0.000132, T: 154686, Avg. loss: 0.003384\n",
      "Total training time: 9.87 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 0.36, NNZs: 3552, Bias: -0.000108, T: 157353, Avg. loss: 0.003351\n",
      "Total training time: 10.03 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 0.36, NNZs: 3533, Bias: -0.000142, T: 160020, Avg. loss: 0.003282\n",
      "Total training time: 10.18 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 0.37, NNZs: 3519, Bias: -0.000141, T: 162687, Avg. loss: 0.003267\n",
      "Total training time: 10.35 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 0.37, NNZs: 3490, Bias: -0.000156, T: 165354, Avg. loss: 0.003204\n",
      "Total training time: 10.51 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 0.38, NNZs: 3474, Bias: -0.000162, T: 168021, Avg. loss: 0.003191\n",
      "Total training time: 10.67 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 0.38, NNZs: 3459, Bias: -0.000155, T: 170688, Avg. loss: 0.003128\n",
      "Total training time: 10.84 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 0.38, NNZs: 3439, Bias: -0.000154, T: 173355, Avg. loss: 0.003097\n",
      "Total training time: 11.00 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 0.39, NNZs: 3419, Bias: -0.000214, T: 176022, Avg. loss: 0.003085\n",
      "Total training time: 11.16 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 0.39, NNZs: 3399, Bias: -0.000215, T: 178689, Avg. loss: 0.003051\n",
      "Total training time: 11.32 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 0.39, NNZs: 3376, Bias: -0.000237, T: 181356, Avg. loss: 0.003031\n",
      "Total training time: 11.48 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 0.40, NNZs: 3359, Bias: -0.000174, T: 184023, Avg. loss: 0.002980\n",
      "Total training time: 11.63 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 0.40, NNZs: 3348, Bias: -0.000250, T: 186690, Avg. loss: 0.002965\n",
      "Total training time: 11.80 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 0.40, NNZs: 3328, Bias: -0.000229, T: 189357, Avg. loss: 0.002930\n",
      "Total training time: 11.96 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 0.41, NNZs: 3314, Bias: -0.000236, T: 192024, Avg. loss: 0.002890\n",
      "Total training time: 12.12 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 0.41, NNZs: 3305, Bias: -0.000282, T: 194691, Avg. loss: 0.002883\n",
      "Total training time: 12.28 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 0.41, NNZs: 3290, Bias: -0.000253, T: 197358, Avg. loss: 0.002849\n",
      "Total training time: 12.44 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 0.41, NNZs: 3277, Bias: -0.000271, T: 200025, Avg. loss: 0.002809\n",
      "Total training time: 12.61 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 0.42, NNZs: 3253, Bias: -0.000284, T: 202692, Avg. loss: 0.002782\n",
      "Total training time: 12.77 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 0.42, NNZs: 3239, Bias: -0.000295, T: 205359, Avg. loss: 0.002730\n",
      "Total training time: 12.93 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 0.42, NNZs: 3228, Bias: -0.000335, T: 208026, Avg. loss: 0.002717\n",
      "Total training time: 13.10 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 0.43, NNZs: 3212, Bias: -0.000342, T: 210693, Avg. loss: 0.002720\n",
      "Total training time: 13.27 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 0.43, NNZs: 3191, Bias: -0.000352, T: 213360, Avg. loss: 0.002658\n",
      "Total training time: 13.43 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 0.43, NNZs: 3178, Bias: -0.000357, T: 216027, Avg. loss: 0.002652\n",
      "Total training time: 13.60 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 0.44, NNZs: 3163, Bias: -0.000357, T: 218694, Avg. loss: 0.002639\n",
      "Total training time: 13.77 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 0.44, NNZs: 3151, Bias: -0.000362, T: 221361, Avg. loss: 0.002610\n",
      "Total training time: 13.93 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 0.44, NNZs: 3140, Bias: -0.000370, T: 224028, Avg. loss: 0.002587\n",
      "Total training time: 14.10 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 0.44, NNZs: 3126, Bias: -0.000382, T: 226695, Avg. loss: 0.002576\n",
      "Total training time: 14.26 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 0.45, NNZs: 3118, Bias: -0.000424, T: 229362, Avg. loss: 0.002540\n",
      "Total training time: 14.43 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 0.45, NNZs: 3102, Bias: -0.000403, T: 232029, Avg. loss: 0.002520\n",
      "Total training time: 14.59 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 0.45, NNZs: 3096, Bias: -0.000435, T: 234696, Avg. loss: 0.002510\n",
      "Total training time: 14.74 seconds.\n",
      "-- Epoch 89\n",
      "Norm: 0.46, NNZs: 3078, Bias: -0.000422, T: 237363, Avg. loss: 0.002488\n",
      "Total training time: 14.90 seconds.\n",
      "-- Epoch 90\n",
      "Norm: 0.46, NNZs: 3066, Bias: -0.000436, T: 240030, Avg. loss: 0.002466\n",
      "Total training time: 15.07 seconds.\n",
      "-- Epoch 91\n",
      "Norm: 0.46, NNZs: 3049, Bias: -0.000424, T: 242697, Avg. loss: 0.002444\n",
      "Total training time: 15.23 seconds.\n",
      "-- Epoch 92\n",
      "Norm: 0.46, NNZs: 3036, Bias: -0.000468, T: 245364, Avg. loss: 0.002431\n",
      "Total training time: 15.38 seconds.\n",
      "-- Epoch 93\n",
      "Norm: 0.47, NNZs: 3016, Bias: -0.000488, T: 248031, Avg. loss: 0.002409\n",
      "Total training time: 15.54 seconds.\n",
      "-- Epoch 94\n",
      "Norm: 0.47, NNZs: 3002, Bias: -0.000497, T: 250698, Avg. loss: 0.002393\n",
      "Total training time: 15.70 seconds.\n",
      "-- Epoch 95\n",
      "Norm: 0.47, NNZs: 2989, Bias: -0.000530, T: 253365, Avg. loss: 0.002375\n",
      "Total training time: 15.86 seconds.\n",
      "-- Epoch 96\n",
      "Norm: 0.47, NNZs: 2975, Bias: -0.000552, T: 256032, Avg. loss: 0.002353\n",
      "Total training time: 16.01 seconds.\n",
      "-- Epoch 97\n",
      "Norm: 0.48, NNZs: 2968, Bias: -0.000491, T: 258699, Avg. loss: 0.002328\n",
      "Total training time: 16.17 seconds.\n",
      "-- Epoch 98\n",
      "Norm: 0.48, NNZs: 2943, Bias: -0.000542, T: 261366, Avg. loss: 0.002329\n",
      "Total training time: 16.32 seconds.\n",
      "-- Epoch 99\n",
      "Norm: 0.48, NNZs: 2933, Bias: -0.000541, T: 264033, Avg. loss: 0.002309\n",
      "Total training time: 16.48 seconds.\n",
      "-- Epoch 100\n",
      "Norm: 0.48, NNZs: 2911, Bias: -0.000584, T: 266700, Avg. loss: 0.002294\n",
      "Total training time: 16.64 seconds.\n",
      "-- Epoch 101\n",
      "Norm: 0.49, NNZs: 2899, Bias: -0.000582, T: 269367, Avg. loss: 0.002280\n",
      "Total training time: 16.80 seconds.\n",
      "-- Epoch 102\n",
      "Norm: 0.49, NNZs: 2886, Bias: -0.000628, T: 272034, Avg. loss: 0.002248\n",
      "Total training time: 16.95 seconds.\n",
      "-- Epoch 103\n",
      "Norm: 0.49, NNZs: 2876, Bias: -0.000623, T: 274701, Avg. loss: 0.002236\n",
      "Total training time: 17.11 seconds.\n",
      "-- Epoch 104\n",
      "Norm: 0.50, NNZs: 2864, Bias: -0.000651, T: 277368, Avg. loss: 0.002221\n",
      "Total training time: 17.27 seconds.\n",
      "-- Epoch 105\n",
      "Norm: 0.50, NNZs: 2851, Bias: -0.000644, T: 280035, Avg. loss: 0.002193\n",
      "Total training time: 17.43 seconds.\n",
      "-- Epoch 106\n",
      "Norm: 0.50, NNZs: 2838, Bias: -0.000662, T: 282702, Avg. loss: 0.002200\n",
      "Total training time: 17.59 seconds.\n",
      "-- Epoch 107\n",
      "Norm: 0.50, NNZs: 2833, Bias: -0.000656, T: 285369, Avg. loss: 0.002190\n",
      "Total training time: 17.75 seconds.\n",
      "-- Epoch 108\n",
      "Norm: 0.50, NNZs: 2818, Bias: -0.000686, T: 288036, Avg. loss: 0.002172\n",
      "Total training time: 17.92 seconds.\n",
      "-- Epoch 109\n",
      "Norm: 0.51, NNZs: 2804, Bias: -0.000710, T: 290703, Avg. loss: 0.002162\n",
      "Total training time: 18.08 seconds.\n",
      "-- Epoch 110\n",
      "Norm: 0.51, NNZs: 2794, Bias: -0.000682, T: 293370, Avg. loss: 0.002138\n",
      "Total training time: 18.23 seconds.\n",
      "-- Epoch 111\n",
      "Norm: 0.51, NNZs: 2782, Bias: -0.000693, T: 296037, Avg. loss: 0.002136\n",
      "Total training time: 18.40 seconds.\n",
      "-- Epoch 112\n",
      "Norm: 0.51, NNZs: 2763, Bias: -0.000775, T: 298704, Avg. loss: 0.002108\n",
      "Total training time: 18.57 seconds.\n",
      "-- Epoch 113\n",
      "Norm: 0.52, NNZs: 2754, Bias: -0.000755, T: 301371, Avg. loss: 0.002100\n",
      "Total training time: 18.74 seconds.\n",
      "-- Epoch 114\n",
      "Norm: 0.52, NNZs: 2746, Bias: -0.000753, T: 304038, Avg. loss: 0.002075\n",
      "Total training time: 18.89 seconds.\n",
      "-- Epoch 115\n",
      "Norm: 0.52, NNZs: 2735, Bias: -0.000770, T: 306705, Avg. loss: 0.002071\n",
      "Total training time: 19.06 seconds.\n",
      "-- Epoch 116\n",
      "Norm: 0.52, NNZs: 2728, Bias: -0.000788, T: 309372, Avg. loss: 0.002049\n",
      "Total training time: 19.22 seconds.\n",
      "-- Epoch 117\n",
      "Norm: 0.53, NNZs: 2719, Bias: -0.000783, T: 312039, Avg. loss: 0.002048\n",
      "Total training time: 19.39 seconds.\n",
      "-- Epoch 118\n",
      "Norm: 0.53, NNZs: 2708, Bias: -0.000767, T: 314706, Avg. loss: 0.002035\n",
      "Total training time: 19.55 seconds.\n",
      "-- Epoch 119\n",
      "Norm: 0.53, NNZs: 2696, Bias: -0.000846, T: 317373, Avg. loss: 0.002025\n",
      "Total training time: 19.72 seconds.\n",
      "-- Epoch 120\n",
      "Norm: 0.53, NNZs: 2679, Bias: -0.000836, T: 320040, Avg. loss: 0.002021\n",
      "Total training time: 19.88 seconds.\n",
      "-- Epoch 121\n",
      "Norm: 0.54, NNZs: 2664, Bias: -0.000858, T: 322707, Avg. loss: 0.002004\n",
      "Total training time: 20.05 seconds.\n",
      "-- Epoch 122\n",
      "Norm: 0.54, NNZs: 2651, Bias: -0.000889, T: 325374, Avg. loss: 0.002000\n",
      "Total training time: 20.21 seconds.\n",
      "-- Epoch 123\n",
      "Norm: 0.54, NNZs: 2641, Bias: -0.000881, T: 328041, Avg. loss: 0.001979\n",
      "Total training time: 20.38 seconds.\n",
      "-- Epoch 124\n",
      "Norm: 0.54, NNZs: 2626, Bias: -0.000923, T: 330708, Avg. loss: 0.001959\n",
      "Total training time: 20.54 seconds.\n",
      "-- Epoch 125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 0.54, NNZs: 2615, Bias: -0.000913, T: 333375, Avg. loss: 0.001940\n",
      "Total training time: 20.71 seconds.\n",
      "-- Epoch 126\n",
      "Norm: 0.55, NNZs: 2603, Bias: -0.000933, T: 336042, Avg. loss: 0.001957\n",
      "Total training time: 20.87 seconds.\n",
      "-- Epoch 127\n",
      "Norm: 0.55, NNZs: 2590, Bias: -0.000949, T: 338709, Avg. loss: 0.001930\n",
      "Total training time: 21.03 seconds.\n",
      "-- Epoch 128\n",
      "Norm: 0.55, NNZs: 2573, Bias: -0.000968, T: 341376, Avg. loss: 0.001931\n",
      "Total training time: 21.19 seconds.\n",
      "-- Epoch 129\n",
      "Norm: 0.55, NNZs: 2561, Bias: -0.001011, T: 344043, Avg. loss: 0.001907\n",
      "Total training time: 21.35 seconds.\n",
      "-- Epoch 130\n",
      "Norm: 0.55, NNZs: 2550, Bias: -0.001002, T: 346710, Avg. loss: 0.001909\n",
      "Total training time: 21.52 seconds.\n",
      "-- Epoch 131\n",
      "Norm: 0.56, NNZs: 2537, Bias: -0.001028, T: 349377, Avg. loss: 0.001904\n",
      "Total training time: 21.68 seconds.\n",
      "-- Epoch 132\n",
      "Norm: 0.56, NNZs: 2523, Bias: -0.001039, T: 352044, Avg. loss: 0.001877\n",
      "Total training time: 21.85 seconds.\n",
      "-- Epoch 133\n",
      "Norm: 0.56, NNZs: 2513, Bias: -0.001070, T: 354711, Avg. loss: 0.001873\n",
      "Total training time: 22.02 seconds.\n",
      "-- Epoch 134\n",
      "Norm: 0.56, NNZs: 2499, Bias: -0.001075, T: 357378, Avg. loss: 0.001880\n",
      "Total training time: 22.18 seconds.\n",
      "-- Epoch 135\n",
      "Norm: 0.57, NNZs: 2489, Bias: -0.001105, T: 360045, Avg. loss: 0.001861\n",
      "Total training time: 22.35 seconds.\n",
      "-- Epoch 136\n",
      "Norm: 0.57, NNZs: 2479, Bias: -0.001109, T: 362712, Avg. loss: 0.001863\n",
      "Total training time: 22.51 seconds.\n",
      "-- Epoch 137\n",
      "Norm: 0.57, NNZs: 2469, Bias: -0.001123, T: 365379, Avg. loss: 0.001836\n",
      "Total training time: 22.68 seconds.\n",
      "-- Epoch 138\n",
      "Norm: 0.57, NNZs: 2459, Bias: -0.001123, T: 368046, Avg. loss: 0.001834\n",
      "Total training time: 22.84 seconds.\n",
      "-- Epoch 139\n",
      "Norm: 0.57, NNZs: 2454, Bias: -0.001124, T: 370713, Avg. loss: 0.001830\n",
      "Total training time: 23.00 seconds.\n",
      "-- Epoch 140\n",
      "Norm: 0.58, NNZs: 2442, Bias: -0.001164, T: 373380, Avg. loss: 0.001806\n",
      "Total training time: 23.16 seconds.\n",
      "-- Epoch 141\n",
      "Norm: 0.58, NNZs: 2439, Bias: -0.001184, T: 376047, Avg. loss: 0.001800\n",
      "Total training time: 23.32 seconds.\n",
      "-- Epoch 142\n",
      "Norm: 0.58, NNZs: 2427, Bias: -0.001209, T: 378714, Avg. loss: 0.001797\n",
      "Total training time: 23.49 seconds.\n",
      "-- Epoch 143\n",
      "Norm: 0.58, NNZs: 2420, Bias: -0.001206, T: 381381, Avg. loss: 0.001778\n",
      "Total training time: 23.65 seconds.\n",
      "-- Epoch 144\n",
      "Norm: 0.58, NNZs: 2412, Bias: -0.001203, T: 384048, Avg. loss: 0.001784\n",
      "Total training time: 23.82 seconds.\n",
      "Convergence after 144 epochs took 23.82 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.02, NNZs: 7979, Bias: 0.000290, T: 2667, Avg. loss: 0.011404\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.04, NNZs: 5996, Bias: 0.000267, T: 5334, Avg. loss: 0.010620\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.05, NNZs: 5487, Bias: 0.000271, T: 8001, Avg. loss: 0.010305\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.06, NNZs: 5372, Bias: 0.000324, T: 10668, Avg. loss: 0.009904\n",
      "Total training time: 0.71 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.07, NNZs: 5161, Bias: 0.000298, T: 13335, Avg. loss: 0.009531\n",
      "Total training time: 0.88 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.08, NNZs: 5092, Bias: 0.000310, T: 16002, Avg. loss: 0.009376\n",
      "Total training time: 1.05 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.09, NNZs: 4980, Bias: 0.000272, T: 18669, Avg. loss: 0.009035\n",
      "Total training time: 1.23 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.10, NNZs: 4950, Bias: 0.000293, T: 21336, Avg. loss: 0.008833\n",
      "Total training time: 1.40 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.11, NNZs: 4864, Bias: 0.000220, T: 24003, Avg. loss: 0.008612\n",
      "Total training time: 1.57 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.11, NNZs: 4857, Bias: 0.000257, T: 26670, Avg. loss: 0.008335\n",
      "Total training time: 1.74 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.12, NNZs: 4804, Bias: 0.000228, T: 29337, Avg. loss: 0.008164\n",
      "Total training time: 1.91 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.13, NNZs: 4774, Bias: 0.000261, T: 32004, Avg. loss: 0.007933\n",
      "Total training time: 2.09 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.14, NNZs: 4726, Bias: 0.000178, T: 34671, Avg. loss: 0.007838\n",
      "Total training time: 2.27 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 0.14, NNZs: 4704, Bias: 0.000209, T: 37338, Avg. loss: 0.007616\n",
      "Total training time: 2.45 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 0.15, NNZs: 4677, Bias: 0.000181, T: 40005, Avg. loss: 0.007401\n",
      "Total training time: 2.63 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 0.16, NNZs: 4629, Bias: 0.000164, T: 42672, Avg. loss: 0.007220\n",
      "Total training time: 2.81 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 0.16, NNZs: 4619, Bias: 0.000208, T: 45339, Avg. loss: 0.007089\n",
      "Total training time: 2.99 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 0.17, NNZs: 4570, Bias: 0.000133, T: 48006, Avg. loss: 0.006906\n",
      "Total training time: 3.17 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.18, NNZs: 4545, Bias: 0.000163, T: 50673, Avg. loss: 0.006715\n",
      "Total training time: 3.35 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 0.18, NNZs: 4514, Bias: 0.000118, T: 53340, Avg. loss: 0.006516\n",
      "Total training time: 3.52 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 0.19, NNZs: 4493, Bias: 0.000116, T: 56007, Avg. loss: 0.006461\n",
      "Total training time: 3.69 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.20, NNZs: 4464, Bias: 0.000142, T: 58674, Avg. loss: 0.006293\n",
      "Total training time: 3.87 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 0.20, NNZs: 4434, Bias: 0.000119, T: 61341, Avg. loss: 0.006158\n",
      "Total training time: 4.05 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 0.21, NNZs: 4430, Bias: 0.000082, T: 64008, Avg. loss: 0.006052\n",
      "Total training time: 4.22 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 0.21, NNZs: 4400, Bias: 0.000115, T: 66675, Avg. loss: 0.005898\n",
      "Total training time: 4.39 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 0.22, NNZs: 4374, Bias: 0.000095, T: 69342, Avg. loss: 0.005792\n",
      "Total training time: 4.57 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 0.23, NNZs: 4355, Bias: 0.000096, T: 72009, Avg. loss: 0.005702\n",
      "Total training time: 4.73 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 0.23, NNZs: 4318, Bias: 0.000074, T: 74676, Avg. loss: 0.005564\n",
      "Total training time: 4.90 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 0.24, NNZs: 4298, Bias: 0.000054, T: 77343, Avg. loss: 0.005477\n",
      "Total training time: 5.07 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 0.24, NNZs: 4266, Bias: 0.000076, T: 80010, Avg. loss: 0.005358\n",
      "Total training time: 5.25 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 0.25, NNZs: 4249, Bias: 0.000017, T: 82677, Avg. loss: 0.005265\n",
      "Total training time: 5.42 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 0.25, NNZs: 4224, Bias: -0.000002, T: 85344, Avg. loss: 0.005153\n",
      "Total training time: 5.59 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.26, NNZs: 4194, Bias: 0.000046, T: 88011, Avg. loss: 0.005048\n",
      "Total training time: 5.76 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.26, NNZs: 4170, Bias: 0.000029, T: 90678, Avg. loss: 0.004958\n",
      "Total training time: 5.93 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 0.27, NNZs: 4152, Bias: -0.000005, T: 93345, Avg. loss: 0.004915\n",
      "Total training time: 6.10 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 0.27, NNZs: 4131, Bias: 0.000004, T: 96012, Avg. loss: 0.004852\n",
      "Total training time: 6.26 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 0.28, NNZs: 4095, Bias: -0.000045, T: 98679, Avg. loss: 0.004695\n",
      "Total training time: 6.43 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 0.28, NNZs: 4089, Bias: -0.000041, T: 101346, Avg. loss: 0.004660\n",
      "Total training time: 6.60 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 0.29, NNZs: 4065, Bias: -0.000050, T: 104013, Avg. loss: 0.004556\n",
      "Total training time: 6.77 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 0.29, NNZs: 4049, Bias: -0.000050, T: 106680, Avg. loss: 0.004517\n",
      "Total training time: 6.94 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 0.30, NNZs: 4020, Bias: -0.000046, T: 109347, Avg. loss: 0.004395\n",
      "Total training time: 7.10 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 0.30, NNZs: 3995, Bias: -0.000093, T: 112014, Avg. loss: 0.004376\n",
      "Total training time: 7.28 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 0.31, NNZs: 3974, Bias: -0.000086, T: 114681, Avg. loss: 0.004263\n",
      "Total training time: 7.44 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 0.31, NNZs: 3953, Bias: -0.000106, T: 117348, Avg. loss: 0.004204\n",
      "Total training time: 7.61 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 0.32, NNZs: 3921, Bias: -0.000147, T: 120015, Avg. loss: 0.004147\n",
      "Total training time: 7.78 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 0.32, NNZs: 3903, Bias: -0.000136, T: 122682, Avg. loss: 0.004084\n",
      "Total training time: 7.95 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 0.32, NNZs: 3881, Bias: -0.000117, T: 125349, Avg. loss: 0.004027\n",
      "Total training time: 8.12 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 0.33, NNZs: 3854, Bias: -0.000145, T: 128016, Avg. loss: 0.003923\n",
      "Total training time: 8.29 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 0.33, NNZs: 3835, Bias: -0.000166, T: 130683, Avg. loss: 0.003908\n",
      "Total training time: 8.45 seconds.\n",
      "-- Epoch 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 0.34, NNZs: 3814, Bias: -0.000192, T: 133350, Avg. loss: 0.003856\n",
      "Total training time: 8.62 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 0.34, NNZs: 3798, Bias: -0.000176, T: 136017, Avg. loss: 0.003773\n",
      "Total training time: 8.79 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 0.34, NNZs: 3771, Bias: -0.000221, T: 138684, Avg. loss: 0.003735\n",
      "Total training time: 8.97 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 0.35, NNZs: 3745, Bias: -0.000228, T: 141351, Avg. loss: 0.003686\n",
      "Total training time: 9.14 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 0.35, NNZs: 3729, Bias: -0.000221, T: 144018, Avg. loss: 0.003640\n",
      "Total training time: 9.31 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 0.36, NNZs: 3710, Bias: -0.000226, T: 146685, Avg. loss: 0.003571\n",
      "Total training time: 9.48 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 0.36, NNZs: 3693, Bias: -0.000256, T: 149352, Avg. loss: 0.003574\n",
      "Total training time: 9.69 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 0.36, NNZs: 3671, Bias: -0.000274, T: 152019, Avg. loss: 0.003491\n",
      "Total training time: 9.88 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 0.37, NNZs: 3661, Bias: -0.000306, T: 154686, Avg. loss: 0.003446\n",
      "Total training time: 10.07 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 0.37, NNZs: 3641, Bias: -0.000300, T: 157353, Avg. loss: 0.003417\n",
      "Total training time: 10.25 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 0.37, NNZs: 3616, Bias: -0.000301, T: 160020, Avg. loss: 0.003382\n",
      "Total training time: 10.41 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 0.38, NNZs: 3600, Bias: -0.000347, T: 162687, Avg. loss: 0.003329\n",
      "Total training time: 10.58 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 0.38, NNZs: 3573, Bias: -0.000330, T: 165354, Avg. loss: 0.003317\n",
      "Total training time: 10.75 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 0.39, NNZs: 3551, Bias: -0.000327, T: 168021, Avg. loss: 0.003257\n",
      "Total training time: 10.91 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 0.39, NNZs: 3537, Bias: -0.000373, T: 170688, Avg. loss: 0.003228\n",
      "Total training time: 11.08 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 0.39, NNZs: 3509, Bias: -0.000362, T: 173355, Avg. loss: 0.003156\n",
      "Total training time: 11.25 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 0.40, NNZs: 3493, Bias: -0.000376, T: 176022, Avg. loss: 0.003135\n",
      "Total training time: 11.41 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 0.40, NNZs: 3481, Bias: -0.000362, T: 178689, Avg. loss: 0.003110\n",
      "Total training time: 11.58 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 0.40, NNZs: 3464, Bias: -0.000393, T: 181356, Avg. loss: 0.003051\n",
      "Total training time: 11.75 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 0.41, NNZs: 3441, Bias: -0.000461, T: 184023, Avg. loss: 0.003047\n",
      "Total training time: 11.91 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 0.41, NNZs: 3423, Bias: -0.000433, T: 186690, Avg. loss: 0.003023\n",
      "Total training time: 12.08 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 0.41, NNZs: 3406, Bias: -0.000463, T: 189357, Avg. loss: 0.002937\n",
      "Total training time: 12.25 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 0.42, NNZs: 3387, Bias: -0.000482, T: 192024, Avg. loss: 0.002955\n",
      "Total training time: 12.41 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 0.42, NNZs: 3379, Bias: -0.000442, T: 194691, Avg. loss: 0.002921\n",
      "Total training time: 12.58 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 0.42, NNZs: 3353, Bias: -0.000511, T: 197358, Avg. loss: 0.002890\n",
      "Total training time: 12.75 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 0.43, NNZs: 3339, Bias: -0.000486, T: 200025, Avg. loss: 0.002871\n",
      "Total training time: 12.91 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 0.43, NNZs: 3319, Bias: -0.000519, T: 202692, Avg. loss: 0.002832\n",
      "Total training time: 13.08 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 0.43, NNZs: 3304, Bias: -0.000517, T: 205359, Avg. loss: 0.002810\n",
      "Total training time: 13.24 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 0.44, NNZs: 3291, Bias: -0.000521, T: 208026, Avg. loss: 0.002769\n",
      "Total training time: 13.41 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 0.44, NNZs: 3280, Bias: -0.000581, T: 210693, Avg. loss: 0.002768\n",
      "Total training time: 13.57 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 0.44, NNZs: 3264, Bias: -0.000563, T: 213360, Avg. loss: 0.002710\n",
      "Total training time: 13.73 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 0.44, NNZs: 3247, Bias: -0.000572, T: 216027, Avg. loss: 0.002694\n",
      "Total training time: 13.88 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 0.45, NNZs: 3233, Bias: -0.000614, T: 218694, Avg. loss: 0.002673\n",
      "Total training time: 14.05 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 0.45, NNZs: 3219, Bias: -0.000621, T: 221361, Avg. loss: 0.002635\n",
      "Total training time: 14.20 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 0.45, NNZs: 3205, Bias: -0.000669, T: 224028, Avg. loss: 0.002626\n",
      "Total training time: 14.35 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 0.46, NNZs: 3195, Bias: -0.000655, T: 226695, Avg. loss: 0.002597\n",
      "Total training time: 14.52 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 0.46, NNZs: 3183, Bias: -0.000684, T: 229362, Avg. loss: 0.002601\n",
      "Total training time: 14.67 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 0.46, NNZs: 3170, Bias: -0.000676, T: 232029, Avg. loss: 0.002563\n",
      "Total training time: 14.84 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 0.46, NNZs: 3148, Bias: -0.000717, T: 234696, Avg. loss: 0.002547\n",
      "Total training time: 15.00 seconds.\n",
      "-- Epoch 89\n",
      "Norm: 0.47, NNZs: 3137, Bias: -0.000719, T: 237363, Avg. loss: 0.002518\n",
      "Total training time: 15.17 seconds.\n",
      "-- Epoch 90\n",
      "Norm: 0.47, NNZs: 3122, Bias: -0.000724, T: 240030, Avg. loss: 0.002480\n",
      "Total training time: 15.33 seconds.\n",
      "-- Epoch 91\n",
      "Norm: 0.47, NNZs: 3109, Bias: -0.000736, T: 242697, Avg. loss: 0.002473\n",
      "Total training time: 15.49 seconds.\n",
      "-- Epoch 92\n",
      "Norm: 0.48, NNZs: 3093, Bias: -0.000775, T: 245364, Avg. loss: 0.002448\n",
      "Total training time: 15.66 seconds.\n",
      "-- Epoch 93\n",
      "Norm: 0.48, NNZs: 3067, Bias: -0.000776, T: 248031, Avg. loss: 0.002446\n",
      "Total training time: 15.82 seconds.\n",
      "-- Epoch 94\n",
      "Norm: 0.48, NNZs: 3052, Bias: -0.000777, T: 250698, Avg. loss: 0.002416\n",
      "Total training time: 15.99 seconds.\n",
      "-- Epoch 95\n",
      "Norm: 0.48, NNZs: 3030, Bias: -0.000775, T: 253365, Avg. loss: 0.002369\n",
      "Total training time: 16.15 seconds.\n",
      "-- Epoch 96\n",
      "Norm: 0.49, NNZs: 3016, Bias: -0.000855, T: 256032, Avg. loss: 0.002368\n",
      "Total training time: 16.30 seconds.\n",
      "-- Epoch 97\n",
      "Norm: 0.49, NNZs: 2997, Bias: -0.000829, T: 258699, Avg. loss: 0.002356\n",
      "Total training time: 16.45 seconds.\n",
      "-- Epoch 98\n",
      "Norm: 0.49, NNZs: 2979, Bias: -0.000871, T: 261366, Avg. loss: 0.002348\n",
      "Total training time: 16.61 seconds.\n",
      "-- Epoch 99\n",
      "Norm: 0.49, NNZs: 2960, Bias: -0.000855, T: 264033, Avg. loss: 0.002315\n",
      "Total training time: 16.77 seconds.\n",
      "-- Epoch 100\n",
      "Norm: 0.50, NNZs: 2946, Bias: -0.000886, T: 266700, Avg. loss: 0.002302\n",
      "Total training time: 16.93 seconds.\n",
      "-- Epoch 101\n",
      "Norm: 0.50, NNZs: 2940, Bias: -0.000910, T: 269367, Avg. loss: 0.002268\n",
      "Total training time: 17.09 seconds.\n",
      "-- Epoch 102\n",
      "Norm: 0.50, NNZs: 2929, Bias: -0.000927, T: 272034, Avg. loss: 0.002268\n",
      "Total training time: 17.26 seconds.\n",
      "-- Epoch 103\n",
      "Norm: 0.51, NNZs: 2911, Bias: -0.000934, T: 274701, Avg. loss: 0.002261\n",
      "Total training time: 17.42 seconds.\n",
      "-- Epoch 104\n",
      "Norm: 0.51, NNZs: 2896, Bias: -0.000981, T: 277368, Avg. loss: 0.002238\n",
      "Total training time: 17.58 seconds.\n",
      "-- Epoch 105\n",
      "Norm: 0.51, NNZs: 2880, Bias: -0.000950, T: 280035, Avg. loss: 0.002232\n",
      "Total training time: 17.75 seconds.\n",
      "-- Epoch 106\n",
      "Norm: 0.51, NNZs: 2871, Bias: -0.000991, T: 282702, Avg. loss: 0.002203\n",
      "Total training time: 17.93 seconds.\n",
      "-- Epoch 107\n",
      "Norm: 0.52, NNZs: 2856, Bias: -0.001018, T: 285369, Avg. loss: 0.002190\n",
      "Total training time: 18.10 seconds.\n",
      "-- Epoch 108\n",
      "Norm: 0.52, NNZs: 2839, Bias: -0.001031, T: 288036, Avg. loss: 0.002169\n",
      "Total training time: 18.27 seconds.\n",
      "-- Epoch 109\n",
      "Norm: 0.52, NNZs: 2826, Bias: -0.001048, T: 290703, Avg. loss: 0.002156\n",
      "Total training time: 18.45 seconds.\n",
      "-- Epoch 110\n",
      "Norm: 0.52, NNZs: 2812, Bias: -0.001039, T: 293370, Avg. loss: 0.002143\n",
      "Total training time: 18.62 seconds.\n",
      "-- Epoch 111\n",
      "Norm: 0.53, NNZs: 2796, Bias: -0.001077, T: 296037, Avg. loss: 0.002141\n",
      "Total training time: 18.80 seconds.\n",
      "-- Epoch 112\n",
      "Norm: 0.53, NNZs: 2780, Bias: -0.001059, T: 298704, Avg. loss: 0.002133\n",
      "Total training time: 18.97 seconds.\n",
      "-- Epoch 113\n",
      "Norm: 0.53, NNZs: 2770, Bias: -0.001130, T: 301371, Avg. loss: 0.002108\n",
      "Total training time: 19.13 seconds.\n",
      "-- Epoch 114\n",
      "Norm: 0.53, NNZs: 2755, Bias: -0.001154, T: 304038, Avg. loss: 0.002077\n",
      "Total training time: 19.30 seconds.\n",
      "-- Epoch 115\n",
      "Norm: 0.53, NNZs: 2745, Bias: -0.001153, T: 306705, Avg. loss: 0.002062\n",
      "Total training time: 19.47 seconds.\n",
      "-- Epoch 116\n",
      "Norm: 0.54, NNZs: 2727, Bias: -0.001153, T: 309372, Avg. loss: 0.002070\n",
      "Total training time: 19.64 seconds.\n",
      "-- Epoch 117\n",
      "Norm: 0.54, NNZs: 2713, Bias: -0.001188, T: 312039, Avg. loss: 0.002050\n",
      "Total training time: 19.79 seconds.\n",
      "-- Epoch 118\n",
      "Norm: 0.54, NNZs: 2698, Bias: -0.001183, T: 314706, Avg. loss: 0.002042\n",
      "Total training time: 19.95 seconds.\n",
      "-- Epoch 119\n",
      "Norm: 0.54, NNZs: 2686, Bias: -0.001221, T: 317373, Avg. loss: 0.002033\n",
      "Total training time: 20.11 seconds.\n",
      "-- Epoch 120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 0.55, NNZs: 2671, Bias: -0.001235, T: 320040, Avg. loss: 0.002019\n",
      "Total training time: 20.26 seconds.\n",
      "-- Epoch 121\n",
      "Norm: 0.55, NNZs: 2659, Bias: -0.001265, T: 322707, Avg. loss: 0.001998\n",
      "Total training time: 20.42 seconds.\n",
      "-- Epoch 122\n",
      "Norm: 0.55, NNZs: 2654, Bias: -0.001312, T: 325374, Avg. loss: 0.001991\n",
      "Total training time: 20.58 seconds.\n",
      "-- Epoch 123\n",
      "Norm: 0.55, NNZs: 2644, Bias: -0.001315, T: 328041, Avg. loss: 0.001982\n",
      "Total training time: 20.74 seconds.\n",
      "-- Epoch 124\n",
      "Norm: 0.56, NNZs: 2633, Bias: -0.001320, T: 330708, Avg. loss: 0.001972\n",
      "Total training time: 20.91 seconds.\n",
      "-- Epoch 125\n",
      "Norm: 0.56, NNZs: 2613, Bias: -0.001360, T: 333375, Avg. loss: 0.001957\n",
      "Total training time: 21.06 seconds.\n",
      "-- Epoch 126\n",
      "Norm: 0.56, NNZs: 2599, Bias: -0.001361, T: 336042, Avg. loss: 0.001955\n",
      "Total training time: 21.22 seconds.\n",
      "-- Epoch 127\n",
      "Norm: 0.56, NNZs: 2591, Bias: -0.001393, T: 338709, Avg. loss: 0.001938\n",
      "Total training time: 21.39 seconds.\n",
      "-- Epoch 128\n",
      "Norm: 0.56, NNZs: 2584, Bias: -0.001395, T: 341376, Avg. loss: 0.001927\n",
      "Total training time: 21.55 seconds.\n",
      "-- Epoch 129\n",
      "Norm: 0.57, NNZs: 2571, Bias: -0.001434, T: 344043, Avg. loss: 0.001921\n",
      "Total training time: 21.71 seconds.\n",
      "-- Epoch 130\n",
      "Norm: 0.57, NNZs: 2563, Bias: -0.001444, T: 346710, Avg. loss: 0.001909\n",
      "Total training time: 21.87 seconds.\n",
      "-- Epoch 131\n",
      "Norm: 0.57, NNZs: 2549, Bias: -0.001455, T: 349377, Avg. loss: 0.001891\n",
      "Total training time: 22.03 seconds.\n",
      "-- Epoch 132\n",
      "Norm: 0.57, NNZs: 2543, Bias: -0.001517, T: 352044, Avg. loss: 0.001884\n",
      "Total training time: 22.19 seconds.\n",
      "-- Epoch 133\n",
      "Norm: 0.57, NNZs: 2530, Bias: -0.001513, T: 354711, Avg. loss: 0.001879\n",
      "Total training time: 22.35 seconds.\n",
      "-- Epoch 134\n",
      "Norm: 0.58, NNZs: 2522, Bias: -0.001536, T: 357378, Avg. loss: 0.001873\n",
      "Total training time: 22.52 seconds.\n",
      "-- Epoch 135\n",
      "Norm: 0.58, NNZs: 2515, Bias: -0.001533, T: 360045, Avg. loss: 0.001864\n",
      "Total training time: 22.67 seconds.\n",
      "-- Epoch 136\n",
      "Norm: 0.58, NNZs: 2500, Bias: -0.001570, T: 362712, Avg. loss: 0.001843\n",
      "Total training time: 22.85 seconds.\n",
      "-- Epoch 137\n",
      "Norm: 0.58, NNZs: 2494, Bias: -0.001613, T: 365379, Avg. loss: 0.001834\n",
      "Total training time: 23.04 seconds.\n",
      "-- Epoch 138\n",
      "Norm: 0.59, NNZs: 2487, Bias: -0.001610, T: 368046, Avg. loss: 0.001826\n",
      "Total training time: 23.21 seconds.\n",
      "-- Epoch 139\n",
      "Norm: 0.59, NNZs: 2468, Bias: -0.001623, T: 370713, Avg. loss: 0.001825\n",
      "Total training time: 23.38 seconds.\n",
      "-- Epoch 140\n",
      "Norm: 0.59, NNZs: 2459, Bias: -0.001643, T: 373380, Avg. loss: 0.001801\n",
      "Total training time: 23.56 seconds.\n",
      "-- Epoch 141\n",
      "Norm: 0.59, NNZs: 2448, Bias: -0.001642, T: 376047, Avg. loss: 0.001795\n",
      "Total training time: 23.72 seconds.\n",
      "-- Epoch 142\n",
      "Norm: 0.59, NNZs: 2437, Bias: -0.001686, T: 378714, Avg. loss: 0.001790\n",
      "Total training time: 23.88 seconds.\n",
      "-- Epoch 143\n",
      "Norm: 0.60, NNZs: 2428, Bias: -0.001724, T: 381381, Avg. loss: 0.001784\n",
      "Total training time: 24.04 seconds.\n",
      "-- Epoch 144\n",
      "Norm: 0.60, NNZs: 2408, Bias: -0.001759, T: 384048, Avg. loss: 0.001784\n",
      "Total training time: 24.21 seconds.\n",
      "-- Epoch 145\n",
      "Norm: 0.60, NNZs: 2396, Bias: -0.001752, T: 386715, Avg. loss: 0.001770\n",
      "Total training time: 24.37 seconds.\n",
      "-- Epoch 146\n",
      "Norm: 0.60, NNZs: 2387, Bias: -0.001779, T: 389382, Avg. loss: 0.001769\n",
      "Total training time: 24.53 seconds.\n",
      "-- Epoch 147\n",
      "Norm: 0.60, NNZs: 2379, Bias: -0.001803, T: 392049, Avg. loss: 0.001746\n",
      "Total training time: 24.69 seconds.\n",
      "-- Epoch 148\n",
      "Norm: 0.61, NNZs: 2372, Bias: -0.001832, T: 394716, Avg. loss: 0.001734\n",
      "Total training time: 24.85 seconds.\n",
      "Convergence after 148 epochs took 24.85 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.03, NNZs: 7636, Bias: 0.000557, T: 2666, Avg. loss: 0.011523\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.04, NNZs: 4582, Bias: 0.000754, T: 5332, Avg. loss: 0.010662\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.06, NNZs: 3555, Bias: 0.000972, T: 7998, Avg. loss: 0.010134\n",
      "Total training time: 0.52 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.07, NNZs: 3007, Bias: 0.001172, T: 10664, Avg. loss: 0.009850\n",
      "Total training time: 0.70 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.08, NNZs: 2469, Bias: 0.001313, T: 13330, Avg. loss: 0.009722\n",
      "Total training time: 0.86 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.09, NNZs: 2029, Bias: 0.001403, T: 15996, Avg. loss: 0.009514\n",
      "Total training time: 1.03 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.10, NNZs: 1956, Bias: 0.001605, T: 18662, Avg. loss: 0.009467\n",
      "Total training time: 1.18 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.11, NNZs: 1626, Bias: 0.001620, T: 21328, Avg. loss: 0.009322\n",
      "Total training time: 1.34 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.12, NNZs: 1344, Bias: 0.001603, T: 23994, Avg. loss: 0.009180\n",
      "Total training time: 1.49 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.12, NNZs: 1304, Bias: 0.001747, T: 26660, Avg. loss: 0.009102\n",
      "Total training time: 1.64 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.13, NNZs: 1141, Bias: 0.001732, T: 29326, Avg. loss: 0.009043\n",
      "Total training time: 1.80 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.14, NNZs: 1036, Bias: 0.001775, T: 31992, Avg. loss: 0.008932\n",
      "Total training time: 1.95 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.14, NNZs: 984, Bias: 0.001827, T: 34658, Avg. loss: 0.008868\n",
      "Total training time: 2.12 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 0.15, NNZs: 929, Bias: 0.001877, T: 37324, Avg. loss: 0.008784\n",
      "Total training time: 2.27 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 0.16, NNZs: 855, Bias: 0.001848, T: 39990, Avg. loss: 0.008732\n",
      "Total training time: 2.43 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 0.16, NNZs: 803, Bias: 0.001841, T: 42656, Avg. loss: 0.008660\n",
      "Total training time: 2.59 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 0.17, NNZs: 760, Bias: 0.001876, T: 45322, Avg. loss: 0.008550\n",
      "Total training time: 2.76 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 0.17, NNZs: 687, Bias: 0.001729, T: 47988, Avg. loss: 0.008525\n",
      "Total training time: 2.91 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.18, NNZs: 691, Bias: 0.001854, T: 50654, Avg. loss: 0.008473\n",
      "Total training time: 3.07 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 0.19, NNZs: 612, Bias: 0.001730, T: 53320, Avg. loss: 0.008398\n",
      "Total training time: 3.22 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 0.19, NNZs: 571, Bias: 0.001665, T: 55986, Avg. loss: 0.008343\n",
      "Total training time: 3.39 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.20, NNZs: 563, Bias: 0.001704, T: 58652, Avg. loss: 0.008297\n",
      "Total training time: 3.54 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 0.20, NNZs: 526, Bias: 0.001587, T: 61318, Avg. loss: 0.008236\n",
      "Total training time: 3.69 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 0.21, NNZs: 501, Bias: 0.001495, T: 63984, Avg. loss: 0.008170\n",
      "Total training time: 3.84 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 0.21, NNZs: 502, Bias: 0.001588, T: 66650, Avg. loss: 0.008111\n",
      "Total training time: 3.99 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 0.22, NNZs: 464, Bias: 0.001450, T: 69316, Avg. loss: 0.008020\n",
      "Total training time: 4.15 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 0.22, NNZs: 443, Bias: 0.001286, T: 71982, Avg. loss: 0.008005\n",
      "Total training time: 4.29 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 0.23, NNZs: 434, Bias: 0.001308, T: 74648, Avg. loss: 0.007949\n",
      "Total training time: 4.45 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 0.23, NNZs: 422, Bias: 0.001239, T: 77314, Avg. loss: 0.007893\n",
      "Total training time: 4.60 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 0.24, NNZs: 389, Bias: 0.001039, T: 79980, Avg. loss: 0.007842\n",
      "Total training time: 4.75 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 0.24, NNZs: 381, Bias: 0.000965, T: 82646, Avg. loss: 0.007762\n",
      "Total training time: 4.91 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 0.25, NNZs: 377, Bias: 0.000910, T: 85312, Avg. loss: 0.007735\n",
      "Total training time: 5.06 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.25, NNZs: 369, Bias: 0.000746, T: 87978, Avg. loss: 0.007659\n",
      "Total training time: 5.22 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.25, NNZs: 367, Bias: 0.000812, T: 90644, Avg. loss: 0.007620\n",
      "Total training time: 5.37 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 0.26, NNZs: 358, Bias: 0.000575, T: 93310, Avg. loss: 0.007577\n",
      "Total training time: 5.52 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 0.26, NNZs: 353, Bias: 0.000549, T: 95976, Avg. loss: 0.007518\n",
      "Total training time: 5.68 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 0.27, NNZs: 354, Bias: 0.000309, T: 98642, Avg. loss: 0.007471\n",
      "Total training time: 5.84 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 0.27, NNZs: 350, Bias: 0.000099, T: 101308, Avg. loss: 0.007432\n",
      "Total training time: 5.99 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 0.28, NNZs: 347, Bias: -0.000002, T: 103974, Avg. loss: 0.007364\n",
      "Total training time: 6.14 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 0.28, NNZs: 341, Bias: -0.000151, T: 106640, Avg. loss: 0.007299\n",
      "Total training time: 6.29 seconds.\n",
      "-- Epoch 41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 0.28, NNZs: 341, Bias: -0.000091, T: 109306, Avg. loss: 0.007288\n",
      "Total training time: 6.45 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 0.29, NNZs: 339, Bias: -0.000268, T: 111972, Avg. loss: 0.007219\n",
      "Total training time: 6.60 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 0.29, NNZs: 337, Bias: -0.000343, T: 114638, Avg. loss: 0.007167\n",
      "Total training time: 6.76 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 0.30, NNZs: 328, Bias: -0.000616, T: 117304, Avg. loss: 0.007115\n",
      "Total training time: 6.91 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 0.30, NNZs: 324, Bias: -0.000676, T: 119970, Avg. loss: 0.007070\n",
      "Total training time: 7.06 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 0.30, NNZs: 323, Bias: -0.000805, T: 122636, Avg. loss: 0.007026\n",
      "Total training time: 7.22 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 0.31, NNZs: 323, Bias: -0.001022, T: 125302, Avg. loss: 0.006971\n",
      "Total training time: 7.36 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 0.31, NNZs: 325, Bias: -0.001124, T: 127968, Avg. loss: 0.006930\n",
      "Total training time: 7.51 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 0.32, NNZs: 323, Bias: -0.001192, T: 130634, Avg. loss: 0.006880\n",
      "Total training time: 7.67 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 0.32, NNZs: 322, Bias: -0.001191, T: 133300, Avg. loss: 0.006834\n",
      "Total training time: 7.82 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 0.32, NNZs: 321, Bias: -0.001437, T: 135966, Avg. loss: 0.006789\n",
      "Total training time: 7.98 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 0.33, NNZs: 319, Bias: -0.001586, T: 138632, Avg. loss: 0.006750\n",
      "Total training time: 8.12 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 0.33, NNZs: 319, Bias: -0.001666, T: 141298, Avg. loss: 0.006681\n",
      "Total training time: 8.28 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 0.33, NNZs: 327, Bias: -0.001921, T: 143964, Avg. loss: 0.006660\n",
      "Total training time: 8.43 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 0.34, NNZs: 333, Bias: -0.002157, T: 146630, Avg. loss: 0.006613\n",
      "Total training time: 8.58 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 0.34, NNZs: 327, Bias: -0.002096, T: 149296, Avg. loss: 0.006549\n",
      "Total training time: 8.73 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 0.35, NNZs: 327, Bias: -0.002169, T: 151962, Avg. loss: 0.006503\n",
      "Total training time: 8.89 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 0.35, NNZs: 334, Bias: -0.002556, T: 154628, Avg. loss: 0.006472\n",
      "Total training time: 9.05 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 0.35, NNZs: 336, Bias: -0.002732, T: 157294, Avg. loss: 0.006426\n",
      "Total training time: 9.20 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 0.36, NNZs: 331, Bias: -0.002663, T: 159960, Avg. loss: 0.006389\n",
      "Total training time: 9.36 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 0.36, NNZs: 331, Bias: -0.002776, T: 162626, Avg. loss: 0.006335\n",
      "Total training time: 9.51 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 0.36, NNZs: 331, Bias: -0.002888, T: 165292, Avg. loss: 0.006304\n",
      "Total training time: 9.67 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 0.37, NNZs: 337, Bias: -0.003164, T: 167958, Avg. loss: 0.006262\n",
      "Total training time: 9.82 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 0.37, NNZs: 341, Bias: -0.003321, T: 170624, Avg. loss: 0.006205\n",
      "Total training time: 9.97 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 0.37, NNZs: 340, Bias: -0.003439, T: 173290, Avg. loss: 0.006181\n",
      "Total training time: 10.12 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 0.38, NNZs: 339, Bias: -0.003537, T: 175956, Avg. loss: 0.006145\n",
      "Total training time: 10.27 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 0.38, NNZs: 345, Bias: -0.003852, T: 178622, Avg. loss: 0.006095\n",
      "Total training time: 10.42 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 0.38, NNZs: 341, Bias: -0.003827, T: 181288, Avg. loss: 0.006034\n",
      "Total training time: 10.57 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 0.39, NNZs: 341, Bias: -0.004005, T: 183954, Avg. loss: 0.006007\n",
      "Total training time: 10.72 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 0.39, NNZs: 347, Bias: -0.004350, T: 186620, Avg. loss: 0.005981\n",
      "Total training time: 10.87 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 0.39, NNZs: 347, Bias: -0.004438, T: 189286, Avg. loss: 0.005951\n",
      "Total training time: 11.02 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 0.40, NNZs: 345, Bias: -0.004564, T: 191952, Avg. loss: 0.005911\n",
      "Total training time: 11.16 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 0.40, NNZs: 344, Bias: -0.004673, T: 194618, Avg. loss: 0.005846\n",
      "Total training time: 11.31 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 0.40, NNZs: 349, Bias: -0.004914, T: 197284, Avg. loss: 0.005813\n",
      "Total training time: 11.46 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 0.41, NNZs: 347, Bias: -0.004969, T: 199950, Avg. loss: 0.005783\n",
      "Total training time: 11.62 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 0.41, NNZs: 346, Bias: -0.005028, T: 202616, Avg. loss: 0.005750\n",
      "Total training time: 11.77 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 0.41, NNZs: 347, Bias: -0.005280, T: 205282, Avg. loss: 0.005725\n",
      "Total training time: 11.92 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 0.42, NNZs: 347, Bias: -0.005395, T: 207948, Avg. loss: 0.005682\n",
      "Total training time: 12.08 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 0.42, NNZs: 346, Bias: -0.005542, T: 210614, Avg. loss: 0.005654\n",
      "Total training time: 12.24 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 0.42, NNZs: 345, Bias: -0.005586, T: 213280, Avg. loss: 0.005614\n",
      "Total training time: 12.39 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 0.43, NNZs: 347, Bias: -0.005807, T: 215946, Avg. loss: 0.005573\n",
      "Total training time: 12.55 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 0.43, NNZs: 352, Bias: -0.006031, T: 218612, Avg. loss: 0.005552\n",
      "Total training time: 12.70 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 0.43, NNZs: 351, Bias: -0.006144, T: 221278, Avg. loss: 0.005499\n",
      "Total training time: 12.85 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 0.44, NNZs: 362, Bias: -0.006393, T: 223944, Avg. loss: 0.005474\n",
      "Total training time: 13.01 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 0.44, NNZs: 369, Bias: -0.006620, T: 226610, Avg. loss: 0.005443\n",
      "Total training time: 13.16 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 0.44, NNZs: 367, Bias: -0.006706, T: 229276, Avg. loss: 0.005419\n",
      "Total training time: 13.31 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 0.44, NNZs: 369, Bias: -0.006924, T: 231942, Avg. loss: 0.005380\n",
      "Total training time: 13.46 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 0.45, NNZs: 371, Bias: -0.007117, T: 234608, Avg. loss: 0.005346\n",
      "Total training time: 13.62 seconds.\n",
      "-- Epoch 89\n",
      "Norm: 0.45, NNZs: 372, Bias: -0.007309, T: 237274, Avg. loss: 0.005313\n",
      "Total training time: 13.77 seconds.\n",
      "-- Epoch 90\n",
      "Norm: 0.45, NNZs: 363, Bias: -0.007167, T: 239940, Avg. loss: 0.005278\n",
      "Total training time: 13.93 seconds.\n",
      "-- Epoch 91\n",
      "Norm: 0.46, NNZs: 368, Bias: -0.007483, T: 242606, Avg. loss: 0.005256\n",
      "Total training time: 14.09 seconds.\n",
      "-- Epoch 92\n",
      "Norm: 0.46, NNZs: 367, Bias: -0.007602, T: 245272, Avg. loss: 0.005219\n",
      "Total training time: 14.25 seconds.\n",
      "-- Epoch 93\n",
      "Norm: 0.46, NNZs: 375, Bias: -0.007942, T: 247938, Avg. loss: 0.005201\n",
      "Total training time: 14.40 seconds.\n",
      "-- Epoch 94\n",
      "Norm: 0.47, NNZs: 373, Bias: -0.008059, T: 250604, Avg. loss: 0.005150\n",
      "Total training time: 14.56 seconds.\n",
      "-- Epoch 95\n",
      "Norm: 0.47, NNZs: 368, Bias: -0.008077, T: 253270, Avg. loss: 0.005115\n",
      "Total training time: 14.71 seconds.\n",
      "-- Epoch 96\n",
      "Norm: 0.47, NNZs: 371, Bias: -0.008291, T: 255936, Avg. loss: 0.005105\n",
      "Total training time: 14.87 seconds.\n",
      "-- Epoch 97\n",
      "Norm: 0.47, NNZs: 378, Bias: -0.008539, T: 258602, Avg. loss: 0.005077\n",
      "Total training time: 15.02 seconds.\n",
      "-- Epoch 98\n",
      "Norm: 0.48, NNZs: 375, Bias: -0.008608, T: 261268, Avg. loss: 0.005049\n",
      "Total training time: 15.18 seconds.\n",
      "-- Epoch 99\n",
      "Norm: 0.48, NNZs: 380, Bias: -0.008917, T: 263934, Avg. loss: 0.005017\n",
      "Total training time: 15.34 seconds.\n",
      "-- Epoch 100\n",
      "Norm: 0.48, NNZs: 380, Bias: -0.009052, T: 266600, Avg. loss: 0.005001\n",
      "Total training time: 15.50 seconds.\n",
      "-- Epoch 101\n",
      "Norm: 0.49, NNZs: 381, Bias: -0.009217, T: 269266, Avg. loss: 0.004964\n",
      "Total training time: 15.66 seconds.\n",
      "-- Epoch 102\n",
      "Norm: 0.49, NNZs: 380, Bias: -0.009339, T: 271932, Avg. loss: 0.004928\n",
      "Total training time: 15.82 seconds.\n",
      "-- Epoch 103\n",
      "Norm: 0.49, NNZs: 383, Bias: -0.009521, T: 274598, Avg. loss: 0.004905\n",
      "Total training time: 15.98 seconds.\n",
      "-- Epoch 104\n",
      "Norm: 0.49, NNZs: 389, Bias: -0.009854, T: 277264, Avg. loss: 0.004873\n",
      "Total training time: 16.14 seconds.\n",
      "-- Epoch 105\n",
      "Norm: 0.50, NNZs: 382, Bias: -0.009789, T: 279930, Avg. loss: 0.004857\n",
      "Total training time: 16.29 seconds.\n",
      "-- Epoch 106\n",
      "Norm: 0.50, NNZs: 384, Bias: -0.010026, T: 282596, Avg. loss: 0.004834\n",
      "Total training time: 16.45 seconds.\n",
      "-- Epoch 107\n",
      "Norm: 0.50, NNZs: 383, Bias: -0.010124, T: 285262, Avg. loss: 0.004798\n",
      "Total training time: 16.60 seconds.\n",
      "-- Epoch 108\n",
      "Norm: 0.50, NNZs: 387, Bias: -0.010429, T: 287928, Avg. loss: 0.004785\n",
      "Total training time: 16.75 seconds.\n",
      "-- Epoch 109\n",
      "Norm: 0.51, NNZs: 386, Bias: -0.010564, T: 290594, Avg. loss: 0.004755\n",
      "Total training time: 16.90 seconds.\n",
      "-- Epoch 110\n",
      "Norm: 0.51, NNZs: 387, Bias: -0.010813, T: 293260, Avg. loss: 0.004725\n",
      "Total training time: 17.06 seconds.\n",
      "-- Epoch 111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 0.51, NNZs: 386, Bias: -0.010912, T: 295926, Avg. loss: 0.004705\n",
      "Total training time: 17.21 seconds.\n",
      "-- Epoch 112\n",
      "Norm: 0.52, NNZs: 383, Bias: -0.011083, T: 298592, Avg. loss: 0.004680\n",
      "Total training time: 17.37 seconds.\n",
      "-- Epoch 113\n",
      "Norm: 0.52, NNZs: 383, Bias: -0.011268, T: 301258, Avg. loss: 0.004658\n",
      "Total training time: 17.52 seconds.\n",
      "-- Epoch 114\n",
      "Norm: 0.52, NNZs: 383, Bias: -0.011369, T: 303924, Avg. loss: 0.004627\n",
      "Total training time: 17.67 seconds.\n",
      "-- Epoch 115\n",
      "Norm: 0.52, NNZs: 385, Bias: -0.011576, T: 306590, Avg. loss: 0.004613\n",
      "Total training time: 17.83 seconds.\n",
      "-- Epoch 116\n",
      "Norm: 0.53, NNZs: 387, Bias: -0.011779, T: 309256, Avg. loss: 0.004586\n",
      "Total training time: 17.98 seconds.\n",
      "-- Epoch 117\n",
      "Norm: 0.53, NNZs: 389, Bias: -0.012071, T: 311922, Avg. loss: 0.004557\n",
      "Total training time: 18.14 seconds.\n",
      "Convergence after 117 epochs took 18.14 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.03, NNZs: 7575, Bias: 0.000547, T: 2667, Avg. loss: 0.010831\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.04, NNZs: 5075, Bias: 0.000809, T: 5334, Avg. loss: 0.010113\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.06, NNZs: 3772, Bias: 0.001020, T: 8001, Avg. loss: 0.009664\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.07, NNZs: 3128, Bias: 0.001214, T: 10668, Avg. loss: 0.009403\n",
      "Total training time: 0.70 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.08, NNZs: 2432, Bias: 0.001309, T: 13335, Avg. loss: 0.009209\n",
      "Total training time: 0.87 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.09, NNZs: 2117, Bias: 0.001451, T: 16002, Avg. loss: 0.008970\n",
      "Total training time: 1.03 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.10, NNZs: 2012, Bias: 0.001647, T: 18669, Avg. loss: 0.008956\n",
      "Total training time: 1.19 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.10, NNZs: 1707, Bias: 0.001713, T: 21336, Avg. loss: 0.008830\n",
      "Total training time: 1.36 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.11, NNZs: 1472, Bias: 0.001753, T: 24003, Avg. loss: 0.008745\n",
      "Total training time: 1.53 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.12, NNZs: 1310, Bias: 0.001824, T: 26670, Avg. loss: 0.008654\n",
      "Total training time: 1.69 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.13, NNZs: 1193, Bias: 0.001896, T: 29337, Avg. loss: 0.008593\n",
      "Total training time: 1.84 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.13, NNZs: 1065, Bias: 0.001917, T: 32004, Avg. loss: 0.008510\n",
      "Total training time: 2.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.14, NNZs: 1028, Bias: 0.002028, T: 34671, Avg. loss: 0.008442\n",
      "Total training time: 2.15 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 0.15, NNZs: 930, Bias: 0.002029, T: 37338, Avg. loss: 0.008371\n",
      "Total training time: 2.31 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 0.15, NNZs: 845, Bias: 0.002007, T: 40005, Avg. loss: 0.008304\n",
      "Total training time: 2.47 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 0.16, NNZs: 781, Bias: 0.002010, T: 42672, Avg. loss: 0.008243\n",
      "Total training time: 2.63 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 0.16, NNZs: 758, Bias: 0.002090, T: 45339, Avg. loss: 0.008168\n",
      "Total training time: 2.79 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 0.17, NNZs: 656, Bias: 0.001940, T: 48006, Avg. loss: 0.008152\n",
      "Total training time: 2.94 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.18, NNZs: 693, Bias: 0.002163, T: 50673, Avg. loss: 0.008081\n",
      "Total training time: 3.11 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 0.18, NNZs: 636, Bias: 0.002124, T: 53340, Avg. loss: 0.008042\n",
      "Total training time: 3.27 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 0.19, NNZs: 574, Bias: 0.002036, T: 56007, Avg. loss: 0.007981\n",
      "Total training time: 3.43 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.19, NNZs: 564, Bias: 0.002013, T: 58674, Avg. loss: 0.007924\n",
      "Total training time: 3.58 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 0.20, NNZs: 525, Bias: 0.001948, T: 61341, Avg. loss: 0.007875\n",
      "Total training time: 3.73 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 0.20, NNZs: 493, Bias: 0.001840, T: 64008, Avg. loss: 0.007822\n",
      "Total training time: 3.88 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 0.21, NNZs: 509, Bias: 0.002040, T: 66675, Avg. loss: 0.007750\n",
      "Total training time: 4.04 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 0.21, NNZs: 475, Bias: 0.001890, T: 69342, Avg. loss: 0.007735\n",
      "Total training time: 4.20 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 0.22, NNZs: 463, Bias: 0.001832, T: 72009, Avg. loss: 0.007680\n",
      "Total training time: 4.35 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 0.22, NNZs: 418, Bias: 0.001640, T: 74676, Avg. loss: 0.007627\n",
      "Total training time: 4.50 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 0.23, NNZs: 408, Bias: 0.001667, T: 77343, Avg. loss: 0.007587\n",
      "Total training time: 4.65 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 0.23, NNZs: 389, Bias: 0.001499, T: 80010, Avg. loss: 0.007540\n",
      "Total training time: 4.80 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 0.23, NNZs: 370, Bias: 0.001387, T: 82677, Avg. loss: 0.007468\n",
      "Total training time: 4.94 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 0.24, NNZs: 370, Bias: 0.001446, T: 85344, Avg. loss: 0.007446\n",
      "Total training time: 5.09 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.24, NNZs: 351, Bias: 0.001206, T: 88011, Avg. loss: 0.007393\n",
      "Total training time: 5.25 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.25, NNZs: 349, Bias: 0.001212, T: 90678, Avg. loss: 0.007331\n",
      "Total training time: 5.40 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 0.25, NNZs: 348, Bias: 0.001043, T: 93345, Avg. loss: 0.007319\n",
      "Total training time: 5.55 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 0.25, NNZs: 337, Bias: 0.000845, T: 96012, Avg. loss: 0.007249\n",
      "Total training time: 5.71 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 0.26, NNZs: 343, Bias: 0.001060, T: 98679, Avg. loss: 0.007217\n",
      "Total training time: 5.87 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 0.26, NNZs: 322, Bias: 0.000570, T: 101346, Avg. loss: 0.007175\n",
      "Total training time: 6.02 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 0.27, NNZs: 319, Bias: 0.000484, T: 104013, Avg. loss: 0.007124\n",
      "Total training time: 6.18 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 0.27, NNZs: 316, Bias: 0.000440, T: 106680, Avg. loss: 0.007083\n",
      "Total training time: 6.34 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 0.27, NNZs: 316, Bias: 0.000260, T: 109347, Avg. loss: 0.007044\n",
      "Total training time: 6.49 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 0.28, NNZs: 316, Bias: 0.000217, T: 112014, Avg. loss: 0.006998\n",
      "Total training time: 6.64 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 0.28, NNZs: 311, Bias: 0.000092, T: 114681, Avg. loss: 0.006963\n",
      "Total training time: 6.79 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 0.29, NNZs: 308, Bias: 0.000047, T: 117348, Avg. loss: 0.006919\n",
      "Total training time: 6.94 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 0.29, NNZs: 304, Bias: -0.000206, T: 120015, Avg. loss: 0.006875\n",
      "Total training time: 7.09 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 0.29, NNZs: 303, Bias: -0.000244, T: 122682, Avg. loss: 0.006834\n",
      "Total training time: 7.25 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 0.30, NNZs: 300, Bias: -0.000102, T: 125349, Avg. loss: 0.006770\n",
      "Total training time: 7.40 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 0.30, NNZs: 306, Bias: -0.000437, T: 128016, Avg. loss: 0.006750\n",
      "Total training time: 7.55 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 0.31, NNZs: 308, Bias: -0.000646, T: 130683, Avg. loss: 0.006700\n",
      "Total training time: 7.70 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 0.31, NNZs: 308, Bias: -0.000817, T: 133350, Avg. loss: 0.006649\n",
      "Total training time: 7.85 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 0.31, NNZs: 306, Bias: -0.000846, T: 136017, Avg. loss: 0.006605\n",
      "Total training time: 8.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 0.32, NNZs: 308, Bias: -0.000946, T: 138684, Avg. loss: 0.006586\n",
      "Total training time: 8.16 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 0.32, NNZs: 311, Bias: -0.001211, T: 141351, Avg. loss: 0.006544\n",
      "Total training time: 8.31 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 0.32, NNZs: 305, Bias: -0.001136, T: 144018, Avg. loss: 0.006488\n",
      "Total training time: 8.46 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 0.33, NNZs: 307, Bias: -0.001316, T: 146685, Avg. loss: 0.006454\n",
      "Total training time: 8.62 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 0.33, NNZs: 312, Bias: -0.001500, T: 149352, Avg. loss: 0.006421\n",
      "Total training time: 8.77 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 0.33, NNZs: 310, Bias: -0.001645, T: 152019, Avg. loss: 0.006372\n",
      "Total training time: 8.93 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 0.34, NNZs: 308, Bias: -0.001745, T: 154686, Avg. loss: 0.006339\n",
      "Total training time: 9.09 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 0.34, NNZs: 306, Bias: -0.001870, T: 157353, Avg. loss: 0.006302\n",
      "Total training time: 9.24 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 0.34, NNZs: 308, Bias: -0.002035, T: 160020, Avg. loss: 0.006259\n",
      "Total training time: 9.40 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 0.35, NNZs: 314, Bias: -0.002288, T: 162687, Avg. loss: 0.006218\n",
      "Total training time: 9.56 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 0.35, NNZs: 306, Bias: -0.002194, T: 165354, Avg. loss: 0.006180\n",
      "Total training time: 9.72 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 0.35, NNZs: 310, Bias: -0.002342, T: 168021, Avg. loss: 0.006135\n",
      "Total training time: 9.87 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 0.36, NNZs: 317, Bias: -0.002698, T: 170688, Avg. loss: 0.006107\n",
      "Total training time: 10.03 seconds.\n",
      "-- Epoch 65\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 0.36, NNZs: 316, Bias: -0.002792, T: 173355, Avg. loss: 0.006069\n",
      "Total training time: 10.18 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 0.36, NNZs: 313, Bias: -0.002776, T: 176022, Avg. loss: 0.006033\n",
      "Total training time: 10.34 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 0.37, NNZs: 321, Bias: -0.003006, T: 178689, Avg. loss: 0.005997\n",
      "Total training time: 10.50 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 0.37, NNZs: 323, Bias: -0.003157, T: 181356, Avg. loss: 0.005966\n",
      "Total training time: 10.66 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 0.37, NNZs: 329, Bias: -0.003327, T: 184023, Avg. loss: 0.005916\n",
      "Total training time: 10.82 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 0.38, NNZs: 327, Bias: -0.003405, T: 186690, Avg. loss: 0.005890\n",
      "Total training time: 10.98 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 0.38, NNZs: 330, Bias: -0.003573, T: 189357, Avg. loss: 0.005852\n",
      "Total training time: 11.15 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 0.38, NNZs: 329, Bias: -0.003658, T: 192024, Avg. loss: 0.005819\n",
      "Total training time: 11.30 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 0.39, NNZs: 334, Bias: -0.003851, T: 194691, Avg. loss: 0.005782\n",
      "Total training time: 11.46 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 0.39, NNZs: 327, Bias: -0.003853, T: 197358, Avg. loss: 0.005746\n",
      "Total training time: 11.63 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 0.39, NNZs: 341, Bias: -0.004206, T: 200025, Avg. loss: 0.005717\n",
      "Total training time: 11.79 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 0.40, NNZs: 331, Bias: -0.004164, T: 202692, Avg. loss: 0.005681\n",
      "Total training time: 11.96 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 0.40, NNZs: 342, Bias: -0.004543, T: 205359, Avg. loss: 0.005644\n",
      "Total training time: 12.12 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 0.40, NNZs: 336, Bias: -0.004520, T: 208026, Avg. loss: 0.005617\n",
      "Total training time: 12.28 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 0.41, NNZs: 337, Bias: -0.004639, T: 210693, Avg. loss: 0.005586\n",
      "Total training time: 12.44 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 0.41, NNZs: 339, Bias: -0.004858, T: 213360, Avg. loss: 0.005553\n",
      "Total training time: 12.60 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 0.41, NNZs: 338, Bias: -0.004962, T: 216027, Avg. loss: 0.005521\n",
      "Total training time: 12.75 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 0.41, NNZs: 337, Bias: -0.005035, T: 218694, Avg. loss: 0.005487\n",
      "Total training time: 12.90 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 0.42, NNZs: 349, Bias: -0.005392, T: 221361, Avg. loss: 0.005443\n",
      "Total training time: 13.06 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 0.42, NNZs: 342, Bias: -0.005397, T: 224028, Avg. loss: 0.005433\n",
      "Total training time: 13.21 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 0.42, NNZs: 341, Bias: -0.005537, T: 226695, Avg. loss: 0.005400\n",
      "Total training time: 13.37 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 0.43, NNZs: 349, Bias: -0.005759, T: 229362, Avg. loss: 0.005354\n",
      "Total training time: 13.53 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 0.43, NNZs: 353, Bias: -0.006044, T: 232029, Avg. loss: 0.005338\n",
      "Total training time: 13.68 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 0.43, NNZs: 349, Bias: -0.006052, T: 234696, Avg. loss: 0.005302\n",
      "Total training time: 13.83 seconds.\n",
      "-- Epoch 89\n",
      "Norm: 0.44, NNZs: 347, Bias: -0.006126, T: 237363, Avg. loss: 0.005272\n",
      "Total training time: 13.98 seconds.\n",
      "-- Epoch 90\n",
      "Norm: 0.44, NNZs: 350, Bias: -0.006333, T: 240030, Avg. loss: 0.005263\n",
      "Total training time: 14.13 seconds.\n",
      "-- Epoch 91\n",
      "Norm: 0.44, NNZs: 351, Bias: -0.006466, T: 242697, Avg. loss: 0.005224\n",
      "Total training time: 14.28 seconds.\n",
      "-- Epoch 92\n",
      "Norm: 0.44, NNZs: 352, Bias: -0.006697, T: 245364, Avg. loss: 0.005197\n",
      "Total training time: 14.43 seconds.\n",
      "-- Epoch 93\n",
      "Norm: 0.45, NNZs: 350, Bias: -0.006877, T: 248031, Avg. loss: 0.005169\n",
      "Total training time: 14.58 seconds.\n",
      "-- Epoch 94\n",
      "Norm: 0.45, NNZs: 349, Bias: -0.007013, T: 250698, Avg. loss: 0.005134\n",
      "Total training time: 14.74 seconds.\n",
      "-- Epoch 95\n",
      "Norm: 0.45, NNZs: 348, Bias: -0.007102, T: 253365, Avg. loss: 0.005110\n",
      "Total training time: 14.89 seconds.\n",
      "-- Epoch 96\n",
      "Norm: 0.46, NNZs: 349, Bias: -0.007336, T: 256032, Avg. loss: 0.005083\n",
      "Total training time: 15.04 seconds.\n",
      "-- Epoch 97\n",
      "Norm: 0.46, NNZs: 348, Bias: -0.007460, T: 258699, Avg. loss: 0.005059\n",
      "Total training time: 15.19 seconds.\n",
      "-- Epoch 98\n",
      "Norm: 0.46, NNZs: 354, Bias: -0.007641, T: 261366, Avg. loss: 0.005025\n",
      "Total training time: 15.34 seconds.\n",
      "-- Epoch 99\n",
      "Norm: 0.46, NNZs: 360, Bias: -0.007851, T: 264033, Avg. loss: 0.005004\n",
      "Total training time: 15.50 seconds.\n",
      "-- Epoch 100\n",
      "Norm: 0.47, NNZs: 360, Bias: -0.007970, T: 266700, Avg. loss: 0.004981\n",
      "Total training time: 15.66 seconds.\n",
      "-- Epoch 101\n",
      "Norm: 0.47, NNZs: 365, Bias: -0.008199, T: 269367, Avg. loss: 0.004952\n",
      "Total training time: 15.83 seconds.\n",
      "-- Epoch 102\n",
      "Norm: 0.47, NNZs: 353, Bias: -0.008156, T: 272034, Avg. loss: 0.004903\n",
      "Total training time: 15.99 seconds.\n",
      "-- Epoch 103\n",
      "Norm: 0.47, NNZs: 354, Bias: -0.008319, T: 274701, Avg. loss: 0.004888\n",
      "Total training time: 16.15 seconds.\n",
      "-- Epoch 104\n",
      "Norm: 0.48, NNZs: 368, Bias: -0.008699, T: 277368, Avg. loss: 0.004871\n",
      "Total training time: 16.31 seconds.\n",
      "-- Epoch 105\n",
      "Norm: 0.48, NNZs: 368, Bias: -0.008775, T: 280035, Avg. loss: 0.004859\n",
      "Total training time: 16.46 seconds.\n",
      "-- Epoch 106\n",
      "Norm: 0.48, NNZs: 364, Bias: -0.008883, T: 282702, Avg. loss: 0.004828\n",
      "Total training time: 16.61 seconds.\n",
      "-- Epoch 107\n",
      "Norm: 0.48, NNZs: 369, Bias: -0.009128, T: 285369, Avg. loss: 0.004807\n",
      "Total training time: 16.76 seconds.\n",
      "-- Epoch 108\n",
      "Norm: 0.49, NNZs: 360, Bias: -0.009128, T: 288036, Avg. loss: 0.004767\n",
      "Total training time: 16.92 seconds.\n",
      "Convergence after 108 epochs took 16.92 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.03, NNZs: 7459, Bias: 0.000543, T: 2667, Avg. loss: 0.011460\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.04, NNZs: 5097, Bias: 0.000811, T: 5334, Avg. loss: 0.010607\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.06, NNZs: 3881, Bias: 0.001026, T: 8001, Avg. loss: 0.010033\n",
      "Total training time: 0.57 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.07, NNZs: 2970, Bias: 0.001172, T: 10668, Avg. loss: 0.009838\n",
      "Total training time: 0.75 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.08, NNZs: 2412, Bias: 0.001305, T: 13335, Avg. loss: 0.009660\n",
      "Total training time: 0.93 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.09, NNZs: 1898, Bias: 0.001350, T: 16002, Avg. loss: 0.009527\n",
      "Total training time: 1.09 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.10, NNZs: 1899, Bias: 0.001583, T: 18669, Avg. loss: 0.009384\n",
      "Total training time: 1.26 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.11, NNZs: 1540, Bias: 0.001574, T: 21336, Avg. loss: 0.009229\n",
      "Total training time: 1.43 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.11, NNZs: 1289, Bias: 0.001571, T: 24003, Avg. loss: 0.009141\n",
      "Total training time: 1.59 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.12, NNZs: 1236, Bias: 0.001712, T: 26670, Avg. loss: 0.009095\n",
      "Total training time: 1.75 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.13, NNZs: 1304, Bias: 0.001957, T: 29337, Avg. loss: 0.008961\n",
      "Total training time: 1.90 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.14, NNZs: 1071, Bias: 0.001843, T: 32004, Avg. loss: 0.008879\n",
      "Total training time: 2.05 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.14, NNZs: 989, Bias: 0.001861, T: 34671, Avg. loss: 0.008849\n",
      "Total training time: 2.22 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 0.15, NNZs: 855, Bias: 0.001764, T: 37338, Avg. loss: 0.008781\n",
      "Total training time: 2.38 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 0.16, NNZs: 914, Bias: 0.002011, T: 40005, Avg. loss: 0.008648\n",
      "Total training time: 2.54 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 0.16, NNZs: 803, Bias: 0.001907, T: 42672, Avg. loss: 0.008609\n",
      "Total training time: 2.70 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 0.17, NNZs: 680, Bias: 0.001743, T: 45339, Avg. loss: 0.008569\n",
      "Total training time: 2.86 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 0.17, NNZs: 651, Bias: 0.001732, T: 48006, Avg. loss: 0.008519\n",
      "Total training time: 3.03 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.18, NNZs: 640, Bias: 0.001805, T: 50673, Avg. loss: 0.008409\n",
      "Total training time: 3.19 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 0.19, NNZs: 581, Bias: 0.001717, T: 53340, Avg. loss: 0.008368\n",
      "Total training time: 3.35 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 0.19, NNZs: 541, Bias: 0.001616, T: 56007, Avg. loss: 0.008274\n",
      "Total training time: 3.51 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.20, NNZs: 529, Bias: 0.001642, T: 58674, Avg. loss: 0.008262\n",
      "Total training time: 3.67 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 0.20, NNZs: 504, Bias: 0.001583, T: 61341, Avg. loss: 0.008195\n",
      "Total training time: 3.84 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 0.21, NNZs: 473, Bias: 0.001469, T: 64008, Avg. loss: 0.008162\n",
      "Total training time: 4.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 0.21, NNZs: 474, Bias: 0.001542, T: 66675, Avg. loss: 0.008084\n",
      "Total training time: 4.16 seconds.\n",
      "-- Epoch 26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 0.22, NNZs: 455, Bias: 0.001351, T: 69342, Avg. loss: 0.008026\n",
      "Total training time: 4.32 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 0.22, NNZs: 446, Bias: 0.001301, T: 72009, Avg. loss: 0.007967\n",
      "Total training time: 4.47 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 0.23, NNZs: 430, Bias: 0.001261, T: 74676, Avg. loss: 0.007938\n",
      "Total training time: 4.62 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 0.23, NNZs: 406, Bias: 0.001037, T: 77343, Avg. loss: 0.007876\n",
      "Total training time: 4.78 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 0.24, NNZs: 407, Bias: 0.001110, T: 80010, Avg. loss: 0.007812\n",
      "Total training time: 4.94 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 0.24, NNZs: 382, Bias: 0.000876, T: 82677, Avg. loss: 0.007766\n",
      "Total training time: 5.10 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 0.24, NNZs: 373, Bias: 0.000736, T: 85344, Avg. loss: 0.007702\n",
      "Total training time: 5.25 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.25, NNZs: 364, Bias: 0.000630, T: 88011, Avg. loss: 0.007684\n",
      "Total training time: 5.41 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.25, NNZs: 361, Bias: 0.000533, T: 90678, Avg. loss: 0.007629\n",
      "Total training time: 5.57 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 0.26, NNZs: 357, Bias: 0.000294, T: 93345, Avg. loss: 0.007579\n",
      "Total training time: 5.73 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 0.26, NNZs: 358, Bias: 0.000438, T: 96012, Avg. loss: 0.007531\n",
      "Total training time: 5.90 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 0.27, NNZs: 358, Bias: 0.000324, T: 98679, Avg. loss: 0.007481\n",
      "Total training time: 6.06 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 0.27, NNZs: 345, Bias: 0.000172, T: 101346, Avg. loss: 0.007420\n",
      "Total training time: 6.21 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 0.27, NNZs: 345, Bias: -0.000117, T: 104013, Avg. loss: 0.007373\n",
      "Total training time: 6.37 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 0.28, NNZs: 340, Bias: -0.000262, T: 106680, Avg. loss: 0.007320\n",
      "Total training time: 6.53 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 0.28, NNZs: 338, Bias: -0.000336, T: 109347, Avg. loss: 0.007282\n",
      "Total training time: 6.68 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 0.29, NNZs: 336, Bias: -0.000401, T: 112014, Avg. loss: 0.007209\n",
      "Total training time: 6.83 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 0.29, NNZs: 337, Bias: -0.000614, T: 114681, Avg. loss: 0.007134\n",
      "Total training time: 6.98 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 0.30, NNZs: 337, Bias: -0.000697, T: 117348, Avg. loss: 0.007140\n",
      "Total training time: 7.14 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 0.30, NNZs: 336, Bias: -0.000784, T: 120015, Avg. loss: 0.007065\n",
      "Total training time: 7.30 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 0.30, NNZs: 337, Bias: -0.000883, T: 122682, Avg. loss: 0.007031\n",
      "Total training time: 7.46 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 0.31, NNZs: 336, Bias: -0.001087, T: 125349, Avg. loss: 0.006973\n",
      "Total training time: 7.62 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 0.31, NNZs: 336, Bias: -0.001165, T: 128016, Avg. loss: 0.006930\n",
      "Total training time: 7.77 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 0.31, NNZs: 334, Bias: -0.001259, T: 130683, Avg. loss: 0.006894\n",
      "Total training time: 7.93 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 0.32, NNZs: 335, Bias: -0.001324, T: 133350, Avg. loss: 0.006841\n",
      "Total training time: 8.10 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 0.32, NNZs: 339, Bias: -0.001587, T: 136017, Avg. loss: 0.006787\n",
      "Total training time: 8.25 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 0.33, NNZs: 336, Bias: -0.001632, T: 138684, Avg. loss: 0.006748\n",
      "Total training time: 8.41 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 0.33, NNZs: 347, Bias: -0.002021, T: 141351, Avg. loss: 0.006691\n",
      "Total training time: 8.58 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 0.33, NNZs: 339, Bias: -0.001897, T: 144018, Avg. loss: 0.006654\n",
      "Total training time: 8.74 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 0.34, NNZs: 346, Bias: -0.002155, T: 146685, Avg. loss: 0.006623\n",
      "Total training time: 8.90 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 0.34, NNZs: 349, Bias: -0.002334, T: 149352, Avg. loss: 0.006569\n",
      "Total training time: 9.07 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 0.34, NNZs: 347, Bias: -0.002317, T: 152019, Avg. loss: 0.006534\n",
      "Total training time: 9.23 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 0.35, NNZs: 347, Bias: -0.002424, T: 154686, Avg. loss: 0.006478\n",
      "Total training time: 9.39 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 0.35, NNZs: 346, Bias: -0.002741, T: 157353, Avg. loss: 0.006440\n",
      "Total training time: 9.55 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 0.36, NNZs: 343, Bias: -0.002802, T: 160020, Avg. loss: 0.006388\n",
      "Total training time: 9.71 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 0.36, NNZs: 349, Bias: -0.003040, T: 162687, Avg. loss: 0.006362\n",
      "Total training time: 9.89 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 0.36, NNZs: 345, Bias: -0.003012, T: 165354, Avg. loss: 0.006310\n",
      "Total training time: 10.06 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 0.37, NNZs: 344, Bias: -0.003299, T: 168021, Avg. loss: 0.006259\n",
      "Total training time: 10.22 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 0.37, NNZs: 344, Bias: -0.003376, T: 170688, Avg. loss: 0.006215\n",
      "Total training time: 10.38 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 0.37, NNZs: 349, Bias: -0.003643, T: 173355, Avg. loss: 0.006190\n",
      "Total training time: 10.53 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 0.38, NNZs: 347, Bias: -0.003680, T: 176022, Avg. loss: 0.006158\n",
      "Total training time: 10.68 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 0.38, NNZs: 339, Bias: -0.003653, T: 178689, Avg. loss: 0.006099\n",
      "Total training time: 10.85 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 0.38, NNZs: 351, Bias: -0.004022, T: 181356, Avg. loss: 0.006068\n",
      "Total training time: 11.01 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 0.39, NNZs: 351, Bias: -0.004184, T: 184023, Avg. loss: 0.006033\n",
      "Total training time: 11.17 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 0.39, NNZs: 352, Bias: -0.004333, T: 186690, Avg. loss: 0.005986\n",
      "Total training time: 11.33 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 0.39, NNZs: 352, Bias: -0.004470, T: 189357, Avg. loss: 0.005951\n",
      "Total training time: 11.49 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 0.40, NNZs: 347, Bias: -0.004515, T: 192024, Avg. loss: 0.005907\n",
      "Total training time: 11.65 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 0.40, NNZs: 356, Bias: -0.004785, T: 194691, Avg. loss: 0.005872\n",
      "Total training time: 11.81 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 0.40, NNZs: 354, Bias: -0.004846, T: 197358, Avg. loss: 0.005837\n",
      "Total training time: 11.97 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 0.41, NNZs: 357, Bias: -0.005064, T: 200025, Avg. loss: 0.005799\n",
      "Total training time: 12.12 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 0.41, NNZs: 358, Bias: -0.005194, T: 202692, Avg. loss: 0.005765\n",
      "Total training time: 12.28 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 0.41, NNZs: 363, Bias: -0.005451, T: 205359, Avg. loss: 0.005734\n",
      "Total training time: 12.44 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 0.42, NNZs: 361, Bias: -0.005518, T: 208026, Avg. loss: 0.005688\n",
      "Total training time: 12.60 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 0.42, NNZs: 365, Bias: -0.005733, T: 210693, Avg. loss: 0.005660\n",
      "Total training time: 12.76 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 0.42, NNZs: 371, Bias: -0.005938, T: 213360, Avg. loss: 0.005623\n",
      "Total training time: 12.92 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 0.42, NNZs: 364, Bias: -0.005973, T: 216027, Avg. loss: 0.005585\n",
      "Total training time: 13.07 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 0.43, NNZs: 370, Bias: -0.006163, T: 218694, Avg. loss: 0.005537\n",
      "Total training time: 13.23 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 0.43, NNZs: 364, Bias: -0.006171, T: 221361, Avg. loss: 0.005506\n",
      "Total training time: 13.39 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 0.43, NNZs: 381, Bias: -0.006562, T: 224028, Avg. loss: 0.005472\n",
      "Total training time: 13.55 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 0.44, NNZs: 383, Bias: -0.006764, T: 226695, Avg. loss: 0.005445\n",
      "Total training time: 13.71 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 0.44, NNZs: 382, Bias: -0.006856, T: 229362, Avg. loss: 0.005422\n",
      "Total training time: 13.87 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 0.44, NNZs: 380, Bias: -0.006975, T: 232029, Avg. loss: 0.005382\n",
      "Total training time: 14.02 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 0.45, NNZs: 385, Bias: -0.007235, T: 234696, Avg. loss: 0.005351\n",
      "Total training time: 14.18 seconds.\n",
      "-- Epoch 89\n",
      "Norm: 0.45, NNZs: 378, Bias: -0.007177, T: 237363, Avg. loss: 0.005317\n",
      "Total training time: 14.33 seconds.\n",
      "-- Epoch 90\n",
      "Norm: 0.45, NNZs: 381, Bias: -0.007396, T: 240030, Avg. loss: 0.005300\n",
      "Total training time: 14.49 seconds.\n",
      "-- Epoch 91\n",
      "Norm: 0.46, NNZs: 388, Bias: -0.007662, T: 242697, Avg. loss: 0.005275\n",
      "Total training time: 14.65 seconds.\n",
      "-- Epoch 92\n",
      "Norm: 0.46, NNZs: 385, Bias: -0.007742, T: 245364, Avg. loss: 0.005234\n",
      "Total training time: 14.81 seconds.\n",
      "-- Epoch 93\n",
      "Norm: 0.46, NNZs: 388, Bias: -0.007912, T: 248031, Avg. loss: 0.005205\n",
      "Total training time: 14.97 seconds.\n",
      "-- Epoch 94\n",
      "Norm: 0.46, NNZs: 387, Bias: -0.008073, T: 250698, Avg. loss: 0.005178\n",
      "Total training time: 15.13 seconds.\n",
      "-- Epoch 95\n",
      "Norm: 0.47, NNZs: 392, Bias: -0.008313, T: 253365, Avg. loss: 0.005151\n",
      "Total training time: 15.29 seconds.\n",
      "-- Epoch 96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 0.47, NNZs: 384, Bias: -0.008285, T: 256032, Avg. loss: 0.005102\n",
      "Total training time: 15.44 seconds.\n",
      "-- Epoch 97\n",
      "Norm: 0.47, NNZs: 396, Bias: -0.008659, T: 258699, Avg. loss: 0.005086\n",
      "Total training time: 15.60 seconds.\n",
      "-- Epoch 98\n",
      "Norm: 0.48, NNZs: 400, Bias: -0.008846, T: 261366, Avg. loss: 0.005054\n",
      "Total training time: 15.76 seconds.\n",
      "-- Epoch 99\n",
      "Norm: 0.48, NNZs: 400, Bias: -0.008986, T: 264033, Avg. loss: 0.005031\n",
      "Total training time: 15.91 seconds.\n",
      "-- Epoch 100\n",
      "Norm: 0.48, NNZs: 402, Bias: -0.009186, T: 266700, Avg. loss: 0.005003\n",
      "Total training time: 16.07 seconds.\n",
      "-- Epoch 101\n",
      "Norm: 0.48, NNZs: 405, Bias: -0.009416, T: 269367, Avg. loss: 0.004965\n",
      "Total training time: 16.23 seconds.\n",
      "-- Epoch 102\n",
      "Norm: 0.49, NNZs: 401, Bias: -0.009470, T: 272034, Avg. loss: 0.004955\n",
      "Total training time: 16.39 seconds.\n",
      "-- Epoch 103\n",
      "Norm: 0.49, NNZs: 396, Bias: -0.009485, T: 274701, Avg. loss: 0.004900\n",
      "Total training time: 16.54 seconds.\n",
      "-- Epoch 104\n",
      "Norm: 0.49, NNZs: 404, Bias: -0.009794, T: 277368, Avg. loss: 0.004891\n",
      "Total training time: 16.70 seconds.\n",
      "-- Epoch 105\n",
      "Norm: 0.50, NNZs: 404, Bias: -0.009999, T: 280035, Avg. loss: 0.004869\n",
      "Total training time: 16.86 seconds.\n",
      "-- Epoch 106\n",
      "Norm: 0.50, NNZs: 407, Bias: -0.010253, T: 282702, Avg. loss: 0.004837\n",
      "Total training time: 17.02 seconds.\n",
      "-- Epoch 107\n",
      "Norm: 0.50, NNZs: 404, Bias: -0.010329, T: 285369, Avg. loss: 0.004813\n",
      "Total training time: 17.18 seconds.\n",
      "-- Epoch 108\n",
      "Norm: 0.50, NNZs: 402, Bias: -0.010433, T: 288036, Avg. loss: 0.004780\n",
      "Total training time: 17.34 seconds.\n",
      "-- Epoch 109\n",
      "Norm: 0.51, NNZs: 405, Bias: -0.010716, T: 290703, Avg. loss: 0.004768\n",
      "Total training time: 17.50 seconds.\n",
      "-- Epoch 110\n",
      "Norm: 0.51, NNZs: 405, Bias: -0.010864, T: 293370, Avg. loss: 0.004742\n",
      "Total training time: 17.65 seconds.\n",
      "-- Epoch 111\n",
      "Norm: 0.51, NNZs: 403, Bias: -0.010983, T: 296037, Avg. loss: 0.004708\n",
      "Total training time: 17.80 seconds.\n",
      "-- Epoch 112\n",
      "Norm: 0.51, NNZs: 410, Bias: -0.011246, T: 298704, Avg. loss: 0.004691\n",
      "Total training time: 17.96 seconds.\n",
      "-- Epoch 113\n",
      "Norm: 0.52, NNZs: 413, Bias: -0.011407, T: 301371, Avg. loss: 0.004662\n",
      "Total training time: 18.12 seconds.\n",
      "-- Epoch 114\n",
      "Norm: 0.52, NNZs: 408, Bias: -0.011491, T: 304038, Avg. loss: 0.004643\n",
      "Total training time: 18.28 seconds.\n",
      "-- Epoch 115\n",
      "Norm: 0.52, NNZs: 411, Bias: -0.011726, T: 306705, Avg. loss: 0.004615\n",
      "Total training time: 18.44 seconds.\n",
      "-- Epoch 116\n",
      "Norm: 0.52, NNZs: 411, Bias: -0.011886, T: 309372, Avg. loss: 0.004590\n",
      "Total training time: 18.60 seconds.\n",
      "-- Epoch 117\n",
      "Norm: 0.53, NNZs: 413, Bias: -0.012276, T: 312039, Avg. loss: 0.004566\n",
      "Total training time: 18.76 seconds.\n",
      "-- Epoch 118\n",
      "Norm: 0.53, NNZs: 407, Bias: -0.012155, T: 314706, Avg. loss: 0.004548\n",
      "Total training time: 18.92 seconds.\n",
      "-- Epoch 119\n",
      "Norm: 0.53, NNZs: 413, Bias: -0.012610, T: 317373, Avg. loss: 0.004522\n",
      "Total training time: 19.07 seconds.\n",
      "Convergence after 119 epochs took 19.08 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.03, NNZs: 7274, Bias: 0.000609, T: 2666, Avg. loss: 0.011454\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.05, NNZs: 5227, Bias: 0.000977, T: 5332, Avg. loss: 0.010590\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.06, NNZs: 3666, Bias: 0.001228, T: 7998, Avg. loss: 0.010196\n",
      "Total training time: 0.55 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.07, NNZs: 3156, Bias: 0.001526, T: 10664, Avg. loss: 0.009847\n",
      "Total training time: 0.72 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.08, NNZs: 2418, Bias: 0.001696, T: 13330, Avg. loss: 0.009751\n",
      "Total training time: 0.89 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.09, NNZs: 2178, Bias: 0.001939, T: 15996, Avg. loss: 0.009561\n",
      "Total training time: 1.05 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.10, NNZs: 1778, Bias: 0.002069, T: 18662, Avg. loss: 0.009433\n",
      "Total training time: 1.22 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.11, NNZs: 1540, Bias: 0.002216, T: 21328, Avg. loss: 0.009333\n",
      "Total training time: 1.38 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.12, NNZs: 1313, Bias: 0.002311, T: 23994, Avg. loss: 0.009173\n",
      "Total training time: 1.54 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.13, NNZs: 1245, Bias: 0.002511, T: 26660, Avg. loss: 0.009126\n",
      "Total training time: 1.69 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.13, NNZs: 1057, Bias: 0.002562, T: 29326, Avg. loss: 0.009000\n",
      "Total training time: 1.85 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.14, NNZs: 1083, Bias: 0.002834, T: 31992, Avg. loss: 0.008979\n",
      "Total training time: 2.01 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.15, NNZs: 911, Bias: 0.002801, T: 34658, Avg. loss: 0.008872\n",
      "Total training time: 2.16 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 0.15, NNZs: 777, Bias: 0.002764, T: 37324, Avg. loss: 0.008788\n",
      "Total training time: 2.32 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 0.16, NNZs: 803, Bias: 0.003015, T: 39990, Avg. loss: 0.008730\n",
      "Total training time: 2.47 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 0.17, NNZs: 684, Bias: 0.002951, T: 42656, Avg. loss: 0.008669\n",
      "Total training time: 2.63 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 0.17, NNZs: 640, Bias: 0.003007, T: 45322, Avg. loss: 0.008603\n",
      "Total training time: 2.79 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 0.18, NNZs: 642, Bias: 0.003204, T: 47988, Avg. loss: 0.008576\n",
      "Total training time: 2.95 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.18, NNZs: 545, Bias: 0.003068, T: 50654, Avg. loss: 0.008474\n",
      "Total training time: 3.10 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 0.19, NNZs: 538, Bias: 0.003218, T: 53320, Avg. loss: 0.008455\n",
      "Total training time: 3.26 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 0.19, NNZs: 489, Bias: 0.003224, T: 55986, Avg. loss: 0.008377\n",
      "Total training time: 3.41 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.20, NNZs: 483, Bias: 0.003338, T: 58652, Avg. loss: 0.008337\n",
      "Total training time: 3.56 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 0.21, NNZs: 405, Bias: 0.003166, T: 61318, Avg. loss: 0.008290\n",
      "Total training time: 3.71 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 0.21, NNZs: 361, Bias: 0.003088, T: 63984, Avg. loss: 0.008228\n",
      "Total training time: 3.87 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 0.22, NNZs: 350, Bias: 0.003168, T: 66650, Avg. loss: 0.008196\n",
      "Total training time: 4.03 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 0.22, NNZs: 336, Bias: 0.003203, T: 69316, Avg. loss: 0.008149\n",
      "Total training time: 4.19 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 0.22, NNZs: 281, Bias: 0.002903, T: 71982, Avg. loss: 0.008119\n",
      "Total training time: 4.35 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 0.23, NNZs: 283, Bias: 0.003041, T: 74648, Avg. loss: 0.008084\n",
      "Total training time: 4.51 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 0.23, NNZs: 254, Bias: 0.002903, T: 77314, Avg. loss: 0.008035\n",
      "Total training time: 4.67 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 0.24, NNZs: 239, Bias: 0.002712, T: 79980, Avg. loss: 0.007988\n",
      "Total training time: 4.83 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 0.24, NNZs: 218, Bias: 0.002516, T: 82646, Avg. loss: 0.007959\n",
      "Total training time: 4.99 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 0.25, NNZs: 199, Bias: 0.002223, T: 85312, Avg. loss: 0.007900\n",
      "Total training time: 5.15 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.25, NNZs: 198, Bias: 0.002236, T: 87978, Avg. loss: 0.007883\n",
      "Total training time: 5.31 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.26, NNZs: 192, Bias: 0.002103, T: 90644, Avg. loss: 0.007848\n",
      "Total training time: 5.47 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 0.26, NNZs: 185, Bias: 0.002033, T: 93310, Avg. loss: 0.007806\n",
      "Total training time: 5.62 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 0.26, NNZs: 162, Bias: 0.001566, T: 95976, Avg. loss: 0.007765\n",
      "Total training time: 5.78 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 0.27, NNZs: 158, Bias: 0.001414, T: 98642, Avg. loss: 0.007737\n",
      "Total training time: 5.93 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 0.27, NNZs: 154, Bias: 0.001305, T: 101308, Avg. loss: 0.007702\n",
      "Total training time: 6.08 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 0.28, NNZs: 147, Bias: 0.000927, T: 103974, Avg. loss: 0.007663\n",
      "Total training time: 6.24 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 0.28, NNZs: 146, Bias: 0.000933, T: 106640, Avg. loss: 0.007630\n",
      "Total training time: 6.39 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 0.28, NNZs: 142, Bias: 0.000474, T: 109306, Avg. loss: 0.007595\n",
      "Total training time: 6.55 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 0.29, NNZs: 138, Bias: 0.000010, T: 111972, Avg. loss: 0.007549\n",
      "Total training time: 6.70 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 0.29, NNZs: 139, Bias: 0.000045, T: 114638, Avg. loss: 0.007523\n",
      "Total training time: 6.86 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 0.29, NNZs: 139, Bias: -0.000151, T: 117304, Avg. loss: 0.007488\n",
      "Total training time: 7.01 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 0.30, NNZs: 144, Bias: -0.000592, T: 119970, Avg. loss: 0.007450\n",
      "Total training time: 7.17 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 0.30, NNZs: 147, Bias: -0.000913, T: 122636, Avg. loss: 0.007412\n",
      "Total training time: 7.32 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 0.31, NNZs: 149, Bias: -0.001136, T: 125302, Avg. loss: 0.007372\n",
      "Total training time: 7.48 seconds.\n",
      "-- Epoch 48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 0.31, NNZs: 149, Bias: -0.001211, T: 127968, Avg. loss: 0.007330\n",
      "Total training time: 7.64 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 0.31, NNZs: 152, Bias: -0.001669, T: 130634, Avg. loss: 0.007293\n",
      "Total training time: 7.79 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 0.32, NNZs: 153, Bias: -0.001797, T: 133300, Avg. loss: 0.007257\n",
      "Total training time: 7.95 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 0.32, NNZs: 157, Bias: -0.002016, T: 135966, Avg. loss: 0.007216\n",
      "Total training time: 8.10 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 0.32, NNZs: 162, Bias: -0.002408, T: 138632, Avg. loss: 0.007180\n",
      "Total training time: 8.26 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 0.33, NNZs: 161, Bias: -0.002502, T: 141298, Avg. loss: 0.007133\n",
      "Total training time: 8.41 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 0.33, NNZs: 167, Bias: -0.002897, T: 143964, Avg. loss: 0.007093\n",
      "Total training time: 8.56 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 0.33, NNZs: 170, Bias: -0.003078, T: 146630, Avg. loss: 0.007066\n",
      "Total training time: 8.72 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 0.34, NNZs: 173, Bias: -0.003376, T: 149296, Avg. loss: 0.007023\n",
      "Total training time: 8.87 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 0.34, NNZs: 170, Bias: -0.003662, T: 151962, Avg. loss: 0.006981\n",
      "Total training time: 9.03 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 0.34, NNZs: 171, Bias: -0.003783, T: 154628, Avg. loss: 0.006943\n",
      "Total training time: 9.19 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 0.35, NNZs: 170, Bias: -0.003849, T: 157294, Avg. loss: 0.006905\n",
      "Total training time: 9.34 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 0.35, NNZs: 180, Bias: -0.004270, T: 159960, Avg. loss: 0.006874\n",
      "Total training time: 9.50 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 0.35, NNZs: 186, Bias: -0.004597, T: 162626, Avg. loss: 0.006832\n",
      "Total training time: 9.65 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 0.36, NNZs: 187, Bias: -0.004752, T: 165292, Avg. loss: 0.006796\n",
      "Total training time: 9.80 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 0.36, NNZs: 184, Bias: -0.004809, T: 167958, Avg. loss: 0.006753\n",
      "Total training time: 9.96 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 0.36, NNZs: 195, Bias: -0.005351, T: 170624, Avg. loss: 0.006716\n",
      "Total training time: 10.12 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 0.37, NNZs: 195, Bias: -0.005430, T: 173290, Avg. loss: 0.006680\n",
      "Total training time: 10.28 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 0.37, NNZs: 201, Bias: -0.005801, T: 175956, Avg. loss: 0.006643\n",
      "Total training time: 10.43 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 0.37, NNZs: 201, Bias: -0.005949, T: 178622, Avg. loss: 0.006608\n",
      "Total training time: 10.59 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 0.38, NNZs: 202, Bias: -0.006068, T: 181288, Avg. loss: 0.006569\n",
      "Total training time: 10.75 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 0.38, NNZs: 202, Bias: -0.006190, T: 183954, Avg. loss: 0.006537\n",
      "Total training time: 10.90 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 0.38, NNZs: 207, Bias: -0.006559, T: 186620, Avg. loss: 0.006502\n",
      "Total training time: 11.05 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 0.39, NNZs: 213, Bias: -0.006944, T: 189286, Avg. loss: 0.006459\n",
      "Total training time: 11.21 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 0.39, NNZs: 210, Bias: -0.006994, T: 191952, Avg. loss: 0.006432\n",
      "Total training time: 11.36 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 0.39, NNZs: 210, Bias: -0.007125, T: 194618, Avg. loss: 0.006384\n",
      "Total training time: 11.52 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 0.40, NNZs: 216, Bias: -0.007517, T: 197284, Avg. loss: 0.006364\n",
      "Total training time: 11.68 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 0.40, NNZs: 216, Bias: -0.007750, T: 199950, Avg. loss: 0.006324\n",
      "Total training time: 11.83 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 0.40, NNZs: 223, Bias: -0.008014, T: 202616, Avg. loss: 0.006290\n",
      "Total training time: 11.99 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 0.41, NNZs: 216, Bias: -0.008010, T: 205282, Avg. loss: 0.006249\n",
      "Total training time: 12.14 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 0.41, NNZs: 222, Bias: -0.008322, T: 207948, Avg. loss: 0.006228\n",
      "Total training time: 12.29 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 0.41, NNZs: 227, Bias: -0.008655, T: 210614, Avg. loss: 0.006189\n",
      "Total training time: 12.45 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 0.41, NNZs: 227, Bias: -0.008771, T: 213280, Avg. loss: 0.006145\n",
      "Total training time: 12.61 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 0.42, NNZs: 228, Bias: -0.008962, T: 215946, Avg. loss: 0.006131\n",
      "Total training time: 12.77 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 0.42, NNZs: 236, Bias: -0.009438, T: 218612, Avg. loss: 0.006097\n",
      "Total training time: 12.93 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 0.42, NNZs: 235, Bias: -0.009538, T: 221278, Avg. loss: 0.006068\n",
      "Total training time: 13.09 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 0.43, NNZs: 236, Bias: -0.009809, T: 223944, Avg. loss: 0.006036\n",
      "Total training time: 13.24 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 0.43, NNZs: 244, Bias: -0.010105, T: 226610, Avg. loss: 0.005998\n",
      "Total training time: 13.40 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 0.43, NNZs: 240, Bias: -0.010176, T: 229276, Avg. loss: 0.005969\n",
      "Total training time: 13.55 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 0.43, NNZs: 244, Bias: -0.010416, T: 231942, Avg. loss: 0.005936\n",
      "Total training time: 13.70 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 0.44, NNZs: 241, Bias: -0.010511, T: 234608, Avg. loss: 0.005911\n",
      "Total training time: 13.86 seconds.\n",
      "-- Epoch 89\n",
      "Norm: 0.44, NNZs: 246, Bias: -0.010793, T: 237274, Avg. loss: 0.005880\n",
      "Total training time: 14.02 seconds.\n",
      "-- Epoch 90\n",
      "Norm: 0.44, NNZs: 250, Bias: -0.011080, T: 239940, Avg. loss: 0.005855\n",
      "Total training time: 14.18 seconds.\n",
      "-- Epoch 91\n",
      "Norm: 0.45, NNZs: 251, Bias: -0.011268, T: 242606, Avg. loss: 0.005821\n",
      "Total training time: 14.34 seconds.\n",
      "-- Epoch 92\n",
      "Norm: 0.45, NNZs: 251, Bias: -0.011455, T: 245272, Avg. loss: 0.005793\n",
      "Total training time: 14.49 seconds.\n",
      "-- Epoch 93\n",
      "Norm: 0.45, NNZs: 253, Bias: -0.011698, T: 247938, Avg. loss: 0.005766\n",
      "Total training time: 14.65 seconds.\n",
      "-- Epoch 94\n",
      "Norm: 0.46, NNZs: 255, Bias: -0.012010, T: 250604, Avg. loss: 0.005737\n",
      "Total training time: 14.81 seconds.\n",
      "-- Epoch 95\n",
      "Norm: 0.46, NNZs: 253, Bias: -0.012062, T: 253270, Avg. loss: 0.005706\n",
      "Total training time: 14.96 seconds.\n",
      "-- Epoch 96\n",
      "Norm: 0.46, NNZs: 255, Bias: -0.012498, T: 255936, Avg. loss: 0.005682\n",
      "Total training time: 15.12 seconds.\n",
      "-- Epoch 97\n",
      "Norm: 0.46, NNZs: 254, Bias: -0.012608, T: 258602, Avg. loss: 0.005645\n",
      "Total training time: 15.27 seconds.\n",
      "-- Epoch 98\n",
      "Norm: 0.47, NNZs: 254, Bias: -0.012771, T: 261268, Avg. loss: 0.005618\n",
      "Total training time: 15.42 seconds.\n",
      "-- Epoch 99\n",
      "Norm: 0.47, NNZs: 252, Bias: -0.012901, T: 263934, Avg. loss: 0.005602\n",
      "Total training time: 15.58 seconds.\n",
      "-- Epoch 100\n",
      "Norm: 0.47, NNZs: 256, Bias: -0.013260, T: 266600, Avg. loss: 0.005573\n",
      "Total training time: 15.74 seconds.\n",
      "-- Epoch 101\n",
      "Norm: 0.47, NNZs: 265, Bias: -0.013605, T: 269266, Avg. loss: 0.005546\n",
      "Total training time: 15.90 seconds.\n",
      "-- Epoch 102\n",
      "Norm: 0.48, NNZs: 258, Bias: -0.013671, T: 271932, Avg. loss: 0.005512\n",
      "Total training time: 16.05 seconds.\n",
      "-- Epoch 103\n",
      "Norm: 0.48, NNZs: 267, Bias: -0.014009, T: 274598, Avg. loss: 0.005505\n",
      "Total training time: 16.21 seconds.\n",
      "-- Epoch 104\n",
      "Norm: 0.48, NNZs: 267, Bias: -0.014157, T: 277264, Avg. loss: 0.005473\n",
      "Total training time: 16.37 seconds.\n",
      "-- Epoch 105\n",
      "Norm: 0.49, NNZs: 267, Bias: -0.014391, T: 279930, Avg. loss: 0.005446\n",
      "Total training time: 16.52 seconds.\n",
      "-- Epoch 106\n",
      "Norm: 0.49, NNZs: 269, Bias: -0.014631, T: 282596, Avg. loss: 0.005419\n",
      "Total training time: 16.67 seconds.\n",
      "-- Epoch 107\n",
      "Norm: 0.49, NNZs: 270, Bias: -0.014891, T: 285262, Avg. loss: 0.005401\n",
      "Total training time: 16.83 seconds.\n",
      "-- Epoch 108\n",
      "Norm: 0.49, NNZs: 275, Bias: -0.015173, T: 287928, Avg. loss: 0.005373\n",
      "Total training time: 16.98 seconds.\n",
      "-- Epoch 109\n",
      "Norm: 0.50, NNZs: 274, Bias: -0.015349, T: 290594, Avg. loss: 0.005341\n",
      "Total training time: 17.13 seconds.\n",
      "-- Epoch 110\n",
      "Norm: 0.50, NNZs: 278, Bias: -0.015684, T: 293260, Avg. loss: 0.005326\n",
      "Total training time: 17.29 seconds.\n",
      "-- Epoch 111\n",
      "Norm: 0.50, NNZs: 274, Bias: -0.015744, T: 295926, Avg. loss: 0.005302\n",
      "Total training time: 17.44 seconds.\n",
      "-- Epoch 112\n",
      "Norm: 0.50, NNZs: 281, Bias: -0.016232, T: 298592, Avg. loss: 0.005267\n",
      "Total training time: 17.60 seconds.\n",
      "-- Epoch 113\n",
      "Norm: 0.51, NNZs: 280, Bias: -0.016386, T: 301258, Avg. loss: 0.005257\n",
      "Total training time: 17.75 seconds.\n",
      "-- Epoch 114\n",
      "Norm: 0.51, NNZs: 284, Bias: -0.016674, T: 303924, Avg. loss: 0.005225\n",
      "Total training time: 17.91 seconds.\n",
      "-- Epoch 115\n",
      "Norm: 0.51, NNZs: 283, Bias: -0.016802, T: 306590, Avg. loss: 0.005209\n",
      "Total training time: 18.06 seconds.\n",
      "-- Epoch 116\n",
      "Norm: 0.51, NNZs: 278, Bias: -0.016931, T: 309256, Avg. loss: 0.005177\n",
      "Total training time: 18.21 seconds.\n",
      "-- Epoch 117\n",
      "Norm: 0.52, NNZs: 278, Bias: -0.017084, T: 311922, Avg. loss: 0.005153\n",
      "Total training time: 18.36 seconds.\n",
      "-- Epoch 118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 0.52, NNZs: 281, Bias: -0.017346, T: 314588, Avg. loss: 0.005146\n",
      "Total training time: 18.52 seconds.\n",
      "-- Epoch 119\n",
      "Norm: 0.52, NNZs: 283, Bias: -0.017604, T: 317254, Avg. loss: 0.005126\n",
      "Total training time: 18.68 seconds.\n",
      "Convergence after 119 epochs took 18.68 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.03, NNZs: 8032, Bias: 0.000662, T: 2667, Avg. loss: 0.010743\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.04, NNZs: 5035, Bias: 0.000962, T: 5334, Avg. loss: 0.010116\n",
      "Total training time: 0.33 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.06, NNZs: 3718, Bias: 0.001242, T: 8001, Avg. loss: 0.009650\n",
      "Total training time: 0.51 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.07, NNZs: 2959, Bias: 0.001486, T: 10668, Avg. loss: 0.009432\n",
      "Total training time: 0.68 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.08, NNZs: 2510, Bias: 0.001732, T: 13335, Avg. loss: 0.009216\n",
      "Total training time: 0.84 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.09, NNZs: 2004, Bias: 0.001887, T: 16002, Avg. loss: 0.009063\n",
      "Total training time: 1.01 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.10, NNZs: 2036, Bias: 0.002218, T: 18669, Avg. loss: 0.008938\n",
      "Total training time: 1.16 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.11, NNZs: 1593, Bias: 0.002275, T: 21336, Avg. loss: 0.008782\n",
      "Total training time: 1.32 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.11, NNZs: 1442, Bias: 0.002470, T: 24003, Avg. loss: 0.008710\n",
      "Total training time: 1.47 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.12, NNZs: 1275, Bias: 0.002596, T: 26670, Avg. loss: 0.008602\n",
      "Total training time: 1.62 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.13, NNZs: 1164, Bias: 0.002748, T: 29337, Avg. loss: 0.008603\n",
      "Total training time: 1.77 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.14, NNZs: 1182, Bias: 0.003029, T: 32004, Avg. loss: 0.008507\n",
      "Total training time: 1.93 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.14, NNZs: 964, Bias: 0.003017, T: 34671, Avg. loss: 0.008477\n",
      "Total training time: 2.08 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 0.15, NNZs: 841, Bias: 0.003063, T: 37338, Avg. loss: 0.008375\n",
      "Total training time: 2.24 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 0.16, NNZs: 840, Bias: 0.003279, T: 40005, Avg. loss: 0.008300\n",
      "Total training time: 2.39 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 0.16, NNZs: 724, Bias: 0.003239, T: 42672, Avg. loss: 0.008254\n",
      "Total training time: 2.54 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 0.17, NNZs: 733, Bias: 0.003473, T: 45339, Avg. loss: 0.008208\n",
      "Total training time: 2.70 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 0.17, NNZs: 617, Bias: 0.003357, T: 48006, Avg. loss: 0.008161\n",
      "Total training time: 2.85 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.18, NNZs: 581, Bias: 0.003431, T: 50673, Avg. loss: 0.008111\n",
      "Total training time: 3.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 0.18, NNZs: 529, Bias: 0.003471, T: 53340, Avg. loss: 0.008057\n",
      "Total training time: 3.16 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 0.19, NNZs: 527, Bias: 0.003629, T: 56007, Avg. loss: 0.008016\n",
      "Total training time: 3.31 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.19, NNZs: 473, Bias: 0.003593, T: 58674, Avg. loss: 0.007969\n",
      "Total training time: 3.46 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 0.20, NNZs: 448, Bias: 0.003650, T: 61341, Avg. loss: 0.007904\n",
      "Total training time: 3.62 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 0.20, NNZs: 410, Bias: 0.003577, T: 64008, Avg. loss: 0.007886\n",
      "Total training time: 3.78 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 0.21, NNZs: 351, Bias: 0.003415, T: 66675, Avg. loss: 0.007798\n",
      "Total training time: 3.94 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 0.21, NNZs: 338, Bias: 0.003506, T: 69342, Avg. loss: 0.007801\n",
      "Total training time: 4.10 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 0.22, NNZs: 313, Bias: 0.003455, T: 72009, Avg. loss: 0.007765\n",
      "Total training time: 4.25 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 0.22, NNZs: 296, Bias: 0.003426, T: 74676, Avg. loss: 0.007729\n",
      "Total training time: 4.41 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 0.23, NNZs: 274, Bias: 0.003273, T: 77343, Avg. loss: 0.007686\n",
      "Total training time: 4.57 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 0.23, NNZs: 284, Bias: 0.003518, T: 80010, Avg. loss: 0.007654\n",
      "Total training time: 4.73 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 0.24, NNZs: 248, Bias: 0.003221, T: 82677, Avg. loss: 0.007617\n",
      "Total training time: 4.89 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 0.24, NNZs: 238, Bias: 0.003215, T: 85344, Avg. loss: 0.007593\n",
      "Total training time: 5.05 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.25, NNZs: 230, Bias: 0.003185, T: 88011, Avg. loss: 0.007548\n",
      "Total training time: 5.22 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.25, NNZs: 223, Bias: 0.003168, T: 90678, Avg. loss: 0.007510\n",
      "Total training time: 5.38 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 0.25, NNZs: 210, Bias: 0.002895, T: 93345, Avg. loss: 0.007486\n",
      "Total training time: 5.54 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 0.26, NNZs: 182, Bias: 0.002493, T: 96012, Avg. loss: 0.007443\n",
      "Total training time: 5.70 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 0.26, NNZs: 172, Bias: 0.002433, T: 98679, Avg. loss: 0.007413\n",
      "Total training time: 5.86 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 0.26, NNZs: 159, Bias: 0.002216, T: 101346, Avg. loss: 0.007394\n",
      "Total training time: 6.01 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 0.27, NNZs: 159, Bias: 0.002216, T: 104013, Avg. loss: 0.007363\n",
      "Total training time: 6.17 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 0.27, NNZs: 150, Bias: 0.001802, T: 106680, Avg. loss: 0.007330\n",
      "Total training time: 6.34 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 0.28, NNZs: 150, Bias: 0.001835, T: 109347, Avg. loss: 0.007300\n",
      "Total training time: 6.50 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 0.28, NNZs: 146, Bias: 0.001499, T: 112014, Avg. loss: 0.007273\n",
      "Total training time: 6.66 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 0.28, NNZs: 136, Bias: 0.001042, T: 114681, Avg. loss: 0.007238\n",
      "Total training time: 6.81 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 0.29, NNZs: 137, Bias: 0.001259, T: 117348, Avg. loss: 0.007200\n",
      "Total training time: 6.97 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 0.29, NNZs: 129, Bias: 0.000745, T: 120015, Avg. loss: 0.007184\n",
      "Total training time: 7.12 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 0.29, NNZs: 128, Bias: 0.000406, T: 122682, Avg. loss: 0.007156\n",
      "Total training time: 7.28 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 0.30, NNZs: 130, Bias: 0.000488, T: 125349, Avg. loss: 0.007119\n",
      "Total training time: 7.44 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 0.30, NNZs: 126, Bias: -0.000114, T: 128016, Avg. loss: 0.007097\n",
      "Total training time: 7.60 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 0.30, NNZs: 126, Bias: -0.000251, T: 130683, Avg. loss: 0.007063\n",
      "Total training time: 7.75 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 0.31, NNZs: 127, Bias: -0.000481, T: 133350, Avg. loss: 0.007033\n",
      "Total training time: 7.90 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 0.31, NNZs: 131, Bias: -0.000884, T: 136017, Avg. loss: 0.007004\n",
      "Total training time: 8.06 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 0.31, NNZs: 129, Bias: -0.001135, T: 138684, Avg. loss: 0.006977\n",
      "Total training time: 8.21 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 0.32, NNZs: 134, Bias: -0.001385, T: 141351, Avg. loss: 0.006942\n",
      "Total training time: 8.37 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 0.32, NNZs: 134, Bias: -0.001506, T: 144018, Avg. loss: 0.006902\n",
      "Total training time: 8.52 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 0.32, NNZs: 136, Bias: -0.001759, T: 146685, Avg. loss: 0.006876\n",
      "Total training time: 8.67 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 0.33, NNZs: 140, Bias: -0.002092, T: 149352, Avg. loss: 0.006847\n",
      "Total training time: 8.82 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 0.33, NNZs: 140, Bias: -0.002310, T: 152019, Avg. loss: 0.006817\n",
      "Total training time: 8.97 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 0.33, NNZs: 142, Bias: -0.002551, T: 154686, Avg. loss: 0.006781\n",
      "Total training time: 9.13 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 0.34, NNZs: 142, Bias: -0.002573, T: 157353, Avg. loss: 0.006737\n",
      "Total training time: 9.28 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 0.34, NNZs: 147, Bias: -0.003114, T: 160020, Avg. loss: 0.006720\n",
      "Total training time: 9.44 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 0.34, NNZs: 151, Bias: -0.003405, T: 162687, Avg. loss: 0.006683\n",
      "Total training time: 9.60 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 0.35, NNZs: 147, Bias: -0.003404, T: 165354, Avg. loss: 0.006648\n",
      "Total training time: 9.76 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 0.35, NNZs: 153, Bias: -0.003742, T: 168021, Avg. loss: 0.006621\n",
      "Total training time: 9.92 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 0.35, NNZs: 154, Bias: -0.003939, T: 170688, Avg. loss: 0.006585\n",
      "Total training time: 10.08 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 0.36, NNZs: 159, Bias: -0.004237, T: 173355, Avg. loss: 0.006559\n",
      "Total training time: 10.23 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 0.36, NNZs: 161, Bias: -0.004402, T: 176022, Avg. loss: 0.006524\n",
      "Total training time: 10.39 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 0.36, NNZs: 165, Bias: -0.004799, T: 178689, Avg. loss: 0.006496\n",
      "Total training time: 10.54 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 0.36, NNZs: 166, Bias: -0.004955, T: 181356, Avg. loss: 0.006461\n",
      "Total training time: 10.71 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 0.37, NNZs: 172, Bias: -0.005334, T: 184023, Avg. loss: 0.006426\n",
      "Total training time: 10.86 seconds.\n",
      "-- Epoch 70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 0.37, NNZs: 168, Bias: -0.005329, T: 186690, Avg. loss: 0.006397\n",
      "Total training time: 11.02 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 0.37, NNZs: 171, Bias: -0.005573, T: 189357, Avg. loss: 0.006360\n",
      "Total training time: 11.17 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 0.38, NNZs: 174, Bias: -0.005853, T: 192024, Avg. loss: 0.006327\n",
      "Total training time: 11.35 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 0.38, NNZs: 175, Bias: -0.006008, T: 194691, Avg. loss: 0.006304\n",
      "Total training time: 11.51 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 0.38, NNZs: 181, Bias: -0.006391, T: 197358, Avg. loss: 0.006277\n",
      "Total training time: 11.68 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 0.39, NNZs: 182, Bias: -0.006618, T: 200025, Avg. loss: 0.006245\n",
      "Total training time: 11.84 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 0.39, NNZs: 183, Bias: -0.006769, T: 202692, Avg. loss: 0.006217\n",
      "Total training time: 12.01 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 0.39, NNZs: 182, Bias: -0.006960, T: 205359, Avg. loss: 0.006184\n",
      "Total training time: 12.16 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 0.39, NNZs: 195, Bias: -0.007406, T: 208026, Avg. loss: 0.006161\n",
      "Total training time: 12.31 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 0.40, NNZs: 183, Bias: -0.007312, T: 210693, Avg. loss: 0.006132\n",
      "Total training time: 12.47 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 0.40, NNZs: 186, Bias: -0.007519, T: 213360, Avg. loss: 0.006093\n",
      "Total training time: 12.64 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 0.40, NNZs: 200, Bias: -0.007932, T: 216027, Avg. loss: 0.006064\n",
      "Total training time: 12.79 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 0.41, NNZs: 202, Bias: -0.008178, T: 218694, Avg. loss: 0.006035\n",
      "Total training time: 12.94 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 0.41, NNZs: 203, Bias: -0.008410, T: 221361, Avg. loss: 0.006013\n",
      "Total training time: 13.09 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 0.41, NNZs: 204, Bias: -0.008624, T: 224028, Avg. loss: 0.005988\n",
      "Total training time: 13.26 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 0.41, NNZs: 201, Bias: -0.008716, T: 226695, Avg. loss: 0.005960\n",
      "Total training time: 13.42 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 0.42, NNZs: 213, Bias: -0.009073, T: 229362, Avg. loss: 0.005925\n",
      "Total training time: 13.58 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 0.42, NNZs: 214, Bias: -0.009233, T: 232029, Avg. loss: 0.005908\n",
      "Total training time: 13.75 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 0.42, NNZs: 219, Bias: -0.009487, T: 234696, Avg. loss: 0.005877\n",
      "Total training time: 13.90 seconds.\n",
      "-- Epoch 89\n",
      "Norm: 0.43, NNZs: 224, Bias: -0.009858, T: 237363, Avg. loss: 0.005841\n",
      "Total training time: 14.06 seconds.\n",
      "-- Epoch 90\n",
      "Norm: 0.43, NNZs: 214, Bias: -0.009676, T: 240030, Avg. loss: 0.005819\n",
      "Total training time: 14.21 seconds.\n",
      "-- Epoch 91\n",
      "Norm: 0.43, NNZs: 219, Bias: -0.010009, T: 242697, Avg. loss: 0.005799\n",
      "Total training time: 14.38 seconds.\n",
      "-- Epoch 92\n",
      "Norm: 0.43, NNZs: 226, Bias: -0.010331, T: 245364, Avg. loss: 0.005768\n",
      "Total training time: 14.54 seconds.\n",
      "-- Epoch 93\n",
      "Norm: 0.44, NNZs: 221, Bias: -0.010368, T: 248031, Avg. loss: 0.005746\n",
      "Total training time: 14.70 seconds.\n",
      "-- Epoch 94\n",
      "Norm: 0.44, NNZs: 230, Bias: -0.010731, T: 250698, Avg. loss: 0.005722\n",
      "Total training time: 14.86 seconds.\n",
      "-- Epoch 95\n",
      "Norm: 0.44, NNZs: 233, Bias: -0.011059, T: 253365, Avg. loss: 0.005690\n",
      "Total training time: 15.02 seconds.\n",
      "-- Epoch 96\n",
      "Norm: 0.44, NNZs: 232, Bias: -0.011172, T: 256032, Avg. loss: 0.005675\n",
      "Total training time: 15.18 seconds.\n",
      "-- Epoch 97\n",
      "Norm: 0.45, NNZs: 235, Bias: -0.011420, T: 258699, Avg. loss: 0.005640\n",
      "Total training time: 15.33 seconds.\n",
      "-- Epoch 98\n",
      "Norm: 0.45, NNZs: 239, Bias: -0.011726, T: 261366, Avg. loss: 0.005612\n",
      "Total training time: 15.49 seconds.\n",
      "-- Epoch 99\n",
      "Norm: 0.45, NNZs: 232, Bias: -0.011719, T: 264033, Avg. loss: 0.005588\n",
      "Total training time: 15.65 seconds.\n",
      "-- Epoch 100\n",
      "Norm: 0.46, NNZs: 238, Bias: -0.012011, T: 266700, Avg. loss: 0.005566\n",
      "Total training time: 15.82 seconds.\n",
      "-- Epoch 101\n",
      "Norm: 0.46, NNZs: 242, Bias: -0.012375, T: 269367, Avg. loss: 0.005541\n",
      "Total training time: 15.98 seconds.\n",
      "-- Epoch 102\n",
      "Norm: 0.46, NNZs: 239, Bias: -0.012375, T: 272034, Avg. loss: 0.005526\n",
      "Total training time: 16.13 seconds.\n",
      "-- Epoch 103\n",
      "Norm: 0.46, NNZs: 243, Bias: -0.012759, T: 274701, Avg. loss: 0.005487\n",
      "Total training time: 16.28 seconds.\n",
      "-- Epoch 104\n",
      "Norm: 0.47, NNZs: 243, Bias: -0.012925, T: 277368, Avg. loss: 0.005475\n",
      "Total training time: 16.44 seconds.\n",
      "-- Epoch 105\n",
      "Norm: 0.47, NNZs: 245, Bias: -0.013155, T: 280035, Avg. loss: 0.005441\n",
      "Total training time: 16.60 seconds.\n",
      "-- Epoch 106\n",
      "Norm: 0.47, NNZs: 248, Bias: -0.013413, T: 282702, Avg. loss: 0.005418\n",
      "Total training time: 16.76 seconds.\n",
      "-- Epoch 107\n",
      "Norm: 0.47, NNZs: 247, Bias: -0.013546, T: 285369, Avg. loss: 0.005406\n",
      "Total training time: 16.91 seconds.\n",
      "-- Epoch 108\n",
      "Norm: 0.48, NNZs: 250, Bias: -0.013782, T: 288036, Avg. loss: 0.005383\n",
      "Total training time: 17.07 seconds.\n",
      "-- Epoch 109\n",
      "Norm: 0.48, NNZs: 250, Bias: -0.013985, T: 290703, Avg. loss: 0.005353\n",
      "Total training time: 17.22 seconds.\n",
      "-- Epoch 110\n",
      "Norm: 0.48, NNZs: 251, Bias: -0.014237, T: 293370, Avg. loss: 0.005337\n",
      "Total training time: 17.38 seconds.\n",
      "-- Epoch 111\n",
      "Norm: 0.48, NNZs: 250, Bias: -0.014336, T: 296037, Avg. loss: 0.005310\n",
      "Total training time: 17.54 seconds.\n",
      "-- Epoch 112\n",
      "Norm: 0.49, NNZs: 255, Bias: -0.014699, T: 298704, Avg. loss: 0.005297\n",
      "Total training time: 17.70 seconds.\n",
      "-- Epoch 113\n",
      "Norm: 0.49, NNZs: 258, Bias: -0.014915, T: 301371, Avg. loss: 0.005270\n",
      "Total training time: 17.86 seconds.\n",
      "-- Epoch 114\n",
      "Norm: 0.49, NNZs: 253, Bias: -0.015016, T: 304038, Avg. loss: 0.005249\n",
      "Total training time: 18.02 seconds.\n",
      "Convergence after 114 epochs took 18.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.03, NNZs: 7248, Bias: 0.000609, T: 2667, Avg. loss: 0.011542\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.04, NNZs: 4524, Bias: 0.000908, T: 5334, Avg. loss: 0.010542\n",
      "Total training time: 0.35 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.06, NNZs: 3655, Bias: 0.001231, T: 8001, Avg. loss: 0.010116\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.07, NNZs: 2714, Bias: 0.001436, T: 10668, Avg. loss: 0.009868\n",
      "Total training time: 0.70 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.08, NNZs: 2374, Bias: 0.001693, T: 13335, Avg. loss: 0.009679\n",
      "Total training time: 0.87 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.09, NNZs: 1905, Bias: 0.001840, T: 16002, Avg. loss: 0.009495\n",
      "Total training time: 1.05 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.10, NNZs: 1701, Bias: 0.002039, T: 18669, Avg. loss: 0.009380\n",
      "Total training time: 1.22 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.11, NNZs: 1552, Bias: 0.002226, T: 21336, Avg. loss: 0.009295\n",
      "Total training time: 1.39 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.12, NNZs: 1300, Bias: 0.002329, T: 24003, Avg. loss: 0.009141\n",
      "Total training time: 1.55 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.13, NNZs: 1206, Bias: 0.002511, T: 26670, Avg. loss: 0.009054\n",
      "Total training time: 1.70 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.13, NNZs: 1052, Bias: 0.002562, T: 29337, Avg. loss: 0.008995\n",
      "Total training time: 1.86 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.14, NNZs: 954, Bias: 0.002647, T: 32004, Avg. loss: 0.008898\n",
      "Total training time: 2.02 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.15, NNZs: 962, Bias: 0.002885, T: 34671, Avg. loss: 0.008846\n",
      "Total training time: 2.19 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 0.15, NNZs: 837, Bias: 0.002882, T: 37338, Avg. loss: 0.008753\n",
      "Total training time: 2.35 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 0.16, NNZs: 745, Bias: 0.002915, T: 40005, Avg. loss: 0.008714\n",
      "Total training time: 2.52 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 0.17, NNZs: 736, Bias: 0.003095, T: 42672, Avg. loss: 0.008667\n",
      "Total training time: 2.68 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 0.17, NNZs: 635, Bias: 0.003034, T: 45339, Avg. loss: 0.008572\n",
      "Total training time: 2.83 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 0.18, NNZs: 605, Bias: 0.003144, T: 48006, Avg. loss: 0.008561\n",
      "Total training time: 2.99 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.18, NNZs: 579, Bias: 0.003247, T: 50673, Avg. loss: 0.008484\n",
      "Total training time: 3.14 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 0.19, NNZs: 508, Bias: 0.003170, T: 53340, Avg. loss: 0.008430\n",
      "Total training time: 3.30 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 0.19, NNZs: 470, Bias: 0.003196, T: 56007, Avg. loss: 0.008381\n",
      "Total training time: 3.46 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.20, NNZs: 465, Bias: 0.003300, T: 58674, Avg. loss: 0.008321\n",
      "Total training time: 3.61 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 0.20, NNZs: 412, Bias: 0.003109, T: 61341, Avg. loss: 0.008283\n",
      "Total training time: 3.76 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 0.21, NNZs: 395, Bias: 0.003125, T: 64008, Avg. loss: 0.008241\n",
      "Total training time: 3.91 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 0.21, NNZs: 356, Bias: 0.002997, T: 66675, Avg. loss: 0.008202\n",
      "Total training time: 4.06 seconds.\n",
      "-- Epoch 26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 0.22, NNZs: 332, Bias: 0.002952, T: 69342, Avg. loss: 0.008146\n",
      "Total training time: 4.22 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 0.22, NNZs: 315, Bias: 0.002979, T: 72009, Avg. loss: 0.008094\n",
      "Total training time: 4.36 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 0.23, NNZs: 284, Bias: 0.002819, T: 74676, Avg. loss: 0.008041\n",
      "Total training time: 4.52 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 0.23, NNZs: 258, Bias: 0.002663, T: 77343, Avg. loss: 0.008015\n",
      "Total training time: 4.67 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 0.24, NNZs: 257, Bias: 0.002725, T: 80010, Avg. loss: 0.007981\n",
      "Total training time: 4.82 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 0.24, NNZs: 238, Bias: 0.002573, T: 82677, Avg. loss: 0.007933\n",
      "Total training time: 4.97 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 0.25, NNZs: 224, Bias: 0.002481, T: 85344, Avg. loss: 0.007894\n",
      "Total training time: 5.13 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.25, NNZs: 207, Bias: 0.002292, T: 88011, Avg. loss: 0.007843\n",
      "Total training time: 5.28 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.26, NNZs: 194, Bias: 0.002070, T: 90678, Avg. loss: 0.007819\n",
      "Total training time: 5.43 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 0.26, NNZs: 189, Bias: 0.001916, T: 93345, Avg. loss: 0.007775\n",
      "Total training time: 5.58 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 0.26, NNZs: 176, Bias: 0.001631, T: 96012, Avg. loss: 0.007731\n",
      "Total training time: 5.73 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 0.27, NNZs: 174, Bias: 0.001624, T: 98679, Avg. loss: 0.007702\n",
      "Total training time: 5.88 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 0.27, NNZs: 161, Bias: 0.001320, T: 101346, Avg. loss: 0.007672\n",
      "Total training time: 6.04 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 0.28, NNZs: 162, Bias: 0.001448, T: 104013, Avg. loss: 0.007620\n",
      "Total training time: 6.19 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 0.28, NNZs: 158, Bias: 0.000898, T: 106680, Avg. loss: 0.007594\n",
      "Total training time: 6.34 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 0.28, NNZs: 153, Bias: 0.000711, T: 109347, Avg. loss: 0.007570\n",
      "Total training time: 6.49 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 0.29, NNZs: 139, Bias: 0.000130, T: 112014, Avg. loss: 0.007525\n",
      "Total training time: 6.65 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 0.29, NNZs: 138, Bias: 0.000085, T: 114681, Avg. loss: 0.007497\n",
      "Total training time: 6.80 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 0.29, NNZs: 130, Bias: -0.000177, T: 117348, Avg. loss: 0.007457\n",
      "Total training time: 6.95 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 0.30, NNZs: 128, Bias: -0.000512, T: 120015, Avg. loss: 0.007423\n",
      "Total training time: 7.11 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 0.30, NNZs: 128, Bias: -0.000762, T: 122682, Avg. loss: 0.007389\n",
      "Total training time: 7.27 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 0.31, NNZs: 128, Bias: -0.000942, T: 125349, Avg. loss: 0.007348\n",
      "Total training time: 7.42 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 0.31, NNZs: 127, Bias: -0.001037, T: 128016, Avg. loss: 0.007309\n",
      "Total training time: 7.58 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 0.31, NNZs: 130, Bias: -0.001547, T: 130683, Avg. loss: 0.007288\n",
      "Total training time: 7.73 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 0.32, NNZs: 131, Bias: -0.001716, T: 133350, Avg. loss: 0.007245\n",
      "Total training time: 7.88 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 0.32, NNZs: 135, Bias: -0.002048, T: 136017, Avg. loss: 0.007211\n",
      "Total training time: 8.04 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 0.32, NNZs: 139, Bias: -0.002277, T: 138684, Avg. loss: 0.007170\n",
      "Total training time: 8.20 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 0.33, NNZs: 147, Bias: -0.002881, T: 141351, Avg. loss: 0.007130\n",
      "Total training time: 8.35 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 0.33, NNZs: 152, Bias: -0.003132, T: 144018, Avg. loss: 0.007084\n",
      "Total training time: 8.50 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 0.33, NNZs: 150, Bias: -0.003166, T: 146685, Avg. loss: 0.007063\n",
      "Total training time: 8.64 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 0.34, NNZs: 157, Bias: -0.003535, T: 149352, Avg. loss: 0.007022\n",
      "Total training time: 8.79 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 0.34, NNZs: 157, Bias: -0.003635, T: 152019, Avg. loss: 0.006992\n",
      "Total training time: 8.95 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 0.34, NNZs: 159, Bias: -0.003801, T: 154686, Avg. loss: 0.006951\n",
      "Total training time: 9.10 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 0.35, NNZs: 167, Bias: -0.004226, T: 157353, Avg. loss: 0.006915\n",
      "Total training time: 9.26 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 0.35, NNZs: 172, Bias: -0.004481, T: 160020, Avg. loss: 0.006874\n",
      "Total training time: 9.41 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 0.35, NNZs: 173, Bias: -0.004605, T: 162687, Avg. loss: 0.006838\n",
      "Total training time: 9.57 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 0.36, NNZs: 190, Bias: -0.005232, T: 165354, Avg. loss: 0.006790\n",
      "Total training time: 9.71 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 0.36, NNZs: 188, Bias: -0.005274, T: 168021, Avg. loss: 0.006763\n",
      "Total training time: 9.86 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 0.36, NNZs: 192, Bias: -0.005539, T: 170688, Avg. loss: 0.006726\n",
      "Total training time: 10.01 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 0.37, NNZs: 189, Bias: -0.005548, T: 173355, Avg. loss: 0.006695\n",
      "Total training time: 10.16 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 0.37, NNZs: 199, Bias: -0.005944, T: 176022, Avg. loss: 0.006658\n",
      "Total training time: 10.31 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 0.37, NNZs: 199, Bias: -0.006046, T: 178689, Avg. loss: 0.006623\n",
      "Total training time: 10.47 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 0.38, NNZs: 203, Bias: -0.006529, T: 181356, Avg. loss: 0.006586\n",
      "Total training time: 10.62 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 0.38, NNZs: 202, Bias: -0.006619, T: 184023, Avg. loss: 0.006545\n",
      "Total training time: 10.77 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 0.38, NNZs: 207, Bias: -0.006858, T: 186690, Avg. loss: 0.006520\n",
      "Total training time: 10.93 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 0.39, NNZs: 213, Bias: -0.007061, T: 189357, Avg. loss: 0.006482\n",
      "Total training time: 11.09 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 0.39, NNZs: 215, Bias: -0.007219, T: 192024, Avg. loss: 0.006449\n",
      "Total training time: 11.25 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 0.39, NNZs: 223, Bias: -0.007593, T: 194691, Avg. loss: 0.006409\n",
      "Total training time: 11.41 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 0.39, NNZs: 221, Bias: -0.007677, T: 197358, Avg. loss: 0.006368\n",
      "Total training time: 11.57 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 0.40, NNZs: 222, Bias: -0.007944, T: 200025, Avg. loss: 0.006343\n",
      "Total training time: 11.73 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 0.40, NNZs: 222, Bias: -0.008106, T: 202692, Avg. loss: 0.006307\n",
      "Total training time: 11.89 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 0.40, NNZs: 223, Bias: -0.008280, T: 205359, Avg. loss: 0.006277\n",
      "Total training time: 12.04 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 0.41, NNZs: 230, Bias: -0.008590, T: 208026, Avg. loss: 0.006243\n",
      "Total training time: 12.19 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 0.41, NNZs: 238, Bias: -0.008873, T: 210693, Avg. loss: 0.006219\n",
      "Total training time: 12.35 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 0.41, NNZs: 236, Bias: -0.008962, T: 213360, Avg. loss: 0.006180\n",
      "Total training time: 12.51 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 0.42, NNZs: 245, Bias: -0.009326, T: 216027, Avg. loss: 0.006142\n",
      "Total training time: 12.67 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 0.42, NNZs: 245, Bias: -0.009467, T: 218694, Avg. loss: 0.006115\n",
      "Total training time: 12.82 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 0.42, NNZs: 252, Bias: -0.009760, T: 221361, Avg. loss: 0.006089\n",
      "Total training time: 12.98 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 0.42, NNZs: 253, Bias: -0.009991, T: 224028, Avg. loss: 0.006051\n",
      "Total training time: 13.13 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 0.43, NNZs: 253, Bias: -0.010177, T: 226695, Avg. loss: 0.006026\n",
      "Total training time: 13.29 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 0.43, NNZs: 252, Bias: -0.010385, T: 229362, Avg. loss: 0.005985\n",
      "Total training time: 13.44 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 0.43, NNZs: 262, Bias: -0.010883, T: 232029, Avg. loss: 0.005955\n",
      "Total training time: 13.60 seconds.\n",
      "-- Epoch 88\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "operation = GridSearchCV(estimator=model,n_jobs=1,verbose=True,cv=3,\n",
    "                         param_grid={'alpha':[0.001, 0.01, 0.1], \n",
    "                                     'l1_ratio':[0.1,0.25,0.75,0.9]})\n",
    "\n",
    "operation.fit(scalerX.transform(X),scalerY.transform(Y).flatten())\n",
    "#model.fit(scalerX.transform(X),scalerY.transform(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
