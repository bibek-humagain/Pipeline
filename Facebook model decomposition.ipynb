{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"C:/Users/bibek/Desktop/movie_metadata.xls\", 'movie_metadata', index_col=None, na_values=['NA'])\n",
    "df.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['profit']=df['gross']- df['budget']\n",
    "df[\"genres\"] = df[\"genres\"].str.replace('|', ', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df.profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['profit', 'gross', 'num_critic_for_reviews', 'num_user_for_reviews', 'movie_movie_link'], 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "color                        0\n",
       "director_name                0\n",
       "duration                     0\n",
       "director_facebook_likes      0\n",
       "actor_3_facebook_likes       0\n",
       "actor_2_name                 0\n",
       "actor_1_facebook_likes       0\n",
       "genres                       0\n",
       "actor_1_name                 0\n",
       "movie_title                  0\n",
       "num_voted_users              0\n",
       "cast_total_facebook_likes    0\n",
       "actor_3_name                 0\n",
       "facenumber_in_poster         0\n",
       "plot_keywords                0\n",
       "language                     0\n",
       "country                      0\n",
       "content_rating               0\n",
       "budget                       0\n",
       "title_year                   0\n",
       "actor_2_facebook_likes       0\n",
       "movie_score                  0\n",
       "aspect_ratio                 0\n",
       "movie_facebook_likes         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(5)\n",
    "X.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "featurename 'color' has 2 unique categories\n",
      "featurename 'director_name' has 1659 unique categories\n",
      "featurename 'actor_2_name' has 2188 unique categories\n",
      "featurename 'genres' has 745 unique categories\n",
      "featurename 'actor_1_name' has 1428 unique categories\n",
      "featurename 'movie_title' has 3655 unique categories\n",
      "featurename 'actor_3_name' has 2587 unique categories\n",
      "featurename 'plot_keywords' has 3656 unique categories\n",
      "featurename 'language' has 34 unique categories\n",
      "featurename 'country' has 45 unique categories\n",
      "featurename 'content_rating' has 12 unique categories\n"
     ]
    }
   ],
   "source": [
    "for col_name in X.columns:\n",
    "    if X[col_name].dtype == 'object':\n",
    "        unique_cat = len(X[col_name].unique())\n",
    "        print (\"featurename '{col_name}' has {unique_cat} unique categories\".format(\n",
    "            col_name =col_name, unique_cat = unique_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "todummy_list = ['color', 'director_name', 'actor_2_name', 'genres', 'actor_1_name', 'movie_title', 'actor_3_name', 'plot_keywords', 'language', 'country', 'content_rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_df(df, todummy_list):\n",
    "    for x in todummy_list:\n",
    "        dummies= pd.get_dummies(df[x], prefix=x)\n",
    "        df = df.drop(x, 1)\n",
    "        df = pd.concat([df, dummies], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   duration  director_facebook_likes  actor_3_facebook_likes  \\\n",
      "0     178.0                      0.0                   855.0   \n",
      "1     169.0                    563.0                  1000.0   \n",
      "2     148.0                      0.0                   161.0   \n",
      "3     164.0                  22000.0                 23000.0   \n",
      "5     132.0                    475.0                   530.0   \n",
      "\n",
      "   actor_1_facebook_likes  num_voted_users  cast_total_facebook_likes  \\\n",
      "0                  1000.0           886204                       4834   \n",
      "1                 40000.0           471220                      48350   \n",
      "2                 11000.0           275868                      11700   \n",
      "3                 27000.0          1144337                     106759   \n",
      "5                   640.0           212204                       1873   \n",
      "\n",
      "   facenumber_in_poster       budget  title_year  actor_2_facebook_likes  ...  \\\n",
      "0                   0.0  237000000.0      2009.0                   936.0  ...   \n",
      "1                   0.0  300000000.0      2007.0                  5000.0  ...   \n",
      "2                   1.0  245000000.0      2015.0                   393.0  ...   \n",
      "3                   0.0  250000000.0      2012.0                 23000.0  ...   \n",
      "5                   1.0  263700000.0      2012.0                   632.0  ...   \n",
      "\n",
      "   content_rating_GP  content_rating_M  content_rating_NC-17  \\\n",
      "0                  0                 0                     0   \n",
      "1                  0                 0                     0   \n",
      "2                  0                 0                     0   \n",
      "3                  0                 0                     0   \n",
      "5                  0                 0                     0   \n",
      "\n",
      "   content_rating_Not Rated  content_rating_PG  content_rating_PG-13  \\\n",
      "0                         0                  0                     1   \n",
      "1                         0                  0                     1   \n",
      "2                         0                  0                     1   \n",
      "3                         0                  0                     1   \n",
      "5                         0                  0                     1   \n",
      "\n",
      "   content_rating_Passed  content_rating_R  content_rating_Unrated  \\\n",
      "0                      0                 0                       0   \n",
      "1                      0                 0                       0   \n",
      "2                      0                 0                       0   \n",
      "3                      0                 0                       0   \n",
      "5                      0                 0                       0   \n",
      "\n",
      "   content_rating_X  \n",
      "0                 0  \n",
      "1                 0  \n",
      "2                 0  \n",
      "3                 0  \n",
      "5                 0  \n",
      "\n",
      "[5 rows x 16024 columns]\n"
     ]
    }
   ],
   "source": [
    "X = dummy_df(X, todummy_list)\n",
    "print(X.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "from statsmodels.nonparametric.kde import KDEUnivariate\n",
    "def find_outliers_kde(x):\n",
    "    x_scaled = scale(list(map(float, x)))\n",
    "    kde = KDEUnivariate(x_scaled)\n",
    "    kde.fit(bw=\"scott\",fft=True)\n",
    "    pred = kde.evaluate(x_scaled)\n",
    "    \n",
    "    n= sum(pred < 0.05)\n",
    "    outlier_ind = np.asarray(pred).argsort()[:n]\n",
    "    outlier_value = np.asarray(x)[outlier_ind]\n",
    "    return outlier_ind, outlier_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.\n",
      "  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.\n",
      "  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.\n",
      "  6.  6.  6.  7.  7.  7.  7.  7.  7.  7.  7.  7.  7.  7.  7.  7.  7.  7.\n",
      "  7.  7.  7.  7.  7.  7.  7.  7.  7.  7.  7.  7.  7.  7.  7.  8.  8.  8.\n",
      "  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.\n",
      "  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  9.  9.  9.  9.  9.  9.  9.\n",
      "  9.  9.  9.  9. 10. 10. 10. 10. 10. 10. 11. 11. 11. 11. 11. 12. 12. 12.\n",
      " 13. 14. 15. 15. 15. 15. 19. 31. 43.]\n"
     ]
    }
   ],
   "source": [
    "kde_indices, kde_values = find_outliers_kde(X['facenumber_in_poster'])\n",
    "print(np.sort(kde_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_interactions(df):\n",
    "    #Get feature names\n",
    "    combos = list(combinations(list(df.columns),2))\n",
    "    colnames =list(df.columns) + ['_'.join(x) for x in combos]\n",
    "    \n",
    "    #find interactions\n",
    "    poly = PolynomialFeatures(interaction_only=True, include_bias=False)\n",
    "    df = poly.fit_transformation(df)\n",
    "    df = pd.DataFrame(df)\n",
    "    df.columns = colnames\n",
    "    \n",
    "    #Remove interaction terms with all 0 values\n",
    "    noint_indicies = [i for i, x in enumerate(list((df == 0).all())) if x]\n",
    "    df = df.drop(df.columns[noint_indicies], axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PolynomialFeatures' object has no attribute 'fit_transformation'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-1d24a5cac665>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madd_interactions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-14-22b3afceeedf>\u001b[0m in \u001b[0;36madd_interactions\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m#find interactions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mpoly\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPolynomialFeatures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minteraction_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minclude_bias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpoly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transformation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolnames\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'PolynomialFeatures' object has no attribute 'fit_transformation'"
     ]
    }
   ],
   "source": [
    "X = add_interactions(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Decomposition of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=50)\n",
    "X_pca = pd.DataFrame(pca.fit_transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             0             1             2             3             4   \\\n",
      "0  1.907632e+08  7.705416e+05 -43136.913399 -28956.290660   3516.728296   \n",
      "1  2.537632e+08  3.539054e+05  29754.916856 -41368.148234   3904.178059   \n",
      "2  1.987632e+08  1.662034e+05   3767.874067  62368.552144   7033.448961   \n",
      "3  2.037632e+08  1.040981e+06  59241.498253  71440.000041 -34392.815652   \n",
      "4  2.174632e+08  9.692002e+04 -15256.525050   8467.662695   1676.542882   \n",
      "\n",
      "             5             6            7          8          9   ...  \\\n",
      "0  -5212.661423    109.101792   322.163163  32.876996 -14.335437  ...   \n",
      "1  -2535.808542    545.538711   464.263912  41.124273 -11.898920  ...   \n",
      "2  -1714.659592    965.387549  -190.265472  27.084746  -2.968569  ...   \n",
      "3  13890.605187 -20932.025564  7702.693412 -22.116868  14.221902  ...   \n",
      "4   -851.291368    239.623677  -330.543053  15.657214  -9.445633  ...   \n",
      "\n",
      "         40        41        42        43        44        45        46  \\\n",
      "0 -0.081925 -0.106588 -0.027081 -0.010155 -0.003320 -0.050983  0.019886   \n",
      "1  0.672764  0.106174  0.226656 -0.044756 -0.080617  0.064447 -0.329609   \n",
      "2  0.129946 -0.022846  0.059157  0.014827  0.029452 -0.024773 -0.005284   \n",
      "3 -0.297933  0.014300 -0.132512 -0.053970 -0.045161  0.028351  0.000365   \n",
      "4  0.221415  0.032290  0.056060  0.041097 -0.006405 -0.009517 -0.032886   \n",
      "\n",
      "         47        48        49  \n",
      "0 -0.040801  0.015372 -0.080728  \n",
      "1  0.178948  0.342301  0.094320  \n",
      "2  0.046335  0.027532  0.015203  \n",
      "3  0.049380 -0.033847  0.050867  \n",
      "4  0.039000  0.017118 -0.011570  \n",
      "\n",
      "[5 rows x 50 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X_pca.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Model building and feature selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.array([Y]).T \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.20, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bibek\\Anaconda3\\envs\\bibekenv\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\bibek\\Anaconda3\\envs\\bibekenv\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: UserWarning: Features [   15    16    17 ... 16020 16022 16023] are constant.\n",
      "  UserWarning)\n",
      "C:\\Users\\bibek\\Anaconda3\\envs\\bibekenv\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:115: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n",
      "C:\\Users\\bibek\\Anaconda3\\envs\\bibekenv\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:115: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    }
   ],
   "source": [
    "import sklearn.feature_selection\n",
    "select = sklearn.feature_selection.SelectKBest(k=20)\n",
    "selected_features = select.fit(X_train, Y_train)\n",
    "indices_selected = selected_features.get_support(indices=True)\n",
    "colnames_selected = [X.columns[i] for i in indices_selected]\n",
    "\n",
    "X_train_selected = X_train[colnames_selected]\n",
    "X_test_selected =  X_test[colnames_selected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['country_Norway',\n",
       " 'country_Official site',\n",
       " 'country_Peru',\n",
       " 'country_Romania',\n",
       " 'country_Russia',\n",
       " 'country_South Africa',\n",
       " 'country_South Korea',\n",
       " 'country_Spain',\n",
       " 'country_Taiwan',\n",
       " 'country_Thailand',\n",
       " 'country_West Germany',\n",
       " 'content_rating_G',\n",
       " 'content_rating_GP',\n",
       " 'content_rating_M',\n",
       " 'content_rating_NC-17',\n",
       " 'content_rating_Not Rated',\n",
       " 'content_rating_PG-13',\n",
       " 'content_rating_Passed',\n",
       " 'content_rating_Unrated',\n",
       " 'content_rating_X']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colnames_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
